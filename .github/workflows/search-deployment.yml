name: Search Integration Deployment

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/ai_service/layers/search/**'
      - 'src/ai_service/layers/embeddings/indexing/elasticsearch_watchlist_adapter.py'
      - 'templates/elasticsearch/**'
      - 'scripts/elasticsearch_setup_and_warmup.py'
      - 'scripts/bulk_loader.py'
  pull_request:
    branches: [main, develop]
    paths:
      - 'src/ai_service/layers/search/**'
      - 'src/ai_service/layers/embeddings/indexing/elasticsearch_watchlist_adapter.py'
      - 'templates/elasticsearch/**'
      - 'scripts/elasticsearch_setup_and_warmup.py'
      - 'scripts/bulk_loader.py'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      skip_tests:
        description: 'Skip tests'
        required: false
        default: false
        type: boolean
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.10'
  ELASTICSEARCH_VERSION: '8.11.0'
  ES_URL: 'http://localhost:9200'
  ES_AUTH: ''
  ES_VERIFY_SSL: 'false'

jobs:
  # ============================================================================
  # Build and Test
  # ============================================================================
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    outputs:
      build-artifacts: ${{ steps.build.outputs.artifacts }}
      test-results: ${{ steps.test.outputs.results }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r tests/requirements_test.txt
          pip install httpx pyyaml pydantic
      
      - name: Build artifacts
        id: build
        run: |
          echo "Building search integration artifacts..."
          
          # Create artifacts directory
          mkdir -p artifacts/search
          
          # Copy source code
          cp -r src/ai_service/layers/search artifacts/search/
          cp -r src/ai_service/layers/embeddings/indexing/elasticsearch_watchlist_adapter.py artifacts/search/
          cp -r templates/elasticsearch artifacts/search/
          cp -r scripts/elasticsearch_setup_and_warmup.py artifacts/search/
          cp -r scripts/bulk_loader.py artifacts/search/
          cp -r scripts/ac_search_templates.py artifacts/search/
          cp -r scripts/vector_search_templates.py artifacts/search/
          
          # Copy test data
          cp -r src/ai_service/data/templates artifacts/search/
          
          # Create version file
          echo "${{ github.sha }}" > artifacts/search/VERSION
          echo "${{ github.ref_name }}" >> artifacts/search/VERSION
          echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> artifacts/search/VERSION
          
          # Create artifact manifest
          cat > artifacts/search/MANIFEST.json << EOF
          {
            "version": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "components": [
              "search_layer",
              "elasticsearch_watchlist_adapter",
              "elasticsearch_templates",
              "setup_scripts",
              "bulk_loader",
              "test_data"
            ]
          }
          EOF
          
          echo "artifacts=artifacts" >> $GITHUB_OUTPUT
          echo "‚úÖ Build artifacts created"
      
      - name: Run unit tests
        id: test
        if: ${{ !inputs.skip_tests }}
        run: |
          echo "Running unit tests..."
          
          # Run unit tests
          pytest tests/unit/ -m "unit" -v --tb=short --junitxml=test-results.xml --cov=src/ai_service --cov-report=xml
          
          # Check test results
          if [ $? -eq 0 ]; then
            echo "results=success" >> $GITHUB_OUTPUT
            echo "‚úÖ Unit tests passed"
          else
            echo "results=failed" >> $GITHUB_OUTPUT
            echo "‚ùå Unit tests failed"
            exit 1
          fi
      
      - name: Upload test results
        if: always() && !inputs.skip_tests
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: |
            test-results.xml
            coverage.xml
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: search-artifacts
          path: artifacts/

  # ============================================================================
  # Integration Tests
  # ============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: build-and-test
    if: ${{ !inputs.skip_tests }}
    
    services:
      elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:${{ env.ELASTICSEARCH_VERSION }}
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: -Xms1g -Xmx1g
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
          --health-start-period 30s
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r tests/requirements_test.txt
          pip install httpx pyyaml pydantic
      
      - name: Wait for Elasticsearch
        run: |
          echo "Waiting for Elasticsearch to be ready..."
          timeout 300 bash -c 'until curl -f http://localhost:9200/_cluster/health; do sleep 5; done'
          echo "‚úÖ Elasticsearch is ready"
      
      - name: Run integration tests
        run: |
          echo "Running integration tests..."
          pytest tests/integration/ -m "integration" -v --tb=short --junitxml=integration-test-results.xml
          
          if [ $? -eq 0 ]; then
            echo "‚úÖ Integration tests passed"
          else
            echo "‚ùå Integration tests failed"
            exit 1
          fi
      
      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results
          path: integration-test-results.xml

  # ============================================================================
  # Deploy to Staging
  # ============================================================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-and-test, integration-tests]
    if: ${{ github.ref == 'refs/heads/develop' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'staging') }}
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: search-artifacts
          path: artifacts/
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install httpx pyyaml pydantic
      
      - name: Deploy to staging
        run: |
          echo "üöÄ Deploying to staging environment..."
          
          # Set staging environment variables
          export ES_URL="${{ secrets.STAGING_ES_URL }}"
          export ES_AUTH="${{ secrets.STAGING_ES_AUTH }}"
          export ES_VERIFY_SSL="${{ secrets.STAGING_ES_VERIFY_SSL }}"
          
          # Run deployment script
          python scripts/deploy_search_integration.py \
            --environment staging \
            --artifacts-path artifacts/ \
            --es-url "$ES_URL" \
            --es-auth "$ES_AUTH" \
            --es-verify-ssl "$ES_VERIFY_SSL" \
            --dry-run false
      
      - name: Run smoke tests
        run: |
          echo "üß™ Running smoke tests..."
          python scripts/smoke_test_search.py \
            --environment staging \
            --es-url "${{ secrets.STAGING_ES_URL }}" \
            --es-auth "${{ secrets.STAGING_ES_AUTH }}"

  # ============================================================================
  # Deploy to Production
  # ============================================================================
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-and-test, integration-tests, deploy-staging]
    if: ${{ github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production') }}
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: search-artifacts
          path: artifacts/
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install httpx pyyaml pydantic
      
      - name: Deploy to production
        run: |
          echo "üöÄ Deploying to production environment..."
          
          # Set production environment variables
          export ES_URL="${{ secrets.PRODUCTION_ES_URL }}"
          export ES_AUTH="${{ secrets.PRODUCTION_ES_AUTH }}"
          export ES_VERIFY_SSL="${{ secrets.PRODUCTION_ES_VERIFY_SSL }}"
          
          # Run deployment script
          python scripts/deploy_search_integration.py \
            --environment production \
            --artifacts-path artifacts/ \
            --es-url "$ES_URL" \
            --es-auth "$ES_AUTH" \
            --es-verify-ssl "$ES_VERIFY_SSL" \
            --dry-run false
      
      - name: Run smoke tests
        run: |
          echo "üß™ Running smoke tests..."
          python scripts/smoke_test_search.py \
            --environment production \
            --es-url "${{ secrets.PRODUCTION_ES_URL }}" \
            --es-auth "${{ secrets.PRODUCTION_ES_AUTH }}"
      
      - name: Generate deployment report
        run: |
          echo "üìä Generating deployment report..."
          python scripts/generate_deployment_report.py \
            --environment production \
            --es-url "${{ secrets.PRODUCTION_ES_URL }}" \
            --es-auth "${{ secrets.PRODUCTION_ES_AUTH }}" \
            --output artifacts/deployment-report.json
      
      - name: Upload deployment report
        uses: actions/upload-artifact@v3
        with:
          name: deployment-report
          path: artifacts/deployment-report.json

  # ============================================================================
  # Rollback (if needed)
  # ============================================================================
  rollback:
    name: Rollback Deployment
    runs-on: ubuntu-latest
    if: failure() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    environment: ${{ github.ref == 'refs/heads/main' && 'production' || 'staging' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install httpx pyyaml pydantic
      
      - name: Rollback deployment
        run: |
          echo "üîÑ Rolling back deployment..."
          
          # Set environment variables
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            export ES_URL="${{ secrets.PRODUCTION_ES_URL }}"
            export ES_AUTH="${{ secrets.PRODUCTION_ES_AUTH }}"
            export ES_VERIFY_SSL="${{ secrets.PRODUCTION_ES_VERIFY_SSL }}"
            export ENVIRONMENT="production"
          else
            export ES_URL="${{ secrets.STAGING_ES_URL }}"
            export ES_AUTH="${{ secrets.STAGING_ES_AUTH }}"
            export ES_VERIFY_SSL="${{ secrets.STAGING_ES_VERIFY_SSL }}"
            export ENVIRONMENT="staging"
          fi
          
          # Run rollback script
          python scripts/rollback_search_integration.py \
            --environment "$ENVIRONMENT" \
            --es-url "$ES_URL" \
            --es-auth "$ES_AUTH" \
            --es-verify-ssl "$ES_VERIFY_SSL"
