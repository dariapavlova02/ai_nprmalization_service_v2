#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å production –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
"""

import os
import sys
from pathlib import Path

# Set production environment variables
os.environ.update({
    'PRESERVE_FEMININE_SURNAMES': 'true',
    'ENABLE_ENHANCED_GENDER_RULES': 'true',
    'PRESERVE_FEMININE_SUFFIX_UK': 'true',
    'ENABLE_FSM_TUNED_ROLES': 'true',
    'MORPHOLOGY_CUSTOM_RULES_FIRST': 'true',
    'ENABLE_ADVANCED_FEATURES': 'true',
    'NORMALIZATION_ENABLE_ADVANCED_FEATURES': 'true',
    'NORMALIZATION_ENABLE_MORPHOLOGY': 'true',
    'NORMALIZATION_PRESERVE_NAMES': 'true',
    'NORMALIZATION_REMOVE_STOP_WORDS': 'true',
    'ENABLE_SMART_FILTER': 'true',
    'ALLOW_SMART_FILTER_SKIP': 'false',
    'ENABLE_AHO_CORASICK': 'true',
    'ENABLE_VECTOR_FALLBACK': 'true'
})

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_critical_cases():
    """–¢–µ—Å—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ —Å production –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏."""
    print("üîç –¢–ï–°–¢ –° PRODUCTION –ü–ï–†–ï–ú–ï–ù–ù–´–ú–ò –û–ö–†–£–ñ–ï–ù–ò–Ø")
    print("="*60)

    try:
        from ai_service.layers.normalization.normalization_service import NormalizationService

        service = NormalizationService()
        print("‚úÖ NormalizationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å production flags")

        # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ –∏–∑ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
        test_cases = [
            {
                "text": "–ü–æ—Ä–æ—à–µ–Ω–∫–∞ –ü–µ—Ç–µ–Ω—å–∫–∞",
                "expected": "–ü–æ—Ä–æ—à–µ–Ω–∫–æ –ü–µ—Ç—Ä–æ"
            },
            {
                "text": "–ü–∞–≤–ª–æ–≤–æ—ó –î–∞—Ä º—ó –Æ—Ä—ñ—ó–≤–Ω–∏",
                "expected": "–ü–∞–≤–ª–æ–≤–∞ –î–∞—Ä º—è –Æ—Ä—ñ—ó–≤–Ω–∞"
            }
        ]

        for case in test_cases:
            text = case["text"]
            expected = case["expected"]

            print(f"\nüìù –¢–µ—Å—Ç: '{text}'")
            print(f"   –û–∂–∏–¥–∞–µ–º: '{expected}'")

            try:
                result = service.normalize_sync(
                    text=text,
                    language="uk",
                    remove_stop_words=True,
                    preserve_names=True,
                    enable_advanced_features=True
                )

                print(f"   ‚úÖ –ü–æ–ª—É—á–∏–ª–∏: '{result.normalized}'")

                status = "‚úÖ PASS" if result.normalized == expected else "‚ùå FAIL"
                print(f"   {status}")

                if result.normalized != expected:
                    print(f"   üîç –¢–æ–∫–µ–Ω—ã: {result.tokens}")
                    print(f"   üîç Trace (first 3):")
                    for i, trace in enumerate(result.trace[:3]):
                        if hasattr(trace, 'token'):
                            print(f"      {i}: {trace.token} ‚Üí {trace.role} ‚Üí {trace.output}")
                        else:
                            print(f"      {i}: {trace}")

            except Exception as e:
                print(f"   ‚ùå –û–®–ò–ë–ö–ê: {e}")

    except ImportError as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å: {e}")
    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")

def test_morphology_direct():
    """–ü—Ä—è–º–æ–π —Ç–µ—Å—Ç –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏."""
    print("\nüîç –¢–ï–°–¢ –ú–û–†–§–û–õ–û–ì–ò–ò –ù–ê–ü–†–Ø–ú–£–Æ")
    print("="*40)

    try:
        from ai_service.layers.normalization.morphology_adapter import MorphologyAdapter

        adapter = MorphologyAdapter()

        test_cases = [
            ("–ü–∞–≤–ª–æ–≤–æ—ó", "uk"),
            ("–ü–æ—Ä–æ—à–µ–Ω–∫–∞", "uk"),
            ("–î–∞—Ä º—ó", "uk"),
            ("–Æ—Ä—ñ—ó–≤–Ω–∏", "uk")
        ]

        for word, lang in test_cases:
            result = adapter.to_nominative(word, lang)
            print(f"   {word} ({lang}) ‚Üí {result}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏: {e}")

if __name__ == "__main__":
    test_morphology_direct()
    test_critical_cases()
    print("\n" + "="*60)
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")