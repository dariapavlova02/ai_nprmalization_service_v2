#!/usr/bin/env python3
"""
Analyze payment tokens for diminutives and nicknames
"""

import csv
import re
from collections import defaultdict

def analyze_diminutives(filename, top_n=1000):
    """Analyze top N tokens for potential diminutives and nicknames"""

    # Known common Ukrainian/Russian/English diminutive patterns
    diminutive_patterns = {
        'ru': {
            # Russian diminutive endings
            '—è_endings': ['–Ω—è', '—Å—è', '–ª—è', '–∫–∞', '—à–∞', '—Ç–∞', '–¥–∞'],  # –¢–∞–Ω—è, –í–∞—Å—è, –ö–æ–ª—è, –ê–Ω—å–∫–∞, –°–∞—à–∞, –°–≤–µ—Ç–∞, –õ—é–¥–∞
            '–∏_endings': ['–∏–∫', '–∏—á', '–∏–Ω'],  # –ö–æ—Å—Ç–∏–∫, –ö–æ—Å—Ç–∏—á, –ö–æ—Å—Ç–∏–Ω
            '–∞_endings': ['—à–∞', '–Ω—è', '–∫–∞', '–ª—è', '—Å—è', '—Ç–∞', '–¥–∞'],  # –ú–∞—à–∞, –°–æ–Ω—è, –í–∞–ª—å–∫–∞, –û–ª—è, –í–∞—Å—è, –°–≤–µ—Ç–∞, –õ—é–¥–∞
        },
        'uk': {
            # Ukrainian similar patterns
            '—è_endings': ['–Ω—è', '—Å—è', '–ª—è', '–∫–∞'],  # –¢–∞–Ω—è, –í–∞—Å—è, –ö–æ–ª—è, –ê–Ω—å–∫–∞
            '—ñ_endings': ['—ñ–∫'],  # –ö–æ—Å—Ç—ñ–∫
            '–∞_endings': ['—à–∞', '–Ω—è', '–∫–∞', '–ª—è', '—Å—è'],  # –ú–∞—à–∞, –°–æ–Ω—è, –í–∞–ª—å–∫–∞, –û–ª—è, –í–∞—Å—è
        }
    }

    # Common full names that might have diminutives in payment data
    known_full_names = {
        # Male names
        '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä': ['—Å–∞—à–∞', '—Å–∞–Ω—è', '—à—É—Ä–∞', '–∞–ª–µ–∫—Å', '—Å–∞—Ö–∞'],
        '–≤–ª–∞–¥–∏–º–∏—Ä': ['–≤–æ–ª–æ–¥—è', '–≤–æ–≤–∞', '–≤–ª–∞–¥–∏–∫', '–≤–æ–ª–æ–¥—å–∫–∞'],
        '—Å–µ—Ä–≥–µ–π': ['—Å–µ—Ä–µ–∂–∞', '—Å–µ—Ä–µ–≥–∞', '—Å–µ—Ä–∂'],
        '–∞–Ω–¥—Ä–µ–π': ['–∞–Ω–¥—Ä—ñ–π', '–∞–Ω–¥—Ä–µ—ó–≤', '–∞–Ω–¥—Ä—é—à–∞'],
        '–¥–º–∏—Ç—Ä–∏–π': ['–¥–∏–º–∞', '–¥–∏–º–∫–∞', '–¥–∏–º–æ–Ω', '–º–∏—Ç—è'],
        '–Ω–∏–∫–æ–ª–∞–π': ['–∫–æ–ª—è', '–∫–æ–ª—è–Ω', '–º–∏–∫–æ–ª–∞', '–Ω–∏–∫–∞'],
        '–∞–ª–µ–∫—Å–µ–π': ['–ª–µ—à–∞', '–∞–ª–µ—à–∞', '–ª—ë—à–∞', '–æ–ª–µ–∫—Å'],
        '–≤–∏–∫—Ç–æ—Ä': ['–≤–∏—Ç—è', '–≤–∏—Ç—å–∫–∞', '–≤—ñ–∫—Ç–æ—Ä'],
        '–ø–µ—Ç—Ä': ['–ø–µ—Ç—è', '–ø–µ—Ç—Ä–æ', '–ø–µ—Ç—Ä—É—à–∞'],
        '—Ä–æ–º–∞–Ω': ['—Ä–æ–º–∞', '—Ä–æ–º–∫–∞', '—Ä–æ–º–∞–Ω—á–∏–∫'],
        '–æ–ª–µ–≥': ['–æ–ª–µ–∂–∫–∞', '–æ–ª–µ–≥–∞'],
        '—é—Ä–∏–π': ['—é—Ä–∞', '—é—Ä–∫–∞', '—é—Ä—ñ–π'],
        '–º–∏—Ö–∞–∏–ª': ['–º–∏—à–∞', '–º–∏—à–∫–∞', '–º–∏—Ö–∞–π–ª–æ', '–º—ñ—à–∞'],
        '–µ–≤–≥–µ–Ω–∏–π': ['–∂–µ–Ω—è', '–∂–µ–Ω—å–∫–∞', '—î–≤–≥–µ–Ω'],
        '–≤–∞–ª–µ–Ω—Ç–∏–Ω': ['–≤–∞–ª—è', '–≤–∞–ª–∏–∫', '–≤–∞–ª–µ–Ω—Ç—ñ–Ω'],
        '–≤–∞—Å–∏–ª–∏–π': ['–≤–∞—Å—è', '–≤–∞—Å—å–∫–∞', '–≤–∞—Å–∏–ª—å'],
        '–∞—Ä—Ç–µ–º': ['—Ç–µ–º–∞', '—Ç–µ–º–∫–∞', '–∞—Ä—Ç–µ–º–∫–∞'],
        '–º–∞–∫—Å–∏–º': ['–º–∞–∫—Å', '–º–∞–∫—Å–∏–∫', '–º–∞–∫—Å–∏–º–∫–∞'],
        '–∏–≥–æ—Ä—å': ['–∏–≥–æ—Ä—ë–∫', '—ñ–≥–æ—Ä'],
        '–ø–∞–≤–µ–ª': ['–ø–∞—à–∞', '–ø–∞—à–∫–∞', '–ø–∞–≤–ª–æ'],
        '–∞–Ω–∞—Ç–æ–ª–∏–π': ['—Ç–æ–ª—è', '—Ç–æ–ª–∏–∫', '–∞–Ω–∞—Ç–æ–ª—ñ–π'],
        '–∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω': ['–∫–æ—Å—Ç—è', '–∫–æ—Å—Ç–∏–∫', '–∫–æ—Å—Ç—è–Ω'],
        '–∏–≤–∞–Ω': ['–≤–∞–Ω—è', '–≤–∞–Ω—å–∫–∞', '—ñ–≤–∞–Ω'],
        '–¥–µ–Ω–∏—Å': ['–¥—ç–Ω', '–¥–µ–Ω—á–∏–∫', '–¥–µ–Ω—è'],
        '—Å—Ç–∞–Ω–∏—Å–ª–∞–≤': ['—Å—Ç–∞—Å', '—Å—Ç–∞—Å–∏–∫', '—Å—Ç–∞–Ω—ñ—Å–ª–∞–≤'],
        '—Ç–∞—Ä–∞—Å': ['—Ç–∞—Ä–∞—Å–∏–∫', '—Ç–∞—Ä–∞—Å–∫–∞'],
        '–±–æ–≥–¥–∞–Ω': ['–±–æ–≥–¥–∞–Ω—á–∏–∫', '–±–æ–≥–¥—è'],
        '–≤–∏—Ç–∞–ª–∏–π': ['–≤–∏—Ç–∞–ª–∏–∫', '–≤—ñ—Ç–∞–ª—ñ–π', '–≤—ñ—Ç–∞–ª—è'],

        # Female names
        '–∞–Ω–Ω–∞': ['–∞–Ω—è', '–∞–Ω—å–∫–∞', '–Ω—é—à–∞', '–∞–Ω–µ—á–∫–∞'],
        '–º–∞—Ä–∏—è': ['–º–∞—à–∞', '–º–∞—à–∫–∞', '–º–∞—Ä–∞', '–º–∞—Ä–∏', '–º–∞—Ä—ñ—è'],
        '–µ–ª–µ–Ω–∞': ['–ª–µ–Ω–∞', '–ª–µ–Ω–∫–∞', '–∞–ª–µ–Ω–∞', '—î–ª–µ–Ω–∞', '–æ–ª–µ–Ω–∞'],
        '–æ–ª—å–≥–∞': ['–æ–ª—è', '–æ–ª—å–∫–∞', '–æ–ª—å–≥—É—à–∞'],
        '—Ç–∞—Ç—å—è–Ω–∞': ['—Ç–∞–Ω—è', '—Ç–∞–Ω—å–∫–∞', '—Ç–∞—Ç–∞', '—Ç–∞—Ç—å—è–Ω–∞'],
        '–Ω–∞—Ç–∞–ª—å—è': ['–Ω–∞—Ç–∞–ª—è', '–Ω–∞—Ç–∞–ª—ñ—è', '–Ω–∞—Ç–∞—à–∞', '–Ω–∞—Ç–∞'],
        '—Å–≤–µ—Ç–ª–∞–Ω–∞': ['—Å–≤–µ—Ç–∞', '—Å–≤–µ—Ç–∏–∫', '—Å–≤–µ—Ç–ª–∞–Ω–∞'],
        '–ª—é–¥–º–∏–ª–∞': ['–ª—é–¥–∞', '–ª—é–¥–∫–∞', '–ª—é–¥–º–∏–ª–∞', '–º–∏–ª–∞'],
        '–∏—Ä–∏–Ω–∞': ['–∏—Ä–∞', '–∏—Ä–∫–∞', '–∏—Ä–∏—à–∞', '—ñ—Ä–∏–Ω–∞'],
        '–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞': ['–≤–∞–ª—è', '–≤–∞–ª—å–∫–∞', '–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞'],
        '–≥–∞–ª–∏–Ω–∞': ['–≥–∞–ª—è', '–≥–∞–ª—å–∫–∞', '–≥–∞–ª–∏–Ω–∞'],
        '–Ω–∏–Ω–∞': ['–Ω–∏–Ω–∫–∞', '–Ω–∏–Ω–æ—á–∫–∞'],
        '–ª—é–±–æ–≤—å': ['–ª—é–±–∞', '–ª—é–±–∫–∞', '–ª—é–±–æ–≤—å'],
        '–µ–∫–∞—Ç–µ—Ä–∏–Ω–∞': ['–∫–∞—Ç—è', '–∫–∞—Ç—å–∫–∞', '–∫–∞—Ç–µ—Ä–∏–Ω–∞', '–∫–∞—Ç–µ—Ä—ñ–Ω'],
        '–ª–∞—Ä–∏—Å–∞': ['–ª–∞—Ä–∞', '–ª–∞—Ä–∫–∞'],
        '—Ç–∞–º–∞—Ä–∞': ['—Ç–æ–º–∞', '—Ç–æ–º–∫–∞', '—Ç–∞–º–∞—Ä–∫–∞'],
        '—Ä–∞–∏—Å–∞': ['—Ä–∞—è', '—Ä–∞–µ—á–∫–∞'],
        '–≤–µ—Ä–∞': ['–≤–µ—Ä–æ—á–∫–∞', '–≤–µ—Ä–∫–∞'],
        '–∞–ª–ª–∞': ['–∞–ª–ª–æ—á–∫–∞', '–∞–ª–∫–∞'],
        '–∏–Ω–Ω–∞': ['–∏–Ω–Ω–∫–∞', '–∏–Ω–Ω–æ—á–∫–∞'],
        '–æ–∫—Å–∞–Ω–∞': ['–∫—Å—é—à–∞', '–∫—Å–µ–Ω–∏—è', '–æ–∫—Å—è'],
        '—é–ª–∏—è': ['—é–ª—è', '—é–ª—å–∫–∞', '—é–ª–∏—è'],
        '–¥–∞—Ä—å—è': ['–¥–∞—à–∞', '–¥–∞—à–∫–∞', '–¥–∞—Ä–∫–∞', '–¥–∞—Ä–∏–Ω–∞'],
        '–∞–Ω–∞—Å—Ç–∞—Å–∏—è': ['–Ω–∞—Å—Ç—è', '–Ω–∞—Å—Ç—å–∫–∞', '–∞–Ω–∞—Å—Ç–∞—Å—ñ—è', '–Ω–∞—Å—Ç–∞—Å—å—è'],
        '–≤–∏–∫—Ç–æ—Ä–∏—è': ['–≤–∏–∫–∞', '–≤–∏–∫–∫–∞', '–≤—ñ–∫—Ç–æ—Ä—ñ—è'],
    }

    potential_diminutives = {}
    potential_full_names = set()
    uncertain_names = set()

    print(f"üîç Analyzing potential names and diminutives from top {top_n} tokens...")

    with open(filename, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)

        for i, row in enumerate(reader):
            if i >= top_n:
                break

            token = row['–¢–æ–∫–µ–Ω'].lower().strip()
            frequency = int(row['–ß–∞—Å—Ç–æ—Ç–∞'])
            percent = float(row['–ü—Ä–æ—Ü–µ–Ω—Ç'].replace('%', ''))

            # Skip very short or very long tokens
            if len(token) < 3 or len(token) > 15:
                continue

            # Skip obvious non-names
            if token.isdigit() or any(char.isdigit() for char in token):
                continue

            # Skip business terms
            business_terms = ['–æ–ø–ª–∞—Ç–∞', '–ø–ª–∞—Ç–µ–∂', '–¥–æ–≥–æ–≤–æ—Ä', '–ø–æ—Å–ª—É–≥', '—Å–µ—Ä–≤—ñ—Å', '—Ç–∞—Ä–∏—Ñ', '–∫–æ–º—ñ—Å—ñ']
            if any(term in token for term in business_terms):
                continue

            # Check if it's a known full name
            if token in known_full_names:
                potential_full_names.add(token)
                continue

            # Check if it matches diminutive patterns
            is_potential_diminutive = False

            # Russian/Ukrainian diminutive patterns
            for lang, patterns in diminutive_patterns.items():
                for ending_type, endings in patterns.items():
                    if any(token.endswith(ending) for ending in endings):
                        # Additional checks to avoid false positives
                        if frequency >= 100:  # Reasonable frequency for a name
                            # Look for potential full form
                            for full_name, diminutives in known_full_names.items():
                                if token in diminutives:
                                    if full_name not in potential_diminutives:
                                        potential_diminutives[full_name] = set()
                                    potential_diminutives[full_name].add(token)
                                    is_potential_diminutive = True
                                    break

            # If it looks like a name but we can't map it, mark as uncertain
            if not is_potential_diminutive and frequency >= 500:
                # Name-like patterns
                if (len(token) >= 4 and
                    token[0] not in '–π—ä—å—ã' and  # Unlikely first letters for names
                    not any(substring in token for substring in ['–æ–ø–ª–∞—Ç', '–ø–ª–∞—Ç', '—Å—É–º–∞', '–≥—Ä–Ω']) and
                    token.count('—ñ') <= 1 and  # Not too many '—ñ' characters
                    re.match(r'^[–∞-—è—ë—ó—ñ—î“ëa-z]+$', token, re.IGNORECASE)):  # Only letters
                    uncertain_names.add(token)

    return potential_diminutives, potential_full_names, uncertain_names

def analyze_existing_diminutives():
    """Analyze existing diminutives files to understand the format"""

    print("\nüìã Analyzing existing diminutives files...")

    files_to_check = [
        "/Users/dariapavlova/Desktop/ai-service/data/diminutives_ru.json",
        "/Users/dariapavlova/Desktop/ai-service/data/diminutives_uk.json"
    ]

    for file_path in files_to_check:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                print(f"\nüìÅ File: {file_path}")
                content = f.read()[:500]  # First 500 characters
                print(f"Format preview: {content}...")
        except FileNotFoundError:
            print(f"‚ùå File not found: {file_path}")
        except Exception as e:
            print(f"‚ùå Error reading {file_path}: {e}")

def generate_diminutives_additions(potential_diminutives, potential_full_names, uncertain_names):
    """Generate recommended additions to diminutives dictionaries"""

    print(f"\nüéØ DIMINUTIVES ANALYSIS RESULTS")
    print("=" * 70)

    if potential_diminutives:
        print(f"\nüìù FOUND DIMINUTIVE MAPPINGS ({len(potential_diminutives)} full names):")
        for full_name, diminutives in sorted(potential_diminutives.items()):
            print(f"  {full_name}: {', '.join(sorted(diminutives))}")

    if potential_full_names:
        print(f"\nüë§ POTENTIAL FULL NAMES FOUND ({len(potential_full_names)}):")
        sorted_names = sorted(list(potential_full_names))
        for i in range(0, len(sorted_names), 8):
            batch = sorted_names[i:i+8]
            print("  " + ", ".join(batch))

    if uncertain_names:
        print(f"\n‚ùì UNCERTAIN NAME-LIKE TOKENS ({len(uncertain_names)}):")
        print("  (These might be names but need manual verification)")
        sorted_uncertain = sorted(list(uncertain_names))
        for i in range(0, len(sorted_uncertain), 10):
            batch = sorted_uncertain[i:i+10]
            print("  " + ", ".join(batch))

    print("\n" + "=" * 70)
    print("üí° RECOMMENDATIONS:")
    print("1. Add found diminutive mappings to existing diminutives files")
    print("2. Review uncertain tokens manually - some might be valid names")
    print("3. Consider regional name variations (Ukrainian vs Russian)")
    print("4. Check if existing diminutives files need the new mappings")

if __name__ == "__main__":
    # First analyze existing diminutives format
    analyze_existing_diminutives()

    # Then analyze payment tokens
    potential_diminutives, potential_full_names, uncertain_names = analyze_diminutives("all_tokens_by_frequency.csv", top_n=2000)

    # Generate recommendations
    generate_diminutives_additions(potential_diminutives, potential_full_names, uncertain_names)