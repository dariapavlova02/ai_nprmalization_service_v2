#!/usr/bin/env python3
"""
Extract real names and their diminutives from payment data
"""

import csv
import json
import re
from collections import defaultdict

def load_existing_diminutives():
    """Load existing diminutive mappings"""

    existing_ru = {}
    existing_uk = {}

    try:
        with open('/Users/dariapavlova/Desktop/ai-service/data/diminutives_ru.json', 'r', encoding='utf-8') as f:
            existing_ru = json.load(f)
        print(f"‚úÖ Loaded {len(existing_ru)} Russian diminutives")
    except Exception as e:
        print(f"‚ùå Failed to load Russian diminutives: {e}")

    try:
        with open('/Users/dariapavlova/Desktop/ai-service/data/diminutives_uk.json', 'r', encoding='utf-8') as f:
            existing_uk = json.load(f)
        print(f"‚úÖ Loaded {len(existing_uk)} Ukrainian diminutives")
    except Exception as e:
        print(f"‚ùå Failed to load Ukrainian diminutives: {e}")

    return existing_ru, existing_uk

def extract_real_names_from_payments(filename, top_n=5000):
    """Extract real names that appear in payment descriptions"""

    # Focus on names that actually appear in payments with decent frequency
    confirmed_names = set()
    potential_diminutives = defaultdict(set)

    # Known diminutive patterns for quick recognition
    common_diminutives = {
        # Russian
        '—Å–∞—à–∞': '–∞–ª–µ–∫—Å–∞–Ω–¥—Ä', '—Å–µ—Ä–µ–∂–∞': '—Å–µ—Ä–≥–µ–π', '–≤–æ–ª–æ–¥—è': '–≤–ª–∞–¥–∏–º–∏—Ä', '–¥–∏–º–∞': '–¥–º–∏—Ç—Ä–∏–π',
        '–∫–æ–ª—è': '–Ω–∏–∫–æ–ª–∞–π', '–ª–µ—à–∞': '–∞–ª–µ–∫—Å–µ–π', '–≤–∏—Ç—è': '–≤–∏–∫—Ç–æ—Ä', '–ø–µ—Ç—è': '–ø–µ—Ç—Ä', '—Ä–æ–º–∞': '—Ä–æ–º–∞–Ω',
        '—é—Ä–∞': '—é—Ä–∏–π', '–º–∏—à–∞': '–º–∏—Ö–∞–∏–ª', '–∂–µ–Ω—è': '–µ–≤–≥–µ–Ω–∏–π', '–≤–∞—Å—è': '–≤–∞—Å–∏–ª–∏–π', '—Ç–æ–ª—è': '–∞–Ω–∞—Ç–æ–ª–∏–π',
        '–∫–æ—Å—Ç—è': '–∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω', '–ø–∞—à–∞': '–ø–∞–≤–µ–ª', '–≤–∞–Ω—è': '–∏–≤–∞–Ω', '—Å—Ç–∞—Å': '—Å—Ç–∞–Ω–∏—Å–ª–∞–≤',
        '–∞–Ω—è': '–∞–Ω–Ω–∞', '–º–∞—à–∞': '–º–∞—Ä–∏—è', '–ª–µ–Ω–∞': '–µ–ª–µ–Ω–∞', '–æ–ª—è': '–æ–ª—å–≥–∞', '—Ç–∞–Ω—è': '—Ç–∞—Ç—å—è–Ω–∞',
        '–Ω–∞—Ç–∞—à–∞': '–Ω–∞—Ç–∞–ª—å—è', '—Å–≤–µ—Ç–∞': '—Å–≤–µ—Ç–ª–∞–Ω–∞', '–ª—é–¥–∞': '–ª—é–¥–º–∏–ª–∞', '–∏—Ä–∞': '–∏—Ä–∏–Ω–∞',
        '–≤–∞–ª—è': '–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞', '–≥–∞–ª—è': '–≥–∞–ª–∏–Ω–∞', '–ª—é–±–∞': '–ª—é–±–æ–≤—å', '–∫–∞—Ç—è': '–µ–∫–∞—Ç–µ—Ä–∏–Ω–∞',

        # Ukrainian
        '–æ–ª–µ–∫—Å–∞–Ω–¥—Ä': '–æ–ª–µ–∫—Å–∞–Ω–¥—Ä', '—Å–µ—Ä–≥—ñ–π': '—Å–µ—Ä–≥—ñ–π', '–≤–æ–ª–æ–¥–∏–º–∏—Ä': '–≤–æ–ª–æ–¥–∏–º–∏—Ä', '–¥–º–∏—Ç—Ä–æ': '–¥–º–∏—Ç—Ä–æ',
        '–º–∏–∫–æ–ª–∞': '–º–∏–∫–æ–ª–∞', '–æ–ª–µ–∫—Å—ñ–π': '–æ–ª–µ–∫—Å—ñ–π', '–≤—ñ–∫—Ç–æ—Ä': '–≤—ñ–∫—Ç–æ—Ä', '–ø–µ—Ç—Ä–æ': '–ø–µ—Ç—Ä–æ',
        '—é—Ä—ñ–π': '—é—Ä—ñ–π', '–º–∏—Ö–∞–π–ª–æ': '–º–∏—Ö–∞–π–ª–æ', '—î–≤–≥–µ–Ω': '—î–≤–≥–µ–Ω', '–≤–∞—Å–∏–ª—å': '–≤–∞—Å–∏–ª—å',
        '–∞–Ω–∞—Ç–æ–ª—ñ–π': '–∞–Ω–∞—Ç–æ–ª—ñ–π', '–∫–æ—Å—Ç—è–Ω—Ç–∏–Ω': '–∫–æ—Å—Ç—è–Ω—Ç–∏–Ω', '–ø–∞–≤–ª–æ': '–ø–∞–≤–ª–æ', '—ñ–≤–∞–Ω': '—ñ–≤–∞–Ω',
        '–∞–Ω–Ω–∞': '–∞–Ω–Ω–∞', '–º–∞—Ä—ñ—è': '–º–∞—Ä—ñ—è', '–æ–ª–µ–Ω–∞': '–æ–ª–µ–Ω–∞', '–æ–ª—å–≥–∞': '–æ–ª—å–≥–∞', '—Ç–µ—Ç—è–Ω–∞': '—Ç–µ—Ç—è–Ω–∞',
        '–Ω–∞—Ç–∞–ª—ñ—è': '–Ω–∞—Ç–∞–ª—ñ—è', '—Å–≤—ñ—Ç–ª–∞–Ω–∞': '—Å–≤—ñ—Ç–ª–∞–Ω–∞', '–ª—é–¥–º–∏–ª–∞': '–ª—é–¥–º–∏–ª–∞', '—ñ—Ä–∏–Ω–∞': '—ñ—Ä–∏–Ω–∞',
        '–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞': '–≤–∞–ª–µ–Ω—Ç–∏–Ω–∞', '–≥–∞–ª–∏–Ω–∞': '–≥–∞–ª–∏–Ω–∞', '–∫–∞—Ç–µ—Ä–∏–Ω–∞': '–∫–∞—Ç–µ—Ä–∏–Ω–∞', '—é–ª—ñ—è': '—é–ª—ñ—è'
    }

    print(f"üîç Extracting real names from top {top_n} payment tokens...")

    with open(filename, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)

        for i, row in enumerate(reader):
            if i >= top_n:
                break

            token = row['–¢–æ–∫–µ–Ω'].lower().strip()
            frequency = int(row['–ß–∞—Å—Ç–æ—Ç–∞'])
            percent = float(row['–ü—Ä–æ—Ü–µ–Ω—Ç'].replace('%', ''))

            # Skip very short tokens or numbers
            if len(token) < 3 or any(char.isdigit() for char in token):
                continue

            # Skip obvious business/service words
            business_keywords = [
                '–æ–ø–ª–∞—Ç', '–ø–ª–∞—Ç', '–ø–æ—Å–ª—É–≥', '—Å–µ—Ä–≤—ñ—Å', '–¥–æ–≥–æ–≤–æ—Ä', '–±–∞–ª–∞–Ω—Å', '—Ä–∞—Ö—É–Ω–æ–∫', '—Ç–∞—Ä–∏—Ñ',
                '–∫–æ–º—ñ—Å—ñ', '–∑–∞–±–æ—Ä–≥', '–∞–±–æ–Ω–µ–Ω—Ç', '–∫–ª—ñ—î–Ω—Ç', '–∫–∞—Ä—Ç–∫', '–±–∞–Ω–∫', '–∫–æ–º–ø–∞–Ω', '–¥–æ—Å—Ç–∞–≤–∫',
                '–∑–∞–º–æ–≤–ª', '—Ç–æ–≤–∞—Ä', '—É—Å–ª—É–≥', '—Å—Ç—Ä–∞—Ö–æ–≤', '–µ–Ω–µ—Ä–≥—ñ', '–≤–æ–¥–∏', '–≥–∞–∑—É', '–µ–ª–µ–∫—Ç—Ä',
                '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–∫–≤–∏—Ç–æ–∫', '–ø—Ä–æ—ó–∑–¥', '–ø–æ—ó–∑–¥–∫', '–º–µ—Ç—Ä–æ', '–∞–≤—Ç–æ–±—É—Å'
            ]

            if any(keyword in token for keyword in business_keywords):
                continue

            # Check if it's a known name or diminutive
            if token in common_diminutives:
                full_name = common_diminutives[token]
                confirmed_names.add(full_name)
                potential_diminutives[full_name].add(token)
                print(f"üìã Found name: {token} ‚Üí {full_name} (freq: {frequency})")

            # Check for patronymic patterns (high confidence for names)
            elif (token.endswith('–æ–≤–∏—á') or token.endswith('–µ–≤–∏—á') or token.endswith('—ñ–≤–∏—á') or
                  token.endswith('–æ–≤–Ω–∞') or token.endswith('–µ–≤–Ω–∞') or token.endswith('—ñ–≤–Ω–∞')):
                # This is likely a patronymic - the root might be a name
                root = token.replace('–æ–≤–∏—á', '').replace('–µ–≤–∏—á', '').replace('—ñ–≤–∏—á', '')
                root = root.replace('–æ–≤–Ω–∞', '').replace('–µ–≤–Ω–∞', '').replace('—ñ–≤–Ω–∞', '')
                if len(root) >= 3 and frequency >= 50:
                    confirmed_names.add(root + '—ñ–π' if token.endswith(('–æ–≤–∏—á', '–µ–≤–∏—á', '—ñ–≤–∏—á')) else root + '—ñ–π')
                    print(f"üìã Found patronymic: {token} ‚Üí implies name {root}")

            # Check for surname patterns (might indicate real person names nearby)
            elif (token.endswith('–µ–Ω–∫–æ') or token.endswith('—É–∫') or token.endswith('—é–∫') or
                  token.endswith('—Å—å–∫–∏–π') or token.endswith('—Å—å–∫–∞') or token.endswith('–∏—á')):
                if frequency >= 100:  # Reasonable frequency for a surname
                    print(f"üìã Found surname pattern: {token} (freq: {frequency})")

            # Check for name-like tokens with good frequency
            elif (frequency >= 200 and len(token) >= 4 and len(token) <= 12 and
                  re.match(r'^[–∞-—è—ó—ñ—î“ë—ëa-z]+$', token, re.IGNORECASE) and
                  not token.startswith(('www', 'http', 'com')) and
                  token.count('—ñ') <= 2 and  # Not too many '—ñ'
                  not any(substring in token for substring in ['–Ω–µ—Ç', '–±–µ–∑', '–¥–ª—è', '–ø—Ä–∏', '–ø—Ä–æ'])):

                # This might be a name - let's be more selective
                vowel_count = sum(1 for c in token if c in '–∞–µ–∏–æ—É—è—é—ë—ñ—ó—î—ã—ç')
                consonant_count = len(token) - vowel_count

                # Names usually have a good vowel/consonant ratio
                if 0.2 <= vowel_count / len(token) <= 0.6 and consonant_count >= 2:
                    confirmed_names.add(token)
                    print(f"üìã Potential name: {token} (freq: {frequency}, {percent:.3f}%)")

    return confirmed_names, potential_diminutives

def compare_with_existing(confirmed_names, potential_diminutives, existing_ru, existing_uk):
    """Compare found names with existing diminutives"""

    print(f"\nüîç Comparing with existing diminutives...")

    new_mappings = {}
    already_covered = set()

    # Check what's already covered
    all_existing = set()
    all_existing.update(existing_ru.keys())
    all_existing.update(existing_ru.values())
    all_existing.update(existing_uk.keys())
    all_existing.update(existing_uk.values())

    for name in confirmed_names:
        if name in all_existing:
            already_covered.add(name)
        else:
            # This is a new name not in existing data
            if name in potential_diminutives:
                new_mappings[name] = list(potential_diminutives[name])

    print(f"‚úÖ Already covered names: {len(already_covered)}")
    print(f"üÜï New names found: {len(new_mappings)}")

    return new_mappings, already_covered

def generate_additions_report(confirmed_names, potential_diminutives, new_mappings, already_covered):
    """Generate a comprehensive report"""

    print(f"\n" + "="*70)
    print(f"üìä PAYMENT NAMES ANALYSIS REPORT")
    print(f"="*70)

    print(f"\nüìà STATISTICS:")
    print(f"  ‚Ä¢ Total confirmed names: {len(confirmed_names)}")
    print(f"  ‚Ä¢ Names with diminutives: {len(potential_diminutives)}")
    print(f"  ‚Ä¢ Already in existing data: {len(already_covered)}")
    print(f"  ‚Ä¢ New names to add: {len(new_mappings)}")

    if new_mappings:
        print(f"\nüÜï NEW DIMINUTIVE MAPPINGS TO ADD:")
        for full_name, diminutives in sorted(new_mappings.items()):
            print(f"  {full_name}: {', '.join(diminutives)}")

    # Show some examples of already covered names
    if already_covered:
        covered_sample = sorted(list(already_covered))[:20]
        print(f"\n‚úÖ EXAMPLES OF ALREADY COVERED NAMES:")
        print(f"  {', '.join(covered_sample)}")
        if len(already_covered) > 20:
            print(f"  ... and {len(already_covered) - 20} more")

    print(f"\nüí° RECOMMENDATIONS:")
    if new_mappings:
        print(f"  1. Add {len(new_mappings)} new diminutive mappings to appropriate files")
        print(f"  2. Verify the new names are actually person names, not places/organizations")
        print(f"  3. Determine if they should go to Russian or Ukrainian diminutives file")
    else:
        print(f"  1. Existing diminutive files appear to be comprehensive")
        print(f"  2. No significant new diminutives found in payment data")

    print(f"  4. Consider the high frequency of names in payments for quality assessment")

    print(f"\n" + "="*70)

if __name__ == "__main__":
    # Load existing diminutives
    existing_ru, existing_uk = load_existing_diminutives()

    # Extract names from payment data
    confirmed_names, potential_diminutives = extract_real_names_from_payments("all_tokens_by_frequency.csv", top_n=3000)

    # Compare with existing data
    new_mappings, already_covered = compare_with_existing(confirmed_names, potential_diminutives, existing_ru, existing_uk)

    # Generate report
    generate_additions_report(confirmed_names, potential_diminutives, new_mappings, already_covered)