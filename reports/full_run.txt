.....FFFFFFFFFFFFFFFFFFFFFFFFFFFFF.....FFFFFFFFF.............F.F.F...... [  3%]
FFF..........F..FF..................F...F.............F.F...FFFFFFF.FF.. [  7%]
.....................FF.FF.FFFFF........................................ [ 11%]
.....................................FF................F.....F.FF....... [ 15%]
..........s.....................................ssss.s.................. [ 19%]
........................................................................ [ 23%]
...............................................................sss.sssss [ 27%]
s....................................................................... [ 31%]
........................................................................ [ 35%]
........................................................................ [ 39%]
........................................................................ [ 43%]
........................................................................ [ 47%]
........................................................................ [ 51%]
........................................................................ [ 54%]
........................................................................ [ 58%]
.....................................................................FFF [ 62%]
....FFFFFFFFFFFFFFFFFFFFF.........F..................................... [ 66%]
.........F.......F...FF............F..FF.F.............................. [ 70%]
....................FFFFFFFFFFFFFF.FFFFFFFFFF.FF.FFFFFFFFFFFFFF.FFFF..F. [ 74%]
FFFFFFFF.................F...F.F.................FF.FFF.FFFF............ [ 78%]
.............................................................F.F.F..F... [ 82%]
FFF..F.......F....F....................FF........FF.FF......F.FFF...FF.. [ 86%]
..FFF.FF.FFFFFFFFFFFF.............FFFF.F..............................F. [ 90%]
........................................................................ [ 94%]
............FFF.F..............................F...........F............ [ 98%]
.................................                                        [100%]
=================================== FAILURES ===================================
___________ TestNightmareScenario.test_corrupted_encoding_nightmare ____________

self = <tests.e2e.test_nightmare_scenario.TestNightmareScenario object at 0x13f80ba80>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16bb69810>

    async def test_corrupted_encoding_nightmare(self, orchestrator_service):
        """
        Corrupted encoding nightmare test:
        Simulating encoding problems during data transmission
        """
        # Arrange
        # Simulate various encoding problems
        corrupted_texts = [
            "√ê¬°√ê¬µ√ë‚Ç¨√ê¬≥√ê¬∏√ê¬π √êÀú√ê¬≤√ê¬∞√ê¬Ω√ê¬æ√ê¬≤",  # UTF-8 interpreted as Latin-1
            "–°–µ—Ä–≥√ê¬∏√ê¬π –ò–≤–∞–Ω–æ–≤",  # Partially corrupted encoding
            "Sergii √Ñ¬∞vanov",  # Mixed encodings
            "–°–µ—Ä–≥—ñ–π –Ü–≤–∞–Ω–æ–≤",  # Correct Ukrainian encoding for comparison
        ]
    
        # Act & Assert
        for i, corrupted_text in enumerate(corrupted_texts):
            result = await orchestrator_service.process(
                text=corrupted_text,
                generate_variants=True,
                generate_embeddings=False
            )
    
            assert result.success is True, f"Failed to process corrupted text {i}: {corrupted_text}"
            assert len(result.variants) > 0, f"No variants generated for corrupted text {i}"
    
            # Check that the system tries to recover the name
            all_variants_lower = ' '.join(result.variants).lower()
>           assert any(name in all_variants_lower for name in ['sergii', 'sergey', '—Å–µ—Ä–≥–∏–π', '—Å–µ—Ä–≥—ñ–π']), \
                f"Should recover Sergii variants from corrupted text {i}"
E           AssertionError: Should recover Sergii variants from corrupted text 0
E           assert False
E            +  where False = any(<generator object TestNightmareScenario.test_corrupted_encoding_nightmare.<locals>.<genexpr> at 0x16bb89700>)

tests/e2e/test_nightmare_scenario.py:149: AssertionError
_______________ TestNightmareScenario.test_performance_nightmare _______________

self = <tests.e2e.test_nightmare_scenario.TestNightmareScenario object at 0x13f80b950>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16bb74fc0>

    async def test_performance_nightmare(self, orchestrator_service):
        """
        Performance test for nightmare scenario:
        Large volume of complex text with many names
        """
        # Arrange
        complex_text = """
        –í –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏: Jean-Baptiste M√ºller (Z√ºrich), –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç (–ö–∏—ó–≤),
        Mar√≠a Jos√© Garc√≠a-Rodr√≠guez (Madrid), –í–ª–∞–¥–∏–º–∏—Ä –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–∏—á –ò–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–æ–≤ (–ú–æ—Å–∫–≤–∞),
        O'Connor Patrick Michael (Dublin), ≈Ωofie Nov√°kov√°-Svobodov√° (Praha),
        ŒëŒªŒ≠ŒæŒ±ŒΩŒ¥œÅŒøœÇ Œ†Œ±œÄŒ±Œ¥œåœÄŒøœÖŒªŒøœÇ (Athens), Â±±Áî∞Â§™ÈÉé (Tokyo), ŸÖÿ≠ŸÖÿØ ÿπÿ®ÿØ ÿßŸÑŸÑŸá (Cairo),
        –ê–Ω–¥—Ä—ñ–π –í–∞—Å–∏–ª—å–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ-–®–µ–≤—á–µ–Ω–∫–æ (–õ—å–≤—ñ–≤), Giuseppe Di Marco-Rossi (Milano).
        –¢–∞–∫–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π 'Freedom & Justice', "Human Rights Watch",
        '–í—Ä–∞—á–∏ –±–µ–∑ –≥—Ä–∞–Ω–∏—Ü', –∏ —Ñ–æ–Ω–¥–∞ –∏–º–µ–Ω–∏ –ê–Ω–¥—Ä–µ—è –°–∞—Ö–∞—Ä–æ–≤–∞.
        """
    
        # Act
        import time
        start_time = time.time()
    
        result = await orchestrator_service.process(
            text=complex_text,
            generate_variants=True,
            generate_embeddings=False
        )
    
        end_time = time.time()
        processing_time = end_time - start_time
    
        # Assert
        assert result.success is True, "Complex text processing should succeed"
        assert processing_time < 30.0, f"Processing should complete within 30 seconds, took {processing_time:.2f}s"
>       assert len(result.variants) >= 50, f"Should generate many variants for complex text, got {len(result.variants)}"
E       AssertionError: Should generate many variants for complex text, got 12
E       assert 12 >= 50
E        +  where 12 = len(['Gnatuk Abdulaeva Zhorzha Rashida', 'Gnatuk Abdulaev Zhorzha Rashid', 'Gnatuk Abdulaev Zhorzha Rashidovich', 'Gnatuk ...hidovich Freedom', 'Jean-Baptiste M√ºller –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç', 'Jean-Baptiste Muller –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç', ...])
E        +    where ['Gnatuk Abdulaeva Zhorzha Rashida', 'Gnatuk Abdulaev Zhorzha Rashid', 'Gnatuk Abdulaev Zhorzha Rashidovich', 'Gnatuk ...hidovich Freedom', 'Jean-Baptiste M√ºller –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç', 'Jean-Baptiste Muller –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç', ...] = UnifiedProcessingResult(original_text='\n        –í –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏: Jean-Baptiste M√ºller (Z√ºrich), –û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü...–º–∏—Ç Z√ºrcher Strasse'], embeddings=None, decision=None, processing_time=0.00015616416931152344, success=True, errors=[]).variants

tests/e2e/test_nightmare_scenario.py:184: AssertionError
_______________ TestNightmareScenario.test_edge_cases_nightmare ________________

self = <tests.e2e.test_nightmare_scenario.TestNightmareScenario object at 0x13fa39010>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16bb75ba0>

    async def test_edge_cases_nightmare(self, orchestrator_service):
        """
        Edge cases test:
        Very short, very long, and strange input data
        """
        # Arrange
        edge_cases = [
            "",  # Empty string
            "A",  # Single letter
            "–Ø",  # Single Cyrillic letter
            "X" * 1000,  # Very long string
            "–Å" * 100,  # Repeated special characters
            "‚àë‚àÇ‚àÜ‚àû‚âà‚â†‚â§‚â•¬±",  # Mathematical symbols
            "üé≠üé®üé™üéØüé≤",  # Emojis
            "–¢–µ—Å—Ç\x00\x01\x02",  # Control characters
            "   \t\n\r   ",  # Only spaces
            "–°–µ—Ä–≥—ñ–π" + "\u200b" * 10 + "–Ü–≤–∞–Ω–æ–≤",  # Invisible characters
        ]
    
        # Act & Assert
        for i, edge_case in enumerate(edge_cases):
            result = await orchestrator_service.process(
                text=edge_case,
                generate_variants=True,
                generate_embeddings=False
            )
    
            # Main check - should not crash
            assert result is not None, f"Edge case {i} returned None: '{repr(edge_case)}'"
            assert hasattr(result, 'success'), f"Edge case {i} missing success attribute"
    
            # For empty or meaningless input data
            if not edge_case.strip() or len(edge_case.strip()) < 2:
>               assert result.normalized_text == "" or len(result.normalized_text) <= 2
E               AssertionError: assert ('   \t\n\r   ' == ''
E                 
E                 Strings contain only whitespace, escaping them using repr()
E                 - ''
E                 + '   \t\n\r   ' or 9 <= 2)
E                +  where 9 = len('   \t\n\r   ')
E                +    where '   \t\n\r   ' = UnifiedProcessingResult(original_text='   \t\n\r   ', language='uk', language_confidence=0.9, normalized_text='   \t\n...–°–º–∏—Ç Z√ºrcher Strasse'], embeddings=None, decision=None, processing_time=6.890296936035156e-05, success=True, errors=[]).normalized_text

tests/e2e/test_nightmare_scenario.py:248: AssertionError
___________ TestNightmareScenario.test_cache_effectiveness_nightmare ___________

self = <tests.e2e.test_nightmare_scenario.TestNightmareScenario object at 0x13f8a99d0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16baed130>

    async def test_cache_effectiveness_nightmare(self, orchestrator_service):
        """
        Cache effectiveness test in nightmare scenarios
        """
        # Arrange
        test_text = "–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç –≤—Å—Ç—Ä–µ—Ç–∏–ª Jean-Baptiste M√ºller"
    
        # Act - first request (cache miss)
        import time
    
        start_time = time.time()
>       result1 = await orchestrator_service.process(
            text=test_text,
            generate_variants=True,
            cache_result=True
        )
E       TypeError: UnifiedOrchestrator.process() got an unexpected keyword argument 'cache_result'

tests/e2e/test_nightmare_scenario.py:266: TypeError
__________________ TestNightmareScenario.test_batch_nightmare __________________

self = <tests.e2e.test_nightmare_scenario.TestNightmareScenario object at 0x13f8a86b0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16bbd8160>

    async def test_batch_nightmare(self, orchestrator_service):
        """
        Batch processing test for nightmare cases
        """
        # Arrange
        nightmare_batch = [
            "–ì–Ω–∞—Ç—é–∫-–ê–±–¥—É–ª–ª–∞—î–≤ –ñ–æ—Ä–∂",
            "Jean-Baptiste M√ºller",
            "–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ-–°–º—ñ—Ç",
            "Mar√≠a Jos√© Garc√≠a",
            "O'Connor Patrick",
            "–í–ª–∞–¥–∏–º–∏—Ä –ò–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–æ–≤",
            "‚àë‚àÇ‚àÜ –¢–µ—Å—Ç ‚àû",
            "",
            "X" * 100,
            "–°–µ—Ä–≥—ñ–π" + "\u200b" + "–Ü–≤–∞–Ω–æ–≤"
        ]
    
        # Act
>       results = await orchestrator_service.process_batch(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            texts=nightmare_batch,
            generate_variants=True,
            generate_embeddings=False,
            max_concurrent=3
        )
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'process_batch'

tests/e2e/test_nightmare_scenario.py:330: AttributeError
__ TestSanctionsScreeningPipelineE2E.test_ukrainian_surname_pattern_detection __

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13f899e50>
screening_pipeline = <AsyncMock id='6102500752'>

    async def test_ukrainian_surname_pattern_detection(self, screening_pipeline):
        """Test E2E screening with Ukrainian surname pattern"""
        # Arrange
        ukrainian_name = "Petro Poroshenko"
        metadata = {
            'entity_type': 'PERSON',
            'country': 'UA'
        }
    
        # Act
        result = await screening_pipeline.screen_entity(ukrainian_name, metadata)
    
        # Assert
>       assert result.input_text == ukrainian_name
E       AssertionError: assert <Mock name='mock.screen_entity().input_text' id='6102502768'> == 'Petro Poroshenko'
E        +  where <Mock name='mock.screen_entity().input_text' id='6102502768'> = <Mock name='mock.screen_entity()' id='6102500080'>.input_text

tests/e2e/test_sanctions_screening_pipeline.py:98: AssertionError
_____ TestSanctionsScreeningPipelineE2E.test_malicious_input_sanitization ______

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13fa24770>
screening_pipeline = <AsyncMock id='6103091248'>

    async def test_malicious_input_sanitization(self, screening_pipeline):
        """Test E2E handling of malicious input through sanitization"""
        # Arrange
        malicious_input = "<script>alert('xss')</script>Petro Poroshenko"
    
        # Act
        result = await screening_pipeline.screen_entity(malicious_input)
    
        # Assert
>       assert result.input_text == malicious_input  # Original preserved for audit
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert <Mock name='mock.screen_entity().input_text' id='6103093936'> == "<script>alert('xss')</script>Petro Poroshenko"
E        +  where <Mock name='mock.screen_entity().input_text' id='6103093936'> = <Mock name='mock.screen_entity()' id='6103092928'>.input_text

tests/e2e/test_sanctions_screening_pipeline.py:135: AssertionError
____ TestSanctionsScreeningPipelineE2E.test_early_stopping_high_confidence _____

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13fa14050>
screening_pipeline = <AsyncMock id='6103099984'>

    async def test_early_stopping_high_confidence(self, screening_pipeline):
        """Test E2E early stopping on high confidence match"""
        # Arrange
        high_confidence_match = "putin"  # Should trigger AC exact match
    
        # Act
        result = await screening_pipeline.screen_entity(high_confidence_match)
    
        # Assert
        if result.final_confidence >= 0.95:
>           assert result.early_stopped is True
E           AssertionError: assert <Mock name='mock.screen_entity().early_stopped' id='6103098304'> is True
E            +  where <Mock name='mock.screen_entity().early_stopped' id='6103098304'> = <Mock name='mock.screen_entity()' id='6103099648'>.early_stopped

tests/e2e/test_sanctions_screening_pipeline.py:207: AssertionError
________ TestSanctionsScreeningPipelineE2E.test_performance_under_load _________

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13f84d040>
screening_pipeline = <AsyncMock id='6103436656'>

    async def test_performance_under_load(self, screening_pipeline):
        """Test E2E performance under concurrent load"""
        # Arrange
        test_entities = [
            "Petro Poroshenko",
            "Volodymyr Zelenskyy",
            "John Smith",
            "Maria Gonzalez",
            "Test Name",  # Chinese characters
            "Mohammed Ali"  # Arabic characters
        ]
    
        # Act - Process concurrently
        tasks = [
            screening_pipeline.screen_entity(entity)
            for entity in test_entities
        ]
        results = await asyncio.gather(*tasks)
    
        # Assert
        assert len(results) == len(test_entities)
    
        for i, result in enumerate(results):
>           assert result.input_text == test_entities[i]
E           AssertionError: assert <Mock name='mock.screen_entity().input_text' id='6103438336'> == 'Petro Poroshenko'
E            +  where <Mock name='mock.screen_entity().input_text' id='6103438336'> = <Mock name='mock.screen_entity()' id='6103437328'>.input_text

tests/e2e/test_sanctions_screening_pipeline.py:259: AssertionError
_______ TestSanctionsScreeningPipelineE2E.test_audit_trail_completeness ________

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13fa32430>
screening_pipeline = <AsyncMock id='6103443712'>

    async def test_audit_trail_completeness(self, screening_pipeline):
        """Test E2E audit trail completeness"""
        # Arrange
        test_entity = "Audit Trail Test"
    
        # Act
        result = await screening_pipeline.screen_entity(test_entity)
    
        # Assert
        assert 'tiers' in result.audit_trail
>       assert 'start_time' in result.audit_trail
E       AssertionError: assert 'start_time' in {'tiers': ['tier1', 'tier2']}
E        +  where {'tiers': ['tier1', 'tier2']} = <Mock name='mock.screen_entity()' id='6103444384'>.audit_trail

tests/e2e/test_sanctions_screening_pipeline.py:294: AssertionError
_____ TestSanctionsScreeningPipelineE2E.test_screening_metrics_collection ______

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13f8bdb50>
screening_pipeline = <AsyncMock id='6103763664'>

    def test_screening_metrics_collection(self, screening_pipeline):
        """Test E2E metrics collection"""
        # Act
        metrics = screening_pipeline.get_screening_metrics()
    
        # Assert
>       assert 'total_screenings' in metrics
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: argument of type 'coroutine' is not iterable

tests/e2e/test_sanctions_screening_pipeline.py:337: TypeError
__ TestSanctionsScreeningPipelineE2E.test_sanctions_data_format_compatibility __

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningPipelineE2E object at 0x13fa49ff0>
screening_pipeline = <AsyncMock id='6103095616'>

    async def test_sanctions_data_format_compatibility(self, screening_pipeline):
        """Test E2E compatibility with actual sanctions data format"""
        # Arrange - Simulate real sanctions data structure
        sanctions_entity = {
            'name': 'Test Entity',
            'name_en': 'Test Entity',
            'name_ru': 'Test Entity',
            'entity_type': 'PERSON',
            'birthdate': '1970-01-01',
            'itn': '1234567890',
            'status': 'ACTIVE',
            'source': 'TEST_SANCTIONS_LIST'
        }
    
        # Act
        result = await screening_pipeline.screen_entity(
            sanctions_entity['name'],
            entity_metadata=sanctions_entity
        )
    
        # Assert
>       assert result.input_text == sanctions_entity['name']
E       AssertionError: assert <Mock name='mock.screen_entity().input_text' id='6103766016'> == 'Test Entity'
E        +  where <Mock name='mock.screen_entity().input_text' id='6103766016'> = <Mock name='mock.screen_entity()' id='6103097296'>.input_text

tests/e2e/test_sanctions_screening_pipeline.py:387: AssertionError
_____ TestSanctionsScreeningRobustness.test_extremely_long_input_handling ______

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningRobustness object at 0x13f89b110>
robust_screening_pipeline = <Mock id='6103768032'>

    async def test_extremely_long_input_handling(self, robust_screening_pipeline):
        """Test handling of extremely long input text"""
        # Arrange
        very_long_text = "Test " * 10000  # 50k+ characters
    
        # Act
>       result = await robust_screening_pipeline.screen_entity(very_long_text)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: object Mock can't be used in 'await' expression

tests/e2e/test_sanctions_screening_pipeline.py:430: TypeError
___________ TestSanctionsScreeningRobustness.test_unicode_edge_cases ___________

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningRobustness object at 0x13f89b250>
robust_screening_pipeline = <Mock id='6103446400'>

    async def test_unicode_edge_cases(self, robust_screening_pipeline):
        """Test Unicode edge cases and special characters"""
        # Arrange
        unicode_test_cases = [
            "Test Name",  # Emoji
            "Test\u0000Name",      # Null character
            "Test\u200eName",      # Left-to-right mark
            "Hebrew Name Arabic",   # Mixed RTL/LTR
            "Test\U0001F4A9Name"   # 4-byte Unicode
        ]
    
        # Act & Assert
        for test_case in unicode_test_cases:
>           result = await robust_screening_pipeline.screen_entity(test_case)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           TypeError: object Mock can't be used in 'await' expression

tests/e2e/test_sanctions_screening_pipeline.py:450: TypeError
______ TestSanctionsScreeningRobustness.test_concurrent_screening_stress _______

self = <tests.e2e.test_sanctions_screening_pipeline.TestSanctionsScreeningRobustness object at 0x13fa248a0>
robust_screening_pipeline = <Mock id='6103094608'>

    async def test_concurrent_screening_stress(self, robust_screening_pipeline):
        """Test concurrent screening under stress conditions"""
        # Arrange
        num_concurrent = 50
        test_entities = [f"Concurrent Test {i}" for i in range(num_concurrent)]
    
        # Act
        start_time = asyncio.get_event_loop().time()
        tasks = [
            robust_screening_pipeline.screen_entity(entity)
            for entity in test_entities
        ]
>       results = await asyncio.gather(*tasks, return_exceptions=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/e2e/test_sanctions_screening_pipeline.py:467: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

return_exceptions = True
coros_or_futures = (<Mock name='mock.screen_entity()' id='6103094272'>, <Mock name='mock.screen_entity()' id='6103094272'>, <Mock name='m...3094272'>, <Mock name='mock.screen_entity()' id='6103094272'>, <Mock name='mock.screen_entity()' id='6103094272'>, ...)
loop = None
_done_callback = <function gather.<locals>._done_callback at 0x16bc13d80>

    def gather(*coros_or_futures, return_exceptions=False):
        """Return a future aggregating results from the given coroutines/futures.
    
        Coroutines will be wrapped in a future and scheduled in the event
        loop. They will not necessarily be scheduled in the same order as
        passed in.
    
        All futures must share the same event loop.  If all the tasks are
        done successfully, the returned future's result is the list of
        results (in the order of the original sequence, not necessarily
        the order of results arrival).  If *return_exceptions* is True,
        exceptions in the tasks are treated the same as successful
        results, and gathered in the result list; otherwise, the first
        raised exception will be immediately propagated to the returned
        future.
    
        Cancellation: if the outer Future is cancelled, all children (that
        have not completed yet) are also cancelled.  If any child is
        cancelled, this is treated as if it raised CancelledError --
        the outer Future is *not* cancelled in this case.  (This is to
        prevent the cancellation of one child to cause other children to
        be cancelled.)
    
        If *return_exceptions* is False, cancelling gather() after it
        has been marked done won't cancel any submitted awaitables.
        For instance, gather can be marked done after propagating an
        exception to the caller, therefore, calling ``gather.cancel()``
        after catching an exception (raised by one of the awaitables) from
        gather won't cancel any other awaitables.
        """
        if not coros_or_futures:
            loop = events.get_event_loop()
            outer = loop.create_future()
            outer.set_result([])
            return outer
    
        def _done_callback(fut):
            nonlocal nfinished
            nfinished += 1
    
            if outer is None or outer.done():
                if not fut.cancelled():
                    # Mark exception retrieved.
                    fut.exception()
                return
    
            if not return_exceptions:
                if fut.cancelled():
                    # Check if 'fut' is cancelled first, as
                    # 'fut.exception()' will *raise* a CancelledError
                    # instead of returning it.
                    exc = fut._make_cancelled_error()
                    outer.set_exception(exc)
                    return
                else:
                    exc = fut.exception()
                    if exc is not None:
                        outer.set_exception(exc)
                        return
    
            if nfinished == nfuts:
                # All futures are done; create a list of results
                # and set it to the 'outer' future.
                results = []
    
                for fut in children:
                    if fut.cancelled():
                        # Check if 'fut' is cancelled first, as 'fut.exception()'
                        # will *raise* a CancelledError instead of returning it.
                        # Also, since we're adding the exception return value
                        # to 'results' instead of raising it, don't bother
                        # setting __context__.  This also lets us preserve
                        # calling '_make_cancelled_error()' at most once.
                        res = exceptions.CancelledError(
                            '' if fut._cancel_message is None else
                            fut._cancel_message)
                    else:
                        res = fut.exception()
                        if res is None:
                            res = fut.result()
                    results.append(res)
    
                if outer._cancel_requested:
                    # If gather is being cancelled we must propagate the
                    # cancellation regardless of *return_exceptions* argument.
                    # See issue 32684.
                    exc = fut._make_cancelled_error()
                    outer.set_exception(exc)
                else:
                    outer.set_result(results)
    
        arg_to_fut = {}
        children = []
        nfuts = 0
        nfinished = 0
        done_futs = []
        loop = None
        outer = None  # bpo-46672
        for arg in coros_or_futures:
            if arg not in arg_to_fut:
>               fut = ensure_future(arg, loop=loop)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:884: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

coro_or_future = <Mock name='mock.screen_entity()' id='6103094272'>

    def ensure_future(coro_or_future, *, loop=None):
        """Wrap a coroutine or an awaitable in a future.
    
        If the argument is a Future, it is returned directly.
        """
        if futures.isfuture(coro_or_future):
            if loop is not None and loop is not futures._get_loop(coro_or_future):
                raise ValueError('The future belongs to a different loop than '
                                'the one specified as the loop argument')
            return coro_or_future
        should_close = True
        if not coroutines.iscoroutine(coro_or_future):
            if inspect.isawaitable(coro_or_future):
                async def _wrap_awaitable(awaitable):
                    return await awaitable
    
                coro_or_future = _wrap_awaitable(coro_or_future)
                should_close = False
            else:
>               raise TypeError('An asyncio.Future, a coroutine or an awaitable '
                                'is required')
E               TypeError: An asyncio.Future, a coroutine or an awaitable is required

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:742: TypeError
___________ TestE2ESanctionsScreening.test_golden_dataset_stability ____________

self = <tests.integration.test_e2e_sanctions_screening.TestE2ESanctionsScreening object at 0x13fa14750>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x16bbc12b0>

    @pytest.mark.asyncio
    async def test_golden_dataset_stability(self, orchestrator):
        """
        –¢–µ—Å—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –∑–æ–ª–æ—Ç–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–º–∏ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏
        """
        golden_cases = [
            {
                "text": "–ò–≤–∞–Ω–æ–≤ –°–µ—Ä–≥–µ–π –ü–µ—Ç—Ä–æ–≤–∏—á –¥.—Ä. 15.03.1985",
                "expected_persons": 1,
                "expected_normalized": "–ò–≤–∞–Ω–æ–≤ –°–µ—Ä–≥–µ–π –ü–µ—Ç—Ä–æ–≤–∏—á",
                "expected_language": "ru",
                "expected_dates": 1
            },
            {
                "text": '–û–û–û "–†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞" –ò–ù–ù 7701123456',
                "expected_organizations": 1,
                "expected_legal_form": "–û–û–û",
                "expected_language": "ru",
                "expected_inn": "7701123456"
            },
            {
                "text": "John Smith, born 1985-03-15",
                "expected_persons": 1,
                "expected_language": "en",
                "expected_dates": 1
            }
        ]
    
        for case in golden_cases:
            result = await orchestrator.process(
                text=case["text"],
                remove_stop_words=True,
                preserve_names=True,
                enable_advanced_features=True
            )
    
            assert result.success is True
            assert result.language == case["expected_language"]
    
            if "expected_persons" in case:
                assert len(result.signals.persons) >= case["expected_persons"]
    
            if "expected_organizations" in case:
                assert len(result.signals.organizations) >= case["expected_organizations"]
    
            if "expected_legal_form" in case:
                org = result.signals.organizations[0]
>               assert org.legal_form == case["expected_legal_form"]
E               AssertionError: assert None == '–û–û–û'
E                +  where None = <ai_service.layers.signals.signals_service.OrgObj object at 0x16bbc3e00>.legal_form

tests/integration/test_e2e_sanctions_screening.py:395: AssertionError
_ test_ukrainian_full_normalization[\u0414\u043b\u044f \u0416\u0435\u043d\u0456 \u0413\u0430\u043b\u0438\u0447\u0430 \u0437 \u0433\u0440\u0443\u043f\u0438 O.Torvald-\u0404\u0432\u0433\u0435\u043d \u0413\u0430\u043b\u0438\u0447] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16cb4f020>
input_text = '–î–ª—è –ñ–µ–Ω—ñ –ì–∞–ª–∏—á–∞ –∑ –≥—Ä—É–ø–∏ O.Torvald', expected_name = '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á –ó.', tokens=['–Ñ–≤–≥–µ–Ω', '–ì–∞–ª–∏—á', '–ó.'], trace=[TokenTrace(token='–ñ–µ–Ω—ñ', role...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–≥–∞–ª–∏—á', '—î–≤–≥–µ–Ω'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–∑.', '–≥–∞–ª–∏—á', '—î–≤–≥–µ–Ω'}
E       assert {'–≥–∞–ª–∏—á', '—î–≤–≥–µ–Ω'} == {'–≥–∞–ª–∏—á', '–∑.', '—î–≤–≥–µ–Ω'}
E         
E         Extra items in the right set:
E         '–∑.'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_ukrainian_full_normalization[\u0417\u0443\u0441\u0442\u0440\u0456\u0447 \u0437 \u041b\u0456\u043d\u043e\u044e \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e-\u041b\u0456\u043d\u0430 \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16bcf8e50>
input_text = '–ó—É—Å—Ç—Ä—ñ—á –∑ –õ—ñ–Ω–æ—é –ö–æ—Å—Ç–µ–Ω–∫–æ', expected_name = '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ó. –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ', tokens=['–ó.', '–õ—ñ–Ω–∞', '–ö–æ—Å—Ç–µ–Ω–∫–æ'], trace=[TokenTrace(token='–∑', rol...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–∫–æ—Å—Ç–µ–Ω–∫–æ', '–ª—ñ–Ω–∞'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–∫–æ—Å—Ç–µ–Ω–∫–æ', '–∑.', '–ª—ñ–Ω–∞'}
E       assert {'–∫–æ—Å—Ç–µ–Ω–∫–æ', '–ª—ñ–Ω–∞'} == {'–∑.', '–∫–æ—Å—Ç–µ–Ω–∫–æ', '–ª—ñ–Ω–∞'}
E         
E         Extra items in the right set:
E         '–∑.'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_ukrainian_full_normalization[\u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0432 \u0437 \u0412\u0430\u043b\u0435\u0440\u0456\u0454\u043c \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u043c-\u0412\u0430\u043b\u0435\u0440\u0456\u0439 \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u0439] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x306eff890>
input_text = '–†–æ–∑–º–æ–≤–ª—è–≤ –∑ –í–∞–ª–µ—Ä—ñ—î–º –ó–∞–ª—É–∂–Ω–∏–º', expected_name = '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ó. –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π', tokens=['–ó.', '–í–∞–ª–µ—Ä—ñ–π', '–ó–∞–ª—É–∂–Ω–∏–π'], trace=[TokenTrace(token='–∑...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–∑–∞–ª—É–∂–Ω–∏–π', '–≤–∞–ª–µ—Ä—ñ–π'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–≤–∞–ª–µ—Ä—ñ–π', '–∑–∞–ª—É–∂–Ω–∏–π', '–∑.'}
E       assert {'–≤–∞–ª–µ—Ä—ñ–π', '–∑–∞–ª—É–∂–Ω–∏–π'} == {'–≤–∞–ª–µ—Ä—ñ–π', '–∑.', '–∑–∞–ª—É–∂–Ω–∏–π'}
E         
E         Extra items in the right set:
E         '–∑.'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_russian_full_normalization[\u0414\u043b\u044f \u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x345f21d30>
input_text = '–î–ª—è –ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω—ã –ü—É–≥–∞—á–µ–≤–æ–π'
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤', tokens=['–ê–ª–ª—ã', '–ë–æ—Ä–∏—Å–æ–≤–Ω', '–ü—É–≥–∞—á–µ–≤'], trace=[TokenTrace(toke...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–ø—É–≥–∞—á–µ–≤–∞', '–∞–ª–ª–∞', '–±–æ—Ä–∏—Å–æ–≤–Ω–∞'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–ø—É–≥–∞—á–µ–≤', '–∞–ª–ª—ã', '–±–æ—Ä–∏—Å–æ–≤–Ω'}
E       assert {'–∞–ª–ª–∞', '–±–æ—Ä...', '–ø—É–≥–∞—á–µ–≤–∞'} == {'–∞–ª–ª—ã', '–±–æ—Ä...–Ω', '–ø—É–≥–∞—á–µ–≤'}
E         
E         Extra items in the left set:
E         '–ø—É–≥–∞—á–µ–≤–∞'
E         '–∞–ª–ª–∞'
E         '–±–æ—Ä–∏—Å–æ–≤–Ω–∞'
E         Extra items in the right set:
E         '–ø—É–≥–∞—á–µ–≤'...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_russian_full_normalization[\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c \u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x306225860>
input_text = '–ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –ü–µ—Ç—Ä—É –ß–∞–π–∫–æ–≤—Å–∫–æ–º—É'
expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º', tokens=['–ü–µ—Ç—Ä', '–ß–∞–π–∫–æ–≤—Å–∫–æ–º'], trace=[TokenTrace(token='–ü–µ—Ç—Ä—É', role...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'—á–∞–π–∫–æ–≤—Å–∫–∏–π', '–ø–µ—Ç—Ä'}, –ø–æ–ª—É—á–µ–Ω–æ: {'—á–∞–π–∫–æ–≤—Å–∫–æ–º', '–ø–µ—Ç—Ä'}
E       assert {'–ø–µ—Ç—Ä', '—á–∞–π–∫–æ–≤—Å–∫–∏–π'} == {'–ø–µ—Ç—Ä', '—á–∞–π–∫–æ–≤—Å–∫–æ–º'}
E         
E         Extra items in the left set:
E         '—á–∞–π–∫–æ–≤—Å–∫–∏–π'
E         Extra items in the right set:
E         '—á–∞–π–∫–æ–≤—Å–∫–æ–º'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_russian_full_normalization[\u0412\u0441\u0442\u0440\u0435\u0447\u0430 \u0441 \u0410\u043d\u043d\u043e\u0439 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u043e\u0439-\u0410\u043d\u043d\u0430 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u0430] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x306ecddb0>
input_text = '–í—Å—Ç—Ä–µ—á–∞ —Å –ê–Ω–Ω–æ–π –ê—Ö–º–∞—Ç–æ–≤–æ–π', expected_name = '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–°. –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞', tokens=['–°.', '–ê–Ω–Ω–∞', '–ê—Ö–º–∞—Ç–æ–≤–∞'], trace=[TokenTrace(token='—Å', rol...re_female': 5, 'score_male': 0, 'gap': 5}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–∞—Ö–º–∞—Ç–æ–≤–∞', '–∞–Ω–Ω–∞'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–∞—Ö–º–∞—Ç–æ–≤–∞', '—Å.', '–∞–Ω–Ω–∞'}
E       assert {'–∞–Ω–Ω–∞', '–∞—Ö–º–∞—Ç–æ–≤–∞'} == {'–∞–Ω–Ω–∞', '–∞—Ö–º–∞—Ç–æ–≤–∞', '—Å.'}
E         
E         Extra items in the right set:
E         '—Å.'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
___ test_english_full_normalization[Sent to ELON MUSK for X corp-Elon Musk] ____

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30620b350>
input_text = 'Sent to ELON MUSK for X corp', expected_name = 'Elon Musk'

    @pytest.mark.parametrize("input_text, expected_name", english_test_cases)
    def test_english_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="en")
>       assert_normalized_name(result, expected_name)

tests/integration/test_full_normalization_suite.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='Elon Musk X', tokens=['Elon', 'Musk', 'X'], trace=[TokenTrace(token='ELON', role='give...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = 'Elon Musk'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'elon', 'musk'}, –ø–æ–ª—É—á–µ–Ω–æ: {'x', 'elon', 'musk'}
E       assert {'elon', 'musk'} == {'elon', 'musk', 'x'}
E         
E         Extra items in the right set:
E         'x'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_____________________ test_critical_russian_normalization ______________________

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16e0cf0d0>

    def test_critical_russian_normalization(normalization_service):
        """–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç: –°–µ—Ä–≥–µ—è –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞ –ü–µ—Ç—Ä–æ–≤–∞ -> –°–µ—Ä–≥–µ–π –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á –ü–µ—Ç—Ä–æ–≤"""
        input_text = "–ü–ª–∞—Ç–µ–∂ –≤ –ø–æ–ª—å–∑—É –°–µ—Ä–≥–µ—è –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞ –ü–µ—Ç—Ä–æ–≤–∞"
        result = normalization_service.normalize(input_text, language="ru", remove_stop_words=True)
    
        # –°—Ç—Ä–æ–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        assert result.success, f"Normalization failed: {result.errors}"
        assert result.tokens, "No tokens returned"
    
        tokens_lower = {token.lower() for token in result.tokens}
        expected_tokens = {"—Å–µ—Ä–≥–µ–π", "–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á", "–ø–µ—Ç—Ä–æ–≤"}
    
>       assert tokens_lower == expected_tokens, f"Expected {expected_tokens}, but got {tokens_lower}"
E       AssertionError: Expected {'—Å–µ—Ä–≥–µ–π', '–ø–µ—Ç—Ä–æ–≤', '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á'}, but got {'–ø–µ—Ç—Ä–æ–≤', '–≤.', '—Å–µ—Ä–≥–µ–π', '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á'}
E       assert {'–≤.', '–≤–ª–∞–¥–∏...–æ–≤', '—Å–µ—Ä–≥–µ–π'} == {'–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏...–æ–≤', '—Å–µ—Ä–≥–µ–π'}
E         
E         Extra items in the left set:
E         '–≤.'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:160: AssertionError
__ TestGenderAdjustmentIntegration.test_ukrainian_female_name_with_patronymic __

self = <tests.integration.test_gender_adjustment.TestGenderAdjustmentIntegration object at 0x13fab07d0>

    def test_ukrainian_female_name_with_patronymic(self):
        """Test Ukrainian female name with patronymic - should adjust surname to feminine."""
        text = "–æ–ø–ª–∞—Ç–∞ –∑–∞ –∫–æ–º—É–Ω–∞–ª—å–Ω—ñ –ø–æ—Å–ª—É–≥–∏ –ü–∞–≤–ª–æ–≤–æ—ó –î–∞—Ä º—ó –Æ—Ä—ñ—ó–≤–Ω–∏"
        result = self.service.normalize_sync(text)
    
        assert result.success
        assert len(result.persons) == 1
    
        person = result.persons[0]
        # Note: –î–∞—Ä º—è is not in Ukrainian names dictionary, so it's tagged as surname
>       assert person["tokens"] == ["–ü–∞–≤–ª–æ–≤", "–î–∞—Ä º—è", "–Æ—Ä—ñ—ó–≤–Ω–∞"]
E       AssertionError: assert ['–ü–∞–≤–ª–æ–≤', '–î–∞—Ä º—ó', '–Æ—Ä—ñ—ó–≤–Ω–∞'] == ['–ü–∞–≤–ª–æ–≤', '–î–∞—Ä º—è', '–Æ—Ä—ñ—ó–≤–Ω–∞']
E         
E         At index 1 diff: '–î–∞—Ä º—ó' != '–î–∞—Ä º—è'
E         Use -v to get more diff

tests/integration/test_gender_adjustment.py:32: AssertionError
_ TestUnicodeFirstLanguageDetectionOrder.test_unicode_normalization_before_language_detection _

self = <tests.integration.test_lang_order_unicode_first.TestUnicodeFirstLanguageDetectionOrder object at 0x13fab0e10>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x30ac71e10>

    def test_unicode_normalization_before_language_detection(self, orchestrator):
        """
        Test that Unicode normalization is called before language detection
        """
        # Test text with mixed Unicode forms and accents
        test_text = "–ü–ª–∞—Ç–µ–∂ –ò–≤–∞–Ω–æ–≤—É"  # Russian text
    
        # Mock unicode service to return normalized text
        unicode_result = {
            "normalized": "–ü–ª–∞—Ç–µ–∂ –ò–≤–∞–Ω–æ–≤—É",  # Normalized version
            "confidence": 0.95,
            "changes_count": 0,
            "char_replacements": 0
        }
        async def mock_normalize_unicode(text):
            return unicode_result
    
        orchestrator.unicode_service.normalize_unicode = Mock(side_effect=mock_normalize_unicode)
    
        # Mock language service to return detection result
        lang_result = {
            "language": "ru",
            "confidence": 0.8,
            "method": "config_driven"
        }
        orchestrator.language_service.detect_language = Mock(return_value=lang_result)
    
        # Mock other services
        async def mock_validate_and_sanitize(text):
            return {
                "sanitized_text": test_text,
                "is_valid": True,
                "should_process": True,
                "errors": []
            }
    
        orchestrator.validation_service.validate_and_sanitize = Mock(side_effect=mock_validate_and_sanitize)
    
        async def mock_normalize_async(text, **kwargs):
            return Mock(
                success=True,
                tokens=["–ø–ª–∞—Ç–µ–∂", "–∏–≤–∞–Ω–æ–≤—É"],
                confidence=0.9
            )
    
        orchestrator.normalization_service.normalize_async = Mock(side_effect=mock_normalize_async)
    
        async def mock_extract_async(text, normalization_result):
            return Mock(
                confidence=0.8,
                persons=[],
                organizations=[]
            )
    
        orchestrator.signals_service.extract_async = Mock(side_effect=mock_extract_async)
    
        # Run the orchestrator
        import asyncio
        result = asyncio.run(orchestrator.process(test_text))
    
        # Verify unicode normalization was called first
>       orchestrator.unicode_service.normalize_unicode.assert_called_once_with(test_text)

tests/integration/test_lang_order_unicode_first.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock name='mock.normalize_unicode' id='13066107072'>
args = ('–ü–ª–∞—Ç–µ–∂ –ò–≤–∞–Ω–æ–≤—É',), kwargs = {}
msg = "Expected 'normalize_unicode' to be called once. Called 0 times."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'normalize_unicode' to be called once. Called 0 times.

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:990: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 290, in process
    signals_result = await self.signals_service.extract_signals(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=context.original_text, normalization_result=norm_result, language=context.language
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_ TestUnicodeFirstLanguageDetectionOrder.test_orchestrator_call_order_verification _

self = <tests.integration.test_lang_order_unicode_first.TestUnicodeFirstLanguageDetectionOrder object at 0x13fae1370>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x309afed50>

    def test_orchestrator_call_order_verification(self, orchestrator):
        """
        Test that orchestrator calls services in the correct order
        """
        test_text = "–ü–ª–∞—Ç–µ–∂ –ò–≤–∞–Ω–æ–≤—É"
    
        # Mock all services
        async def mock_normalize_unicode(text):
            return {
                "normalized": test_text,
                "confidence": 0.95
            }
    
        orchestrator.unicode_service.normalize_unicode = mock_normalize_unicode
    
        orchestrator.language_service.detect_language = Mock(return_value={
            "language": "ru",
            "confidence": 0.8
        })
    
        async def mock_normalize_async(text, **kwargs):
            return Mock(
                success=True,
                tokens=["–ø–ª–∞—Ç–µ–∂", "–∏–≤–∞–Ω–æ–≤—É"],
                confidence=0.9
            )
    
        orchestrator.normalization_service.normalize_async = mock_normalize_async
    
        async def mock_extract_async(text, normalization_result):
            return Mock(
                confidence=0.8,
                persons=[],
                organizations=[]
            )
    
        orchestrator.signals_service.extract_async = mock_extract_async
    
        async def mock_validate_and_sanitize(text):
            return {
                "sanitized_text": test_text,
                "is_valid": True,
                "should_process": True,
                "errors": []
            }
    
        orchestrator.validation_service.validate_and_sanitize = Mock(side_effect=mock_validate_and_sanitize)
    
        # Track call order
        call_order = []
    
        async def track_unicode_call(*args, **kwargs):
            call_order.append("unicode")
            return {
                "normalized": test_text,
                "confidence": 0.95
            }
    
        def track_lang_call(*args, **kwargs):
            call_order.append("language")
            return {
                "language": "ru",
                "confidence": 0.8
            }
    
        orchestrator.unicode_service.normalize_unicode = Mock(side_effect=track_unicode_call)
        orchestrator.language_service.detect_language = Mock(side_effect=track_lang_call)
    
        # Run orchestrator
        import asyncio
        asyncio.run(orchestrator.process(test_text))
    
        # Verify call order
>       assert "unicode" in call_order
E       AssertionError: assert 'unicode' in []

tests/integration/test_lang_order_unicode_first.py:297: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 290, in process
    signals_result = await self.signals_service.extract_signals(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=context.original_text, normalization_result=norm_result, language=context.language
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_________ TestMixedScriptNames.test_ascii_names_with_cyrillic_surnames _________

self = <tests.integration.test_mixed_script_names.TestMixedScriptNames object at 0x13fa27490>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30c2513d0>

    def test_ascii_names_with_cyrillic_surnames(self, service):
        """Test ASCII given names with Cyrillic surnames"""
        text = "John –ö–æ–≤–∞–ª–µ–Ω–∫–æ –∏ Mary –ü–µ—Ç—Ä–æ–≤–∞ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ"
        result = service._normalize_sync(text, language="uk")
    
        # Check that all names are preserved
        assert "John" in result.normalized
        assert "–ö–æ–≤–∞–ª–µ–Ω–∫–æ" in result.normalized
        assert "Mary" in result.normalized
>       assert "–ü–µ—Ç—Ä–æ–≤–∞" in result.normalized
E       AssertionError: assert '–ü–µ—Ç—Ä–æ–≤–∞' in 'John –ö–æ–≤–∞–ª–µ–Ω–∫–æ Mary –ü–µ—Ç—Ä–æ–≤'
E        +  where 'John –ö–æ–≤–∞–ª–µ–Ω–∫–æ Mary –ü–µ—Ç—Ä–æ–≤' = NormalizationResult(normalized='John –ö–æ–≤–∞–ª–µ–Ω–∫–æ Mary –ü–µ—Ç—Ä–æ–≤', tokens=['John', '–ö–æ–≤–∞–ª–µ–Ω–∫–æ', 'Mary', '–ü–µ—Ç—Ä–æ–≤'], trace=[To...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/integration/test_mixed_script_names.py:66: AssertionError
_____________ TestMixedScriptNames.test_ascii_names_no_morphology ______________

self = <tests.integration.test_mixed_script_names.TestMixedScriptNames object at 0x13fa39b50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30b51e5d0>

    def test_ascii_names_no_morphology(self, service):
        """Test that ASCII names skip morphology"""
        text = "John Smith —Ä–∞–±–æ—Ç–∞–µ—Ç"
        result = service._normalize_sync(text, language="uk")
    
        # Check that ASCII names are not morphed
        john_trace = next(t for t in result.trace if t.token == "John")
        smith_trace = next(t for t in result.trace if t.token == "Smith")
    
        # Should not have morphology-related rules
        assert "morph" not in john_trace.rule.lower()
>       assert "morph" not in smith_trace.rule.lower()
E       AssertionError: assert 'morph' not in 'morph'
E         
E         'morph' is contained here:
E           morph

tests/integration/test_mixed_script_names.py:106: AssertionError
____________ TestNormalizationPipeline.test_ukrainian_name_pipeline ____________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fab1a90>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30f4a1d30>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30f4a1e80>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30ff74c20>

    @pytest.mark.asyncio
    async def test_ukrainian_name_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """
        Full pipeline test for Ukrainian name
        Checks: language detected as uk, Ukrainian morphological forms generated
        """
        # Arrange
        input_text = "–û–ª–µ–Ω–∞ –ü–µ—Ç—Ä—ñ–≤–Ω–∞"
    
        # Act
        # Step 1: Language detection
        language_result = language_detection_service.detect_language(input_text)
        detected_language = language_result['language']
    
        # Step 2: Advanced normalization
        normalization_result = await advanced_normalization_service.normalize_async(
            text=input_text,
            language=detected_language
        )
    
        # Step 3: Variant generation
        variant_result = variant_generation_service.generate_variants(
            text=normalization_result.normalized,
            language=detected_language,
            max_variants=20
        )
    
        # Assert
        # Check language detection
        assert detected_language == 'uk', f"Expected Ukrainian, got {detected_language}"
        assert language_result['confidence'] > 0.5
    
        # Check normalization
>       assert normalization_result['language'] == 'uk'
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:51: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestNormalizationPipeline.test_russian_name_pipeline _____________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fab1590>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30e978fc0>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30d00a990>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30d009e50>

    @pytest.mark.asyncio
    async def test_russian_name_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline test for Russian name"""
        # Arrange
        input_text = "–°–µ—Ä–≥–µ–π –ò–≤–∞–Ω–æ–≤"
    
        # Act
        language_result = language_detection_service.detect_language(input_text)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=input_text,
            language=language_result['language'],
            enable_morphology=True
        )
        variant_result = variant_generation_service.generate_variants(
>           text=normalization_result['normalized'],
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            language=language_result['language']
        )
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:96: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_________ TestNormalizationPipeline.test_mixed_language_text_pipeline __________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fa27820>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30f0e5bf0>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16bfc0a50>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x16e056e90>

    @pytest.mark.asyncio
    async def test_mixed_language_text_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline test for mixed language text"""
        # Arrange
        input_text = "John Smith and –Ü–≤–∞–Ω –ü–µ—Ç—Ä–µ–Ω–∫–æ"
    
        # Act
        language_result = language_detection_service.detect_language(input_text)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=input_text,
            language=language_result['language'],
            enable_morphology=True
        )
    
        # Assert
        # Language can be detected as any, but normalization should work
>       assert normalization_result['language'] in ['en', 'ru', 'uk']
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:125: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____________ TestNormalizationPipeline.test_compound_name_pipeline _____________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fa27950>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30b5b0d50>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x311bac9d0>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x311baf950>

    @pytest.mark.asyncio
    async def test_compound_name_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline test for compound name"""
        # Arrange
        input_text = "–ñ–∞–Ω-–ü–æ–ª—å –°–∞—Ä—Ç—Ä"
    
        # Act
        language_result = language_detection_service.detect_language(input_text)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=input_text,
            language=language_result['language'],
            enable_morphology=True
        )
        variant_result = variant_generation_service.generate_variants(
>           text=normalization_result['normalized'],
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            language=language_result['language']
        )
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:154: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
___________ TestNormalizationPipeline.test_error_resilience_pipeline ___________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fae1130>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x3128e1b70>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x312826780>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x3134ed810>

    @pytest.mark.asyncio
    async def test_error_resilience_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline error resilience test"""
        # Arrange
        problematic_text = "‚àë‚àÇ‚àÜ –¢–µ—Å—Ç ‚àû"
    
        # Act & Assert - should not crash with error
        language_result = language_detection_service.detect_language(problematic_text)
        assert language_result is not None
    
        normalization_result = await advanced_normalization_service.normalize_async(
            text=problematic_text,
            language=language_result['language']
        )
        assert normalization_result is not None
    
        variant_result = variant_generation_service.generate_variants(
>           text=normalization_result['normalized'],
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            language=language_result['language']
        )
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:199: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
______________ TestNormalizationPipeline.test_empty_text_pipeline ______________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fade690>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30c00eed0>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30ff83530>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30dd11130>

    @pytest.mark.asyncio
    async def test_empty_text_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline test with empty text"""
        # Arrange
        empty_text = ""
    
        # Act
        language_result = language_detection_service.detect_language(empty_text)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=empty_text,
            language=language_result['language']
        )
        variant_result = variant_generation_service.generate_variants(
>           text=normalization_result['normalized'],
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            language=language_result['language']
        )
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:217: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestNormalizationPipeline.test_performance_pipeline ______________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fade8b0>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30e32eaf0>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30f4fd8c0>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30f965480>

    @pytest.mark.asyncio
    async def test_performance_pipeline(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Pipeline performance test"""
        # Arrange
        test_names = [
            "–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ",
            "Maria Gonzalez",
            "–°–µ—Ä–≥—ñ–π –Ü–≤–∞–Ω–µ–Ω–∫–æ",
            "John O'Connor",
            "–ê–Ω–Ω–∞-–ú–∞—Ä—ñ—è –ö–æ–≤–∞–ª–µ–Ω–∫–æ"
        ]
    
        # Act
        import time
        start_time = time.time()
    
        results = []
        for name in test_names:
            language_result = language_detection_service.detect_language(name)
            normalization_result = await advanced_normalization_service.normalize_async(
                text=name,
                language=language_result['language'],
                enable_morphology=True
            )
            results.append(normalization_result)
    
        end_time = time.time()
        total_time = end_time - start_time
    
        # Assert
        assert total_time < 10.0, f"Pipeline should complete within 10 seconds, took {total_time:.2f}s"
        assert len(results) == len(test_names)
    
        for result in results:
            assert result is not None
>           assert 'token_variants' in result
E           AssertionError: assert 'token_variants' in NormalizationResult(normalized='–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–µ—Ç—Ä–µ–Ω–∫–æ', tokens=['–û–ª–µ–∫—Å–∞–Ω–¥—Ä', '–ü–µ—Ç—Ä–µ–Ω–∫–æ'], trace=[TokenTrace(token='–û–ª–µ–∫—Å–∞...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')

tests/integration/test_normalization_pipeline.py:262: AssertionError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____________ TestNormalizationPipeline.test_morphology_integration _____________

self = NormalizationResult(normalized='', tokens=[], trace=[], errors=[], language='ru', confidence=1.0, original_length=9, n..._core=[], organizations_core=[], persons=[], person_gender=None, gender_confidence=None, organizations=[], org_core='')
item = 'get'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
>                   return pydantic_extra[item]
                           ^^^^^^^^^^^^^^^^^^^^
E                   KeyError: 'get'

venv/lib/python3.13/site-packages/pydantic/main.py:983: KeyError

The above exception was the direct cause of the following exception:

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13fa16450>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30fd5e8d0>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30e9e1450>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30e9e1050>

    @pytest.mark.asyncio
    async def test_morphology_integration(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Morphological analysis integration test"""
        # Arrange
        ukrainian_name = "–í–æ–ª–æ–¥–∏–º–∏—Ä"
    
        # Act
        language_result = language_detection_service.detect_language(ukrainian_name)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=ukrainian_name,
            language=language_result['language'],
            enable_morphology=True,
            clean_unicode=False  # Preserve Cyrillic text for morphological analysis
        )
    
        # Assert
        # Language detection may vary, so just check that it's one of the supported languages
        assert language_result['language'] in ['uk', 'ru', 'en']
    
        # Check that morphological analysis worked
>       names_analysis = normalization_result.get('names_analysis', [])
                         ^^^^^^^^^^^^^^^^^^^^^^^^

tests/integration/test_normalization_pipeline.py:300: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = NormalizationResult(normalized='', tokens=[], trace=[], errors=[], language='ru', confidence=1.0, original_length=9, n..._core=[], organizations_core=[], persons=[], person_gender=None, gender_confidence=None, organizations=[], org_core='')
item = 'get'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
E                   AttributeError: 'NormalizationResult' object has no attribute 'get'

venv/lib/python3.13/site-packages/pydantic/main.py:985: AttributeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
__________ TestNormalizationPipeline.test_transliteration_integration __________

self = <tests.integration.test_normalization_pipeline.TestNormalizationPipeline object at 0x13f84f5c0>
language_detection_service = <src.ai_service.layers.language.language_detection_service.LanguageDetectionService object at 0x30dd2d850>
advanced_normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x30e9e2e50>
variant_generation_service = <src.ai_service.layers.variants.variant_generation_service.VariantGenerationService object at 0x30e9e3250>

    @pytest.mark.asyncio
    async def test_transliteration_integration(self, language_detection_service, advanced_normalization_service, variant_generation_service):
        """Transliteration integration test"""
        # Arrange
        cyrillic_name = "–°–µ—Ä–≥—ñ–π"
    
        # Act
        language_result = language_detection_service.detect_language(cyrillic_name)
        normalization_result = await advanced_normalization_service.normalize_async(
            text=cyrillic_name,
            language=language_result['language'],
            enable_transliterations=True
        )
    
        # Assert
>       token_variants = normalization_result['token_variants']
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: 'NormalizationResult' object is not subscriptable

tests/integration/test_normalization_pipeline.py:328: TypeError
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_ TestPipelineEnd2End.test_pipeline_integration[ukrainian_company_with_legal_form] _

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fb24640>
test_case = IntegrationTestCase(name='ukrainian_company_with_legal_form', input_text="–¢–û–í '–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫'", expected_language='ru', e...cess=True, expected_trace_roles=[], notes='Company with legal form - legal form handled by Signals, not Normalization')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
        assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
    
        # 4. TokenTrace Validation (per CLAUDE.md requirement)
        if test_case.expected_trace_roles:
            trace_roles = [trace.role for trace in result.trace if hasattr(trace, 'role')]
            assert trace_roles == test_case.expected_trace_roles, \
                f"Expected trace roles {test_case.expected_trace_roles}, got {trace_roles}"
    
        # 5. Signals Layer Tests - Persons
        assert len(result.signals.persons) == len(test_case.expected_persons), \
            f"Expected {len(test_case.expected_persons)} persons, got {len(result.signals.persons)}"
    
        for i, expected_person in enumerate(test_case.expected_persons):
            if i < len(result.signals.persons):
                actual_person = result.signals.persons[i]
                assert actual_person.core == expected_person["core"], \
                    f"Person {i} core mismatch: expected {expected_person['core']}, got {actual_person.core}"
    
                if expected_person["dob"]:
                    assert actual_person.dob == expected_person["dob"], \
                        f"Person {i} DOB mismatch: expected {expected_person['dob']}, got {actual_person.dob}"
    
        # 6. Signals Layer Tests - Organizations
>       assert len(result.signals.organizations) == len(test_case.expected_organizations), \
            f"Expected {len(test_case.expected_organizations)} orgs, got {len(result.signals.organizations)}"
E       AssertionError: Expected 1 orgs, got 0
E       assert 0 == 1
E        +  where 0 = len([])
E        +    where [] = <ai_service.layers.signals.signals_service.SignalsService.extract_signals.<locals>.ResultWrapper object at 0x318534ad0>.organizations
E        +      where <ai_service.layers.signals.signals_service.SignalsService.extract_signals.<locals>.ResultWrapper object at 0x318534ad0> = UnifiedProcessingResult(original_text="–¢–û–í '–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫'", language='ru', language_confidence=0.6, normalized_text='', ...318534ad0>, variants=None, embeddings=None, decision=None, processing_time=0.0017242431640625, success=True, errors=[]).signals
E        +  and   1 = len([{'core': '–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫', 'full_name': '–¢–û–í –ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫', 'legal_form': '–¢–û–í'}])
E        +    where [{'core': '–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫', 'full_name': '–¢–û–í –ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫', 'legal_form': '–¢–û–í'}] = IntegrationTestCase(name='ukrainian_company_with_legal_form', input_text="–¢–û–í '–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫'", expected_language='ru', e...cess=True, expected_trace_roles=[], notes='Company with legal form - legal form handled by Signals, not Normalization').expected_organizations

tests/integration/test_pipeline_end2end.py:374: AssertionError
___ TestPipelineEnd2End.test_pipeline_integration[mixed_person_and_company] ____

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fb24770>
test_case = IntegrationTestCase(name='mixed_person_and_company', input_text="–†–∞—Ö—É–Ω–æ–∫ –≤—ñ–¥ –ü.–Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ, –¢–û–í '–ê–≥—Ä–æ—Å–≤—ñ—Ç'", expected...ce_roles=['initial', 'initial', 'surname'], notes='Mixed person with initials and company - proper initial formatting')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
>       assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
E       AssertionError: Expected normalized '–ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ', got '–ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–≥—Ä–æ—Å–≤—ñ—Ç'
E       assert '–ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–≥—Ä–æ—Å–≤—ñ—Ç' == '–ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ'
E         
E         - –ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ
E         + –ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–≥—Ä–æ—Å–≤—ñ—Ç
E         ?                +++++++++

tests/integration/test_pipeline_end2end.py:350: AssertionError
________ TestPipelineEnd2End.test_pipeline_integration[person_with_inn] ________

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fadf130>
test_case = IntegrationTestCase(name='person_with_inn', input_text='–ü–ª–∞—Ç–µ–∂ –ò–≤–∞–Ω–æ–≤—É –ü.–°., –Ü–ü–ù 1234567890', expected_language='uk', ...e, expected_trace_roles=['initial', 'initial', 'surname'], notes='Person with INN - signals should extract identifier')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
>       assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
E       AssertionError: Expected normalized '–ü. –°. –Ü–≤–∞–Ω–æ–≤', got '–ò–≤–∞–Ω–æ–≤ –ü. –°.'
E       assert '–ò–≤–∞–Ω–æ–≤ –ü. –°.' == '–ü. –°. –Ü–≤–∞–Ω–æ–≤'
E         
E         - –ü. –°. –Ü–≤–∞–Ω–æ–≤
E         + –ò–≤–∞–Ω–æ–≤ –ü. –°.

tests/integration/test_pipeline_end2end.py:350: AssertionError
______ TestPipelineEnd2End.test_pipeline_integration[mixed_script_names] _______

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fadf350>
test_case = IntegrationTestCase(name='mixed_script_names', input_text='Payment for John Smith and –û–ª–µ–Ω–∞ –ü–µ—Ç—Ä–µ–Ω–∫–æ', expected_langua...['given', 'surname', 'given', 'surname'], notes='Mixed script - ASCII names in Cyrillic context should not be morphed')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
>       assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
E       AssertionError: Expected normalized 'John Smith –û–ª–µ–Ω–∞ –ü–µ—Ç—Ä–µ–Ω–∫–æ', got 'John Smith'
E       assert 'John Smith' == 'John Smith –û–ª–µ–Ω–∞ –ü–µ—Ç—Ä–µ–Ω–∫–æ'
E         
E         - John Smith –û–ª–µ–Ω–∞ –ü–µ—Ç—Ä–µ–Ω–∫–æ
E         + John Smith

tests/integration/test_pipeline_end2end.py:350: AssertionError
__ TestPipelineEnd2End.test_pipeline_integration[quoted_company_with_person] ___

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fa17450>
test_case = IntegrationTestCase(name='quoted_company_with_person', input_text="–û–û–û '–¢–µ—Å—Ç –°–∏—Å—Ç–µ–º—Å' –ø–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –ò–≤–∞–Ω—É –ü–µ—Ç—Ä–æ–≤—É", ...ected_should_process=True, expected_trace_roles=['given', 'surname'], notes='Quoted company name with person transfer')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
>       assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
E       AssertionError: Language confidence 0.75 below minimum 0.8
E       assert 0.75 >= 0.8
E        +  where 0.75 = UnifiedProcessingResult(original_text="–û–û–û '–¢–µ—Å—Ç –°–∏—Å—Ç–µ–º—Å' –ø–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –ò–≤–∞–Ω—É –ü–µ—Ç—Ä–æ–≤—É", language='ru', language_conf...349ef90>, variants=None, embeddings=None, decision=None, processing_time=0.007681131362915039, success=True, errors=[]).language_confidence
E        +  and   0.8 = IntegrationTestCase(name='quoted_company_with_person', input_text="–û–û–û '–¢–µ—Å—Ç –°–∏—Å—Ç–µ–º—Å' –ø–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –ò–≤–∞–Ω—É –ü–µ—Ç—Ä–æ–≤—É", ...ected_should_process=True, expected_trace_roles=['given', 'surname'], notes='Quoted company name with person transfer').expected_language_confidence_min

tests/integration/test_pipeline_end2end.py:338: AssertionError
______ TestPipelineEnd2End.test_pipeline_integration[hyphenated_surname] _______

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fb40230>
test_case = IntegrationTestCase(name='hyphenated_surname', input_text='–ü–ª–∞—Ç–µ–∂ –¥–ª—è –ú–∞—Ä—ñ—ó –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–æ—ó-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ', expected_languag...ocess=True, expected_trace_roles=['given', 'surname'], notes='Hyphenated surname - preserve_names should keep hyphens')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
>       assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
E       AssertionError: Expected normalized '–ú–∞—Ä—ñ—è –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–∞-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ', got '–ú–∞—Ä—ñ—ó –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–∏–π-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ'
E       assert '–ú–∞—Ä—ñ—ó –ö–æ—Ü—é–±–∏...–∏–π-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ' == '–ú–∞—Ä—ñ—è –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–∞-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ'
E         
E         - –ú–∞—Ä—ñ—è –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–∞-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ
E         ?     ^           ^
E         + –ú–∞—Ä—ñ—ó –ö–æ—Ü—é–±–∏–Ω—Å—å–∫–∏–π-–ì–æ–Ω—á–∞—Ä–µ–Ω–∫–æ
E         ?     ^           ^^

tests/integration/test_pipeline_end2end.py:350: AssertionError
________ TestPipelineEnd2End.test_pipeline_integration[overfit_canary] _________

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fb40320>
test_case = IntegrationTestCase(name='overfit_canary', input_text='–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞, —Ä–∞—Ö—É–Ω–æ–∫, –¥–∏—Å–ø–ª–µ–π, table', expected_language='uk', e... expected_should_process=False, expected_trace_roles=[], notes='Overfit canary - random words should not become names')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
>       assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
E       AssertionError: Expected language uk, got ru
E       assert 'ru' == 'uk'
E         
E         - uk
E         + ru

tests/integration/test_pipeline_end2end.py:335: AssertionError
___ TestPipelineEnd2End.test_pipeline_integration[full_pipeline_stress_test] ___

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13faf9fd0>
test_case = IntegrationTestCase(name='full_pipeline_stress_test', input_text="–¢–û–í '–ê–≥—Ä–æ—Å–≤—ñ—Ç', –§–û–ü –Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á, –Ü–ü–ù 1234...expected_trace_roles=['surname', 'given', 'patronymic'], notes='Full pipeline stress test - all signals types present')

    @pytest.mark.parametrize("test_case", INTEGRATION_TEST_CASES, ids=lambda tc: tc.name)
    async def test_pipeline_integration(self, test_case: IntegrationTestCase):
        """Test complete pipeline integration with real payment scenarios"""
    
        logger.info(f"Testing: {test_case.name} - {test_case.notes}")
        logger.info(f"Input: {test_case.input_text}")
    
        # Process through unified pipeline
        result = await self.orchestrator.process(
            text=test_case.input_text,
            # Test with production-like settings per CLAUDE.md
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=False,  # Focus on core functionality
            generate_embeddings=False
        )
    
        # Assert processing succeeded
        if test_case.expected_should_process:
            assert result.success, f"Processing should succeed but failed: {result.errors}"
    
        # 1. Language Detection Layer Tests
        assert result.language == test_case.expected_language, \
            f"Expected language {test_case.expected_language}, got {result.language}"
    
        assert result.language_confidence >= test_case.expected_language_confidence_min, \
            f"Language confidence {result.language_confidence} below minimum {test_case.expected_language_confidence_min}"
    
        # 2. Smart Filter Layer Tests
        smart_filter_meta = result.__dict__.get('metadata', {}).get('smart_filter', {})
        if smart_filter_meta:
            detected_signals = smart_filter_meta.get('detected_signals', [])
            for expected_signal in test_case.expected_smart_filter_signals:
                assert expected_signal in detected_signals, \
                    f"Expected smart filter signal '{expected_signal}' not found in {detected_signals}"
    
        # 3. Normalization Layer Tests (THE CORE)
>       assert result.normalized_text == test_case.expected_normalized, \
            f"Expected normalized '{test_case.expected_normalized}', got '{result.normalized_text}'"
E       AssertionError: Expected normalized '–Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á', got '–ê–≥—Ä–æ—Å–≤—ñ—Ç –Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á'
E       assert '–ê–≥—Ä–æ—Å–≤—ñ—Ç –Ü–≤–∞...–Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á' == '–Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á'
E         
E         - –Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á
E         + –ê–≥—Ä–æ—Å–≤—ñ—Ç –Ü–≤–∞–Ω–µ–Ω–∫–æ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á
E         ? +++++++++

tests/integration/test_pipeline_end2end.py:350: AssertionError
____________ TestPipelineEnd2End.test_normalization_flags_behavior _____________

self = <tests.integration.test_pipeline_end2end.TestPipelineEnd2End object at 0x13fa79e10>

    async def test_normalization_flags_behavior(self):
        """Test that normalization flags actually change behavior (CLAUDE.md requirement)"""
    
        test_text = "–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ –∏ –û–û–û –∫–æ–º–ø–∞–Ω–∏—è"
    
        # Test different flag combinations
        flag_combinations = [
            {"remove_stop_words": True, "preserve_names": True, "enable_advanced_features": True},
            {"remove_stop_words": False, "preserve_names": True, "enable_advanced_features": True},
            {"remove_stop_words": True, "preserve_names": False, "enable_advanced_features": True},
            {"remove_stop_words": True, "preserve_names": True, "enable_advanced_features": False},
        ]
    
        results = []
        for flags in flag_combinations:
            result = await self.orchestrator.process(text=test_text, **flags)
            results.append((flags, result.normalized_text, len(result.tokens)))
    
        # Verify flags produce different results
        normalized_results = [r[1] for r in results]
        unique_results = set(normalized_results)
    
>       assert len(unique_results) > 1, \
            f"Flags should produce different results but all were identical: {normalized_results}"
E       AssertionError: Flags should produce different results but all were identical: ['–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ', '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ', '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ', '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ']
E       assert 1 > 1
E        +  where 1 = len({'–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤–∏—á –°–∏–¥–æ—Ä–µ–Ω–∫–æ'})

tests/integration/test_pipeline_end2end.py:413: AssertionError
_ test_role_based_slavic_normalization[\u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430-ru] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x3142e5cd0>
input_text = '–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω—ã –ü—É–≥–∞—á–µ–≤–æ–π'
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞', lang = 'ru'

    @pytest.mark.parametrize("input_text, expected_name, lang", role_based_test_cases)
    def test_role_based_slavic_normalization(normalization_service, input_text, expected_name, lang):
        """
        Tests the new role-based normalization logic with specific cases.
        """
        result = normalization_service.normalize(input_text, language=lang)
>       assert_normalized_name(result, expected_name)

tests/integration/test_role_based_normalization.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤', tokens=['–ê–ª–ª—ã', '–ë–æ—Ä–∏—Å–æ–≤–Ω', '–ü—É–≥–∞—á–µ–≤'], trace=[TokenTrace(toke...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'–ø—É–≥–∞—á–µ–≤–∞', '–∞–ª–ª–∞', '–±–æ—Ä–∏—Å–æ–≤–Ω–∞'}, –ø–æ–ª—É—á–µ–Ω–æ: {'–ø—É–≥–∞—á–µ–≤', '–∞–ª–ª—ã', '–±–æ—Ä–∏—Å–æ–≤–Ω'}
E       assert {'–∞–ª–ª–∞', '–±–æ—Ä...', '–ø—É–≥–∞—á–µ–≤–∞'} == {'–∞–ª–ª—ã', '–±–æ—Ä...–Ω', '–ø—É–≥–∞—á–µ–≤'}
E         
E         Extra items in the left set:
E         '–ø—É–≥–∞—á–µ–≤–∞'
E         '–∞–ª–ª–∞'
E         '–±–æ—Ä–∏—Å–æ–≤–Ω–∞'
E         Extra items in the right set:
E         '–ø—É–≥–∞—á–µ–≤'...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

tests/integration/test_full_normalization_suite.py:38: AssertionError
_ test_role_based_slavic_normalization[\u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439-ru] _

normalization_service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x13fbba0d0>
input_text = '–ü–µ—Ç—Ä—É –ß–∞–π–∫–æ–≤—Å–∫–æ–º—É', expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π', lang = 'ru'

    @pytest.mark.parametrize("input_text, expected_name, lang", role_based_test_cases)
    def test_role_based_slavic_normalization(normalization_service, input_text, expected_name, lang):
        """
        Tests the new role-based normalization logic with specific cases.
        """
        result = normalization_service.normalize(input_text, language=lang)
>       assert_normalized_name(result, expected_name)

tests/integration/test_role_based_normalization.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º', tokens=['–ü–µ—Ç—Ä', '–ß–∞–π–∫–æ–≤—Å–∫–æ–º'], trace=[TokenTrace(token='–ü–µ—Ç—Ä—É', role...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'

    def assert_normalized_name(result, expected_name):
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º –∏–º–µ–Ω–µ–º.
        –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤.
        –¢—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ –Ω–∞–±–æ—Ä—É —Å–ª–æ–≤ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        expected_parts = set(expected_name.lower().split())
    
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        actual_tokens = {token.lower() for token in result.tokens if token.strip()}
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
>       assert expected_parts == actual_tokens, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {expected_parts}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_tokens}"
E       AssertionError: –û–∂–∏–¥–∞–ª–æ—Å—å: {'—á–∞–π–∫–æ–≤—Å–∫–∏–π', '–ø–µ—Ç—Ä'}, –ø–æ–ª—É—á–µ–Ω–æ: {'—á–∞–π–∫–æ–≤—Å–∫–æ–º', '–ø–µ—Ç—Ä'}
E       assert {'–ø–µ—Ç—Ä', '—á–∞–π–∫–æ–≤—Å–∫–∏–π'} == {'–ø–µ—Ç—Ä', '—á–∞–π–∫–æ–≤—Å–∫–æ–º'}
E         
E         Extra items in the left set:
E         '—á–∞–π–∫–æ–≤—Å–∫–∏–π'
E         Extra items in the right set:
E         '—á–∞–π–∫–æ–≤—Å–∫–æ–º'
E         Use -v to get more diff

tests/integration/test_full_normalization_suite.py:38: AssertionError
_______ TestRussianUkrainianSentences.test_multiple_persons_same_surname _______

self = <tests.integration.test_ru_uk_sentences.TestRussianUkrainianSentences object at 0x13fb8c9e0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x31ccdc4d0>

    def test_multiple_persons_same_surname(self, service):
        """Test multiple persons with same surname"""
        text = "–í–ª–∞–¥–∏–º–∏—Ä –∏ –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤—ã —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ"
        result = service._normalize_sync(text, language="ru")
    
        # Check that both names are normalized with correct gender
>       assert "–í–ª–∞–¥–∏–º–∏—Ä –ü–µ—Ç—Ä–æ–≤" in result.normalized
E       AssertionError: assert '–í–ª–∞–¥–∏–º–∏—Ä –ü–µ—Ç—Ä–æ–≤' in '–í–ª–∞–¥–∏–º–∏—Ä –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤'
E        +  where '–í–ª–∞–¥–∏–º–∏—Ä –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤' = NormalizationResult(normalized='–í–ª–∞–¥–∏–º–∏—Ä –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤', tokens=['–í–ª–∞–¥–∏–º–∏—Ä', '–ê–Ω–Ω–∞', '–ü–µ—Ç—Ä–æ–≤'], trace=[TokenTrace(token=...re_female': 3, 'score_male': 2, 'gap': 1}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/integration/test_ru_uk_sentences.py:97: AssertionError
____________ TestRussianUkrainianSentences.test_surname_variations _____________

self = <tests.integration.test_ru_uk_sentences.TestRussianUkrainianSentences object at 0x13fb9b3f0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x31f621050>

    def test_surname_variations(self, service):
        """Test various surname forms"""
        text = "–ü–µ—Ç—Ä–æ–≤, –ü–µ—Ç—Ä–æ–≤–∞, –ü–µ—Ç—Ä–æ–≤—ã–º, –ü–µ—Ç—Ä–æ–≤—É"
        result = service._normalize_sync(text, language="ru")
    
        # Check that surnames are normalized to nominative
        assert "–ü–µ—Ç—Ä–æ–≤" in result.normalized
>       assert "–ü–µ—Ç—Ä–æ–≤–∞" in result.normalized
E       AssertionError: assert '–ü–µ—Ç—Ä–æ–≤–∞' in '–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤'
E        +  where '–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤' = NormalizationResult(normalized='–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ–≤', tokens=['–ü–µ—Ç—Ä–æ–≤', '–ü–µ—Ç—Ä–æ–≤', '–ü–µ—Ç—Ä–æ–≤', '–ü–µ—Ç—Ä–æ–≤'], trace=[...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/integration/test_ru_uk_sentences.py:161: AssertionError
____ TestRussianUkrainianSentences.test_organization_legal_forms_filtering _____

self = <tests.integration.test_ru_uk_sentences.TestRussianUkrainianSentences object at 0x13fb2e690>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x31428df50>

    def test_organization_legal_forms_filtering(self, service):
        """Test that legal forms are filtered out"""
        text = "–¢–û–í '–ü–†–ò–í–ê–¢–ë–ê–ù–ö' –û–û–û '–¢–ï–°–¢' LLC 'EXAMPLE'"
        result = service._normalize_sync(text, language="uk")
    
        # Check that legal forms are not in normalized
        assert "–¢–û–í" not in result.normalized
        assert "–û–û–û" not in result.normalized
        assert "LLC" not in result.normalized
    
        # Check that organization cores are extracted
        assert "–ü–†–ò–í–ê–¢–ë–ê–ù–ö" in result.organizations
        assert "–¢–ï–°–¢" in result.organizations
>       assert "EXAMPLE" in result.organizations
E       AssertionError: assert 'EXAMPLE' in ['–ü–†–ò–í–ê–¢–ë–ê–ù–ö', '–¢–ï–°–¢']
E        +  where ['–ü–†–ò–í–ê–¢–ë–ê–ù–ö', '–¢–ï–°–¢'] = NormalizationResult(normalized='Example', tokens=['Example'], trace=[TokenTrace(token='–ü–†–ò–í–ê–¢–ë–ê–ù–ö', role='org', rule='...p': 0}}], person_gender=None, gender_confidence=None, organizations=['–ü–†–ò–í–ê–¢–ë–ê–ù–ö', '–¢–ï–°–¢'], org_core='–ü–†–ò–í–ê–¢–ë–ê–ù–ö –¢–ï–°–¢').organizations

tests/integration/test_ru_uk_sentences.py:184: AssertionError
________ TestRussianUkrainianSentences.test_performance_with_long_text _________

self = <tests.integration.test_ru_uk_sentences.TestRussianUkrainianSentences object at 0x13fb2e750>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x31b7fee50>

    def test_performance_with_long_text(self, service):
        """Test performance with longer text"""
        text = " ".join([
            "–ü–µ—Ç—Ä –ò–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ", "–ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤–∞",
            "–í–ª–∞–¥–∏–º–∏—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á –ü–µ—Ç—Ä–æ–≤", "–ï–ª–µ–Ω–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞ –ö–æ–∑–ª–æ–≤–∞",
            "–ú–∏—Ö–∞–∏–ª –ù–∏–∫–æ–ª–∞–µ–≤–∏—á –°–º–∏—Ä–Ω–æ–≤", "–û–ª—å–≥–∞ –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–Ω–∞ –ú–æ—Ä–æ–∑–æ–≤–∞"
        ])
    
        result = service._normalize_sync(text, language="ru")
    
        # Check that all names are normalized
        assert "–ü–µ—Ç—Ä –ò–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ" in result.normalized
>       assert "–ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤–∞" in result.normalized
E       AssertionError: assert '–ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤–∞' in '–ü–µ—Ç—Ä –ò–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤ –í–ª–∞–¥–∏–º–∏—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á –ü–µ—Ç—Ä–æ–≤ –ï–ª–µ–Ω–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞ –ö–æ–∑–ª–æ–≤ –ú–∏—Ö–∞–∏–ª –ù–∏–∫–æ–ª–∞–µ–≤–∏—á –°–º–∏—Ä–Ω–æ–≤ –û–ª—å–≥–∞ –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–Ω–∞ –ú–æ—Ä–æ–∑–æ–≤'
E        +  where '–ü–µ—Ç—Ä –ò–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤ –í–ª–∞–¥–∏–º–∏—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á –ü–µ—Ç—Ä–æ–≤ –ï–ª–µ–Ω–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞ –ö–æ–∑–ª–æ–≤ –ú–∏—Ö–∞–∏–ª –ù–∏–∫–æ–ª–∞–µ–≤–∏—á –°–º–∏—Ä–Ω–æ–≤ –û–ª—å–≥–∞ –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–Ω–∞ –ú–æ—Ä–æ–∑–æ–≤' = NormalizationResult(normalized='–ü–µ—Ç—Ä –ò–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ê–Ω–Ω–∞ –ü–µ—Ç—Ä–æ–≤–Ω–∞ –°–∏–¥–æ—Ä–æ–≤ –í–ª–∞–¥–∏–º–∏—Ä –°–µ—Ä–≥–µ–µ–≤–∏—á –ü–µ—Ç—Ä–æ–≤ –ï–ª–µ–Ω–∞ –ê–ª–µ–∫—Å–∞–Ω–¥...female': 18, 'score_male': 28, 'gap': 10}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/integration/test_ru_uk_sentences.py:198: AssertionError
___________ TestUnifiedOrchestrator.test_process_basic_functionality ___________

self = <tests.unit.test_orchestrator_service_fixed.TestUnifiedOrchestrator object at 0x16b752e90>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f229150>

    @pytest.mark.asyncio
    async def test_process_basic_functionality(self, orchestrator_service):
        """Test basic process functionality"""
        # Arrange
        test_text = "Test text"
    
        # Mock all services
        with patch.object(orchestrator_service.validation_service, 'validate_and_sanitize') as mock_validation, \
             patch.object(orchestrator_service.smart_filter_service, 'should_skip') as mock_smart_filter, \
             patch.object(orchestrator_service.language_service, 'detect_language_config_driven') as mock_language, \
             patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.normalization_service, 'normalize') as mock_normalize, \
             patch.object(orchestrator_service.signals_service, 'extract_signals') as mock_signals, \
             patch.object(orchestrator_service.variants_service, 'generate_variants') as mock_variants, \
             patch.object(orchestrator_service.embeddings_service, 'encode') as mock_embeddings, \
             patch.object(orchestrator_service.decision_engine, 'make_decision') as mock_decision:
    
            # Setup mocks
            mock_validation.return_value = {'valid': True, 'errors': []}
            mock_smart_filter.return_value = False  # Don't skip
            mock_language.return_value = Mock(language='en', confidence=0.9)
            mock_unicode.return_value = {'normalized': 'test text'}
    
            # Mock normalization result
            mock_normalize_result = Mock()
            mock_normalize_result.normalized = 'test text'
            mock_normalize_result.tokens = ['test', 'text']
            mock_normalize_result.trace = [TokenTrace(token='test', role='given', rule='capitalize', output='test')]
            mock_normalize_result.success = True
            mock_normalize.return_value = mock_normalize_result
    
            # Mock signals result
            mock_signals_result = Mock()
            mock_signals_result.persons = []
            mock_signals_result.organizations = []
            mock_signals_result.confidence = 0.5
            mock_signals.return_value = mock_signals_result
    
            mock_variants.return_value = ['test text', 'test']
            mock_embeddings.return_value = [0.1] * 384  # 384-dimensional embedding
            mock_decision_result = Mock()
            mock_decision_result.risk_level = 'low'
            mock_decision_result.confidence = 0.8
            mock_decision.return_value = mock_decision_result
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
>           assert result.success is True
E           assert False is True
E            +  where False = UnifiedProcessingResult(original_text='Test text', language='unknown', language_confidence=0.0, normalized_text='', to...=None, processing_time=6.29425048828125e-05, success=False, errors=["object Mock can't be used in 'await' expression"]).success

tests/unit/test_orchestrator_service_fixed.py:98: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_________ TestUnifiedOrchestrator.test_process_with_smart_filter_skip __________

self = <tests.unit.test_orchestrator_service_fixed.TestUnifiedOrchestrator object at 0x16b752d50>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f229ae0>

    @pytest.mark.asyncio
    async def test_process_with_smart_filter_skip(self, orchestrator_service):
        """Test process when smart filter decides to skip"""
        # Arrange
        test_text = "Test text"
    
        with patch.object(orchestrator_service.validation_service, 'validate_text') as mock_validation, \
             patch.object(orchestrator_service.smart_filter_service, 'should_skip') as mock_smart_filter:
    
            mock_validation.return_value = {'valid': True, 'errors': []}
            mock_smart_filter.return_value = True  # Skip processing
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
>           assert result.success is True
E           assert False is True
E            +  where False = UnifiedProcessingResult(original_text='Test text', language='unknown', language_confidence=0.0, normalized_text='', to...None, processing_time=0.0003268718719482422, success=False, errors=["object Mock can't be used in 'await' expression"]).success

tests/unit/test_orchestrator_service_fixed.py:126: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
__________ TestUnifiedOrchestrator.test_process_with_validation_error __________

self = <tests.unit.test_orchestrator_service_fixed.TestUnifiedOrchestrator object at 0x16b75a520>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f22a470>

    @pytest.mark.asyncio
    async def test_process_with_validation_error(self, orchestrator_service):
        """Test process with validation error"""
        # Arrange
        test_text = "Invalid text"
    
        with patch.object(orchestrator_service.validation_service, 'validate_text') as mock_validation:
            mock_validation.return_value = {'valid': False, 'errors': ['Invalid input']}
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
            assert result.success is False
>           assert 'Invalid input' in result.errors
E           assert 'Invalid input' in ["object Mock can't be used in 'await' expression"]
E            +  where ["object Mock can't be used in 'await' expression"] = UnifiedProcessingResult(original_text='Invalid text', language='unknown', language_confidence=0.0, normalized_text='',...None, processing_time=0.0003559589385986328, success=False, errors=["object Mock can't be used in 'await' expression"]).errors

tests/unit/test_orchestrator_service_fixed.py:145: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
___________ TestOrchestratorService.test_process_basic_functionality ___________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b753110>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f22bdf0>

    @pytest.mark.asyncio
    async def test_process_basic_functionality(self, orchestrator_service):
        """Test basic process functionality"""
        # Arrange
        test_text = "Test text"
    
        # Mock all services
        with patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.language_service, 'detect_language', new_callable=AsyncMock) as mock_language, \
             patch.object(orchestrator_service.normalization_service, 'normalize', new_callable=AsyncMock) as mock_normalize, \
             patch.object(orchestrator_service.variants_service, 'generate_variants', new_callable=AsyncMock) as mock_variants:
    
            mock_unicode.return_value = {'normalized': 'test text'}
            mock_language.return_value = {'language': 'en', 'confidence': 0.9}
            mock_normalize.return_value = {'normalized': 'test text'}
            mock_variants.return_value = {'variants': ['test text', 'test']}
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
            assert result.success is True
            assert result.original_text == test_text
>           assert result.normalized_text == 'test text'
E           AssertionError: assert 'Test text' == 'test text'
E             
E             - test text
E             ? ^
E             + Test text
E             ? ^

tests/unit/test_orchestrator_service_old.py:41: AssertionError
_____________ TestOrchestratorService.test_process_with_cache_hit ______________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b752fd0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c0050>

    @pytest.mark.asyncio
    async def test_process_with_cache_hit(self, orchestrator_service):
        """Test process with cache hit"""
        # Arrange
        test_text = "Cached text"
>       cached_result = UnifiedProcessingResult(
            original_text=test_text,
            normalized_text="cached text",
            language="en",
            language_confidence=0.9,
            variants=["cached", "text"],
            processing_time=0.001
        )
E       TypeError: UnifiedProcessingResult.__init__() missing 3 required positional arguments: 'tokens', 'trace', and 'signals'

tests/unit/test_orchestrator_service_old.py:52: TypeError
_____________ TestOrchestratorService.test_process_with_cache_miss _____________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b75a650>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c08d0>

    @pytest.mark.asyncio
    async def test_process_with_cache_miss(self, orchestrator_service):
        """Test process with cache miss"""
        # Arrange
        test_text = "Uncached text"
    
        # Mock services
>       with patch.object(orchestrator_service.cache_service, 'get') as mock_get, \
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch.object(orchestrator_service.cache_service, 'set') as mock_set, \
             patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.language_service, 'detect_language') as mock_language, \
             patch.object(orchestrator_service.normalization_service, 'normalize') as mock_normalize:
E            AttributeError: 'UnifiedOrchestrator' object has no attribute 'cache_service'. Did you mean: 'unicode_service'?

tests/unit/test_orchestrator_service_old.py:79: AttributeError
_____________ TestOrchestratorService.test_process_with_embeddings _____________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b75a780>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c1150>

    @pytest.mark.asyncio
    async def test_process_with_embeddings(self, orchestrator_service):
        """Test process with embeddings generation"""
        # Arrange
        test_text = "Test for embeddings"
    
        with patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.language_service, 'detect_language') as mock_language, \
             patch.object(orchestrator_service.normalization_service, 'normalize') as mock_normalize, \
>            patch.object(orchestrator_service.embedding_service, 'get_embeddings') as mock_embeddings:
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E            AttributeError: 'UnifiedOrchestrator' object has no attribute 'embedding_service'. Did you mean: 'embeddings_service'?

tests/unit/test_orchestrator_service_old.py:107: AttributeError
_____________ TestOrchestratorService.test_process_error_handling ______________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7cf410>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c19d0>

    @pytest.mark.asyncio
    async def test_process_error_handling(self, orchestrator_service):
        """Test error handling in process"""
        # Arrange
        test_text = "Error test"
    
        with patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode:
            mock_unicode.side_effect = Exception("Unicode service error")
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert result.success is False
            assert len(result.errors) > 0
            assert "Unicode service error" in result.errors[0]
            assert result.processing_time > 0
>           assert orchestrator_service.processing_stats['failed'] == 1
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'UnifiedOrchestrator' object has no attribute 'processing_stats'

tests/unit/test_orchestrator_service_old.py:143: AttributeError
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: Unicode service error
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 232, in process
    unicode_result = self.unicode_service.normalize_text(
        context.sanitized_text
    )
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Unicode service error
__________________ TestOrchestratorService.test_process_batch __________________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b76e580>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c2360>

    @pytest.mark.asyncio
    async def test_process_batch(self, orchestrator_service):
        """Test batch processing"""
        # Arrange
        texts = ["Text 1", "Text 2", "Text 3"]
    
        # Mock process to return successful results
        with patch.object(orchestrator_service, 'process') as mock_process:
            mock_results = [
>               UnifiedProcessingResult(
                    original_text=text,
                    normalized_text=text.lower(),
                    language="en",
                    language_confidence=0.9,
                    variants=[text.lower()],
                    processing_time=0.1
                ) for text in texts
            ]
E           TypeError: UnifiedProcessingResult.__init__() missing 3 required positional arguments: 'tokens', 'trace', and 'signals'

tests/unit/test_orchestrator_service_old.py:154: TypeError
__________ TestOrchestratorService.test_process_batch_with_exceptions __________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b76e690>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c2be0>

    @pytest.mark.asyncio
    async def test_process_batch_with_exceptions(self, orchestrator_service):
        """Test batch processing with exceptions"""
        # Arrange
        texts = ["Good text", "Bad text"]
    
        with patch.object(orchestrator_service, 'process') as mock_process:
            # First successful, second with error
            mock_process.side_effect = [
>               UnifiedProcessingResult(
                    original_text="Good text",
                    normalized_text="good text",
                    language="en",
                    language_confidence=0.9,
                    variants=["good text"]
                ),
                Exception("Processing error")
            ]
E           TypeError: UnifiedProcessingResult.__init__() missing 3 required positional arguments: 'tokens', 'trace', and 'signals'

tests/unit/test_orchestrator_service_old.py:182: TypeError
______ TestOrchestratorService.test_search_similar_names_with_embeddings _______

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b766650>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f22bbd0>

    @pytest.mark.asyncio
    async def test_search_similar_names_with_embeddings(self, orchestrator_service):
        """Test similar names search using embeddings"""
        # Arrange
        query = "John Smith"
        candidates = ["Jon Smith", "John Smyth", "Jane Smith", "Bob Johnson"]
    
>       with patch.object(orchestrator_service.embedding_service, 'find_similar_texts') as mock_search:
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'embedding_service'. Did you mean: 'embeddings_service'?

tests/unit/test_orchestrator_service_old.py:208: AttributeError
__________ TestOrchestratorService.test_search_similar_names_fallback __________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b766750>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f22b350>

    @pytest.mark.asyncio
    async def test_search_similar_names_fallback(self, orchestrator_service):
        """Test fallback similar names search"""
        # Arrange
        query = "John Smith"
        candidates = ["Jon Smith", "John Smyth"]
    
>       with patch.object(orchestrator_service.embedding_service, 'find_similar_texts') as mock_search, \
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch.object(orchestrator_service.variants_service, 'find_best_matches') as mock_fallback:
E            AttributeError: 'UnifiedOrchestrator' object has no attribute 'embedding_service'. Did you mean: 'embeddings_service'?

tests/unit/test_orchestrator_service_old.py:238: AttributeError
_____________ TestOrchestratorService.test_analyze_text_complexity _____________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b5466c0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f22a140>

    @pytest.mark.asyncio
    async def test_analyze_text_complexity(self, orchestrator_service):
        """Test text complexity analysis"""
        # Arrange
        test_text = "Complex text for analysis"
    
        with patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.language_service, 'detect_language') as mock_language, \
>            patch.object(orchestrator_service.signal_service, 'get_name_signals') as mock_signals:
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E            AttributeError: 'UnifiedOrchestrator' object has no attribute 'signal_service'. Did you mean: 'signals_service'?

tests/unit/test_orchestrator_service_old.py:265: AttributeError
______________ TestOrchestratorService.test_get_processing_stats _______________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b5467b0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56f2298c0>

    def test_get_processing_stats(self, orchestrator_service):
        """Test processing statistics retrieval"""
        # Arrange
        # Simulate some activity
>       orchestrator_service.processing_stats['total_processed'] = 10
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'processing_stats'

tests/unit/test_orchestrator_service_old.py:304: AttributeError
___________________ TestOrchestratorService.test_clear_cache ___________________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7c6350>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c2690>

    def test_clear_cache(self, orchestrator_service):
        """Test cache clearing"""
        # Act
>       orchestrator_service.clear_cache()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'clear_cache'

tests/unit/test_orchestrator_service_old.py:324: AttributeError
___________________ TestOrchestratorService.test_reset_stats ___________________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7c5a90>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c2140>

    def test_reset_stats(self, orchestrator_service):
        """Test statistics reset"""
        # Arrange
>       orchestrator_service.processing_stats['total_processed'] = 5
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'processing_stats'

tests/unit/test_orchestrator_service_old.py:333: AttributeError
_______________ TestOrchestratorService.test_generate_cache_key ________________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b4fbd40>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c1480>

    def test_generate_cache_key(self, orchestrator_service):
        """Test cache key generation"""
        # Act
>       key1 = orchestrator_service._generate_cache_key("test", True, False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute '_generate_cache_key'

tests/unit/test_orchestrator_service_old.py:346: AttributeError
__________________ TestOrchestratorService.test_update_stats ___________________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7e5010>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c0c00>

    def test_update_stats(self, orchestrator_service):
        """Test statistics update"""
        # Arrange
>       initial_processed = orchestrator_service.processing_stats['total_processed']
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'processing_stats'

tests/unit/test_orchestrator_service_old.py:359: AttributeError
___________ TestOrchestratorService.test_calculate_complexity_score ____________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7e50d0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c0380>

    def test_calculate_complexity_score(self, orchestrator_service):
        """Test complexity score calculation"""
        # Arrange
        unicode_complexity = {'confidence': 0.8}
        language_complexity = {'confidence': 0.9}
        name_complexity = {'confidence': 0.7}
    
        # Act
>       score = orchestrator_service._calculate_complexity_score(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            unicode_complexity,
            language_complexity,
            name_complexity
        )
E       AttributeError: 'UnifiedOrchestrator' object has no attribute '_calculate_complexity_score'

tests/unit/test_orchestrator_service_old.py:381: AttributeError
_______ TestOrchestratorService.test_generate_complexity_recommendations _______

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b53f330>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c3460>

    def test_generate_complexity_recommendations(self, orchestrator_service):
        """Test complexity recommendations generation"""
        # Act
>       low_recommendations = orchestrator_service._generate_complexity_recommendations(0.2)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute '_generate_complexity_recommendations'

tests/unit/test_orchestrator_service_old.py:394: AttributeError
__________ TestOrchestratorService.test_force_reprocess_ignores_cache __________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b53f1d0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c3ce0>

    @pytest.mark.asyncio
    async def test_force_reprocess_ignores_cache(self, orchestrator_service):
        """Test that force_reprocess ignores cache"""
        # Arrange
        test_text = "Force reprocess test"
>       cached_result = UnifiedProcessingResult(
            original_text=test_text,
            normalized_text="old cached result",
            language="en",
            language_confidence=0.5,
            variants=["old"]
        )
E       TypeError: UnifiedProcessingResult.__init__() missing 3 required positional arguments: 'tokens', 'trace', and 'signals'

tests/unit/test_orchestrator_service_old.py:415: TypeError
___________ TestOrchestratorService.test_orchestrator_initialization ___________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7d0eb0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x3fe6f85a0>

    def test_orchestrator_initialization(self, orchestrator_service):
        """Test orchestrator initialization"""
        # Act - use the fixture instead of creating new instance
        orchestrator = orchestrator_service
    
        # Assert
>       assert orchestrator.cache_service.max_size == 100  # From fixture
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'UnifiedOrchestrator' object has no attribute 'cache_service'. Did you mean: 'unicode_service'?

tests/unit/test_orchestrator_service_old.py:449: AttributeError
________ TestOrchestratorService.test_process_language_service_failure _________

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b7d0690>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c3ac0>

    @pytest.mark.asyncio
    async def test_process_language_service_failure(self, orchestrator_service):
        """Test resilience to language_service.detect_language failure"""
        # Arrange
        test_text = "Test text for language service failure"
    
        # Mock language_service.detect_language returns None
        with patch.object(orchestrator_service.language_service, 'detect_language') as mock_language, \
             patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.normalization_service, 'normalize') as mock_normalize:
    
            mock_unicode.return_value = {'normalized': test_text}
            mock_language.return_value = None  # Language service failure
            mock_normalize.return_value = {'normalized': test_text}
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
            # Check that we have either a successful result or an error
            if result.success:
>               assert result.language == 'en'  # Should use fallback
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               AssertionError: assert 'uk' == 'en'
E                 
E                 - en
E                 + uk

tests/unit/test_orchestrator_service_old.py:489: AssertionError
_____ TestOrchestratorService.test_process_normalization_service_exception _____

self = <tests.unit.test_orchestrator_service_old.TestOrchestratorService object at 0x16b8089e0>
orchestrator_service = <src.ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4ff5c3240>

    @pytest.mark.asyncio
    async def test_process_normalization_service_exception(self, orchestrator_service):
        """Test resilience to normalization_service.normalize exception"""
        # Arrange
        test_text = "Test text for normalization service exception"
    
        # Mock normalization_service.normalize throws exception
        with patch.object(orchestrator_service.unicode_service, 'normalize_text') as mock_unicode, \
             patch.object(orchestrator_service.language_service, 'detect_language') as mock_language, \
             patch.object(orchestrator_service.normalization_service, 'normalize') as mock_normalize:
    
            mock_unicode.return_value = {'normalized': test_text}
            mock_language.return_value = {'language': 'en', 'confidence': 0.9}
            mock_normalize.side_effect = Exception("Normalization service error")
    
            # Act
            result = await orchestrator_service.process(test_text)
    
            # Assert
            assert isinstance(result, UnifiedProcessingResult)
>           assert result.success is False
E           AssertionError: assert True is False
E            +  where True = UnifiedProcessingResult(original_text='Test text for normalization service exception', language='uk', language_confide...19be0>, variants=None, embeddings=None, decision=None, processing_time=0.00011014938354492188, success=True, errors=[]).success

tests/unit/test_orchestrator_service_old.py:518: AssertionError
______________ TestPatternService.test_case_sensitivity_handling _______________

self = <tests.unit.test_pattern_service.TestPatternService object at 0x16b546b70>
pattern_service = <src.ai_service.layers.patterns.unified_pattern_service.UnifiedPatternService object at 0x3fcbce8e0>

    def test_case_sensitivity_handling(self, pattern_service):
        """Test case sensitivity handling"""
        # Act
        upper_patterns = pattern_service.generate_patterns("JOHN SMITH", "en")
        lower_patterns = pattern_service.generate_patterns("john smith", "en")
        mixed_patterns = pattern_service.generate_patterns("John Smith", "en")
    
        # Assert
        for patterns in [upper_patterns, lower_patterns, mixed_patterns]:
>           assert len(patterns) > 0
E           assert 0 > 0
E            +  where 0 = len([])

tests/unit/test_pattern_service.py:192: AssertionError
____________ TestRussianMorphologyAnalyzer.test_analyze_word_basic _____________

self = <tests.unit.test_russian_morphology_unit.TestRussianMorphologyAnalyzer object at 0x16b753d90>

    def test_analyze_word_basic(self):
        """Test basic analyze_word functionality"""
        # Mock pymorphy3 response
        mock_parse = Mock()
        mock_parse.normal_form = "–°–µ—Ä–≥–µ–π"
        mock_parse.score = 1.0
    
        self.mock_pymorphy.parse.return_value = [mock_parse]
    
        result = self.analyzer.analyze_word('–°–µ—Ä–≥–µ–π')
    
        # Check result structure
        assert isinstance(result, list)
        assert len(result) > 0
>       assert isinstance(result[0], MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–°–µ—Ä–≥–µ–π', ...}, MorphologicalAnalysis)

tests/unit/test_russian_morphology_unit.py:63: AssertionError
______________ TestRussianMorphologyAnalyzer.test_is_russian_name ______________

self = <tests.unit.test_russian_morphology_unit.TestRussianMorphologyAnalyzer object at 0x16b767550>

    def test_is_russian_name(self):
        """Test is_russian_name detection"""
        # Test known Russian names
>       assert self.analyzer.is_known_word('–°–µ—Ä–≥–µ–π') == True
E       AssertionError: assert False == True
E        +  where False = is_known_word('–°–µ—Ä–≥–µ–π')
E        +    where is_known_word = <src.ai_service.layers.normalization.morphology.russian_morphology.RussianMorphologyAnalyzer object at 0x4ff45d050>.is_known_word
E        +      where <src.ai_service.layers.normalization.morphology.russian_morphology.RussianMorphologyAnalyzer object at 0x4ff45d050> = <tests.unit.test_russian_morphology_unit.TestRussianMorphologyAnalyzer object at 0x16b767550>.analyzer

tests/unit/test_russian_morphology_unit.py:184: AssertionError
____________ TestRussianMorphologyAnalyzer.test_analyze_name_basic _____________

self = <tests.unit.test_russian_morphology_unit.TestRussianMorphologyAnalyzer object at 0x16b78a6d0>

    def test_analyze_name_basic(self):
        """Test basic analyze_name functionality"""
        test_name = "–°–µ—Ä–≥–µ–π"
    
        result = self.analyzer.analyze_word(test_name)
    
        # Should return analysis result
        assert isinstance(result, list)
        assert len(result) > 0
        if result:  # If there are results
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–°–µ—Ä–≥–µ–π', ...}, MorphologicalAnalysis)

tests/unit/test_russian_morphology_unit.py:250: AssertionError
________ TestRussianMorphologyAnalyzer.test_analyze_name_with_language _________

self = <tests.unit.test_russian_morphology_unit.TestRussianMorphologyAnalyzer object at 0x16b7f18b0>

    def test_analyze_name_with_language(self):
        """Test analyze_name with language parameter"""
        test_name = "–°–µ—Ä–≥–µ–π"
    
        # Note: analyze_word doesn't take language parameter
        result = self.analyzer.analyze_word(test_name)
    
        # Should return analysis result
        assert isinstance(result, list)
        assert len(result) > 0
        if result:  # If there are results
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–°–µ—Ä–≥–µ–π', ...}, MorphologicalAnalysis)

tests/unit/test_russian_morphology_unit.py:263: AssertionError
_____ TestSmartFilterService.test_initialization_with_terrorism_detection ______

self = <tests.unit.test_smart_filter_service.TestSmartFilterService testMethod=test_initialization_with_terrorism_detection>

    def test_initialization_with_terrorism_detection(self):
        """Test service initialization with terrorism detection enabled"""
>       with patch('ai_service.layers.smart_filter.smart_filter_service.SignalService'):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/unit/test_smart_filter_service.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x4ff520d60>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x4ff520d60>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_service.layers.smart_filter.smart_filter_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/smart_filter/smart_filter_service.py'> does not have the attribute 'SignalService'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
_______________ TestSmartFilterService.test_make_smart_decision ________________

self = <tests.unit.test_smart_filter_service.TestSmartFilterService testMethod=test_make_smart_decision>
mock_decision_logic = <MagicMock name='DecisionLogic' id='22819632000'>

    @patch('ai_service.layers.smart_filter.smart_filter_service.DecisionLogic')
    def test_make_smart_decision(self, mock_decision_logic):
        """Test smart decision making"""
        # Mock decision result
        mock_decision_result = MagicMock()
        mock_decision_result.decision = DecisionType.FULL_SEARCH
        mock_decision_result.confidence = 0.8
        mock_decision_result.risk_level = RiskLevel.MEDIUM
        mock_decision_result.reasoning = "Test reasoning"
        mock_decision_result.recommendations = ["Test recommendation"]
        mock_decision_result.requires_escalation = False
        mock_decision_result.processing_time = 0.001
        mock_decision_result.detected_signals = {}
        mock_decision_result.metadata = {}
    
        mock_decision_logic.return_value.make_decision.return_value = mock_decision_result
    
>       with patch('ai_service.layers.smart_filter.smart_filter_service.SignalService'):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/unit/test_smart_filter_service.py:100: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x4ff521860>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x4ff521860>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'ai_service.layers.smart_filter.smart_filter_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/smart_filter/smart_filter_service.py'> does not have the attribute 'SignalService'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
______________ TestSmartFilterService.test_service_words_cleaning ______________

self = <tests.unit.test_smart_filter_service.TestSmartFilterService testMethod=test_service_words_cleaning>

    def test_service_words_cleaning(self):
        """Test service words cleaning"""
        text_with_service_words = "–æ–ø–ª–∞—Ç–∞ –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é –ü–µ—Ç—Ä–æ–≤ –Ü–≤–∞–Ω"
        cleaned = self.smart_filter._clean_service_words(text_with_service_words)
    
        # Should remove "–æ–ø–ª–∞—Ç–∞ –∑–∞" from the beginning
>       self.assertNotEqual(cleaned, text_with_service_words)
E       AssertionError: '–æ–ø–ª–∞—Ç–∞ –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é –ü–µ—Ç—Ä–æ–≤ –Ü–≤–∞–Ω' == '–æ–ø–ª–∞—Ç–∞ –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é –ü–µ—Ç—Ä–æ–≤ –Ü–≤–∞–Ω'

tests/unit/test_smart_filter_service.py:195: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.smart_filter.smart_filter_service:smart_filter_service.py:479 _clean_service_words is deprecated - use context-aware analysis instead
___________ TestSmartFilterService.test_should_process_text_excluded ___________

self = <tests.unit.test_smart_filter_service.TestSmartFilterService testMethod=test_should_process_text_excluded>

    def test_should_process_text_excluded(self):
        """Test processing excluded text"""
        # Mock the exclusion check
        with patch.object(self.smart_filter, '_is_excluded_text', return_value=True):
            result = self.smart_filter.should_process_text("–æ–ø–ª–∞—Ç–∞")
    
            self.assertFalse(result.should_process)
>           self.assertIn("–∏—Å–∫–ª—é—á–µ–Ω", result.processing_recommendation)
E           AssertionError: '–∏—Å–∫–ª—é—á–µ–Ω' not found in 'Text excluded from processing (service information only)'

tests/unit/test_smart_filter_service.py:59: AssertionError
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0421\u0435\u0440\u0433\u0456\u0439-masc-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b87f610>
name = '–°–µ—Ä–≥—ñ–π', expected_gender = 'masc', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041e\u043b\u0435\u043d\u0430-femn-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b87f750>
name = '–û–ª–µ–Ω–∞', expected_gender = 'femn', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–æ–ª–µ–Ω–∞', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–û–ª–µ–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-masc-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8a0640>
name = '–í–æ–ª–æ–¥–∏–º–∏—Ä', expected_gender = 'masc', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–≤–æ–ª–æ–¥–∏–º–∏—Ä', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–í–æ–ª–æ–¥–∏–º–∏—Ä': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0414\u0430\u0440\u0456\u044f-femn-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8a0770>
name = '–î–∞—Ä—ñ—è', expected_gender = 'femn', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–¥–∞—Ä—ñ—è', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041f\u0435\u0442\u0440\u043e-masc-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8d8a70>
name = '–ü–µ—Ç—Ä–æ', expected_gender = 'masc', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0410\u043d\u043d\u0430-femn-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8b06b0>
name = '–ê–Ω–Ω–∞', expected_gender = 'femn', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–∞–Ω–Ω–∞', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ê–Ω–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041c\u0438\u0445\u0430\u0439\u043b\u043e-masc-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8b07c0>
name = '–ú–∏—Ö–∞–π–ª–æ', expected_gender = 'masc', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–º–∏—Ö–∞–π–ª–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ú–∏—Ö–∞–π–ª–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041a\u0430\u0442\u0435\u0440\u0438\u043d\u0430-femn-uk] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8cc250>
name = '–ö–∞—Ç–µ—Ä–∏–Ω–∞', expected_gender = 'femn', expected_language = 'uk'

    @pytest.mark.parametrize("name,expected_gender,expected_language", [
        ("–°–µ—Ä–≥—ñ–π", "masc", "uk"),
        ("–û–ª–µ–Ω–∞", "femn", "uk"),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", "masc", "uk"),
        ("–î–∞—Ä—ñ—è", "femn", "uk"),
        ("–ü–µ—Ç—Ä–æ", "masc", "uk"),
        ("–ê–Ω–Ω–∞", "femn", "uk"),
        ("–ú–∏—Ö–∞–π–ª–æ", "masc", "uk"),
        ("–ö–∞—Ç–µ—Ä–∏–Ω–∞", "femn", "uk"),
    ])
    def test_gender_detection_for_ukrainian_names(self, name, expected_gender, expected_language):
        """Parameterized test for gender detection of Ukrainian names"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–∫–∞—Ç–µ—Ä–∏–Ω–∞', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:37: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ö–∞—Ç–µ—Ä–∏–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_________ TestUkrainianMorphologyAnalyzer.test_diminutives_generation __________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8cc350>

    def test_diminutives_generation(self):
        """Test generation of diminutive forms"""
        # Act
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:257: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_transliteration_generation ________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8b85f0>

    def test_transliteration_generation(self):
        """Test generation of transliterations"""
        # Act
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:268: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e-expected_endings0] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8b88c0>
name = '–ü–µ—Ç—Ä–µ–Ω–∫–æ', expected_endings = ['–∫–æ']

    @pytest.mark.parametrize("name,expected_endings", [
        ("–ü–µ—Ç—Ä–µ–Ω–∫–æ", ["–∫–æ"]),
        ("–Ü–≤–∞–Ω–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
        ("–ú–µ–ª—å–Ω–∏–∫", ["–Ω–∏–∫"]),
        ("–®–µ–≤—á–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
    ])
    def test_ukrainian_surname_endings(self, name, expected_endings):
        """Parameterized test for Ukrainian surname endings"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–µ–Ω–∫–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:86: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u0406\u0432\u0430\u043d\u0435\u043d\u043a\u043e-expected_endings1] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8aba10>
name = '–Ü–≤–∞–Ω–µ–Ω–∫–æ', expected_endings = ['–µ–Ω–∫–æ']

    @pytest.mark.parametrize("name,expected_endings", [
        ("–ü–µ—Ç—Ä–µ–Ω–∫–æ", ["–∫–æ"]),
        ("–Ü–≤–∞–Ω–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
        ("–ú–µ–ª—å–Ω–∏–∫", ["–Ω–∏–∫"]),
        ("–®–µ–≤—á–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
    ])
    def test_ukrainian_surname_endings(self, name, expected_endings):
        """Parameterized test for Ukrainian surname endings"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': 'masc', 'lemma': '—ñ–≤–∞–Ω–µ–Ω–∫–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:86: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–Ü–≤–∞–Ω–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u041c\u0435\u043b\u044c\u043d\u0438\u043a-expected_endings2] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8abbd0>
name = '–ú–µ–ª—å–Ω–∏–∫', expected_endings = ['–Ω–∏–∫']

    @pytest.mark.parametrize("name,expected_endings", [
        ("–ü–µ—Ç—Ä–µ–Ω–∫–æ", ["–∫–æ"]),
        ("–Ü–≤–∞–Ω–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
        ("–ú–µ–ª—å–Ω–∏–∫", ["–Ω–∏–∫"]),
        ("–®–µ–≤—á–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
    ])
    def test_ukrainian_surname_endings(self, name, expected_endings):
        """Parameterized test for Ukrainian surname endings"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': None, 'lemma': '–º–µ–ª—å–Ω–∏–∫', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:86: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ú–µ–ª—å–Ω–∏–∫': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u0428\u0435\u0432\u0447\u0435\u043d\u043a\u043e-expected_endings3] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b7f3ba0>
name = '–®–µ–≤—á–µ–Ω–∫–æ', expected_endings = ['–µ–Ω–∫–æ']

    @pytest.mark.parametrize("name,expected_endings", [
        ("–ü–µ—Ç—Ä–µ–Ω–∫–æ", ["–∫–æ"]),
        ("–Ü–≤–∞–Ω–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
        ("–ú–µ–ª—å–Ω–∏–∫", ["–Ω–∏–∫"]),
        ("–®–µ–≤—á–µ–Ω–∫–æ", ["–µ–Ω–∫–æ"]),
    ])
    def test_ukrainian_surname_endings(self, name, expected_endings):
        """Parameterized test for Ukrainian surname endings"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': 'masc', 'lemma': '—à–µ–≤—á–µ–Ω–∫–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:86: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–®–µ–≤—á–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_edge_cases_handling[\u0410-expected_result1] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b7e7590>
input_name = '–ê', expected_result = {'name': '–ê', 'total_forms': 1}

    @pytest.mark.parametrize("input_name,expected_result", [
        ("", {'name': '', 'total_forms': 0}),
        ("–ê", {'name': '–ê', 'total_forms': 1}),
        ("–°–µ—Ä–≥—ñ–π", {'name': '–°–µ—Ä–≥—ñ–π', 'total_forms': 0}),  # Will check after analysis
    ])
    def test_edge_cases_handling(self, input_name, expected_result):
        """Parameterized test for edge cases handling"""
        # Act
        results = self.analyzer.analyze_word(input_name)
        if input_name:  # If name is not empty
            assert len(results) > 0
            result = results[0]
    
            # Assert
>           assert isinstance(result, MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.1, 'gender': None, 'lemma': '–ê', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:103: AssertionError
_ TestUkrainianMorphologyAnalyzer.test_edge_cases_handling[\u0421\u0435\u0440\u0433\u0456\u0439-expected_result2] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b87b490>
input_name = '–°–µ—Ä–≥—ñ–π', expected_result = {'name': '–°–µ—Ä–≥—ñ–π', 'total_forms': 0}

    @pytest.mark.parametrize("input_name,expected_result", [
        ("", {'name': '', 'total_forms': 0}),
        ("–ê", {'name': '–ê', 'total_forms': 1}),
        ("–°–µ—Ä–≥—ñ–π", {'name': '–°–µ—Ä–≥—ñ–π', 'total_forms': 0}),  # Will check after analysis
    ])
    def test_edge_cases_handling(self, input_name, expected_result):
        """Parameterized test for edge cases handling"""
        # Act
        results = self.analyzer.analyze_word(input_name)
        if input_name:  # If name is not empty
            assert len(results) > 0
            result = results[0]
    
            # Assert
>           assert isinstance(result, MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:103: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0421\u0435\u0440\u0433\u0456\u0439-expected_ukrainian_chars0] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b87b6a0>
name = '–°–µ—Ä–≥—ñ–π', expected_ukrainian_chars = ['—ñ']

    @pytest.mark.parametrize("name,expected_ukrainian_chars", [
        ("–°–µ—Ä–≥—ñ–π", ["—ñ"]),
        ("–û–ª–µ–∫—Å—ñ–π", ["—ñ"]),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", []),  # Does not contain Ukrainian symbols
        ("–î–∞—Ä—ñ—è", ["—ñ"]),
        ("–ü–µ—Ç—Ä–æ", []),  # Does not contain Ukrainian symbols
    ])
    def test_ukrainian_character_detection(self, name, expected_ukrainian_chars):
        """Parameterized test for Ukrainian character detection"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:121: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u041e\u043b\u0435\u043a\u0441\u0456\u0439-expected_ukrainian_chars1] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8d6030>
name = '–û–ª–µ–∫—Å—ñ–π', expected_ukrainian_chars = ['—ñ']

    @pytest.mark.parametrize("name,expected_ukrainian_chars", [
        ("–°–µ—Ä–≥—ñ–π", ["—ñ"]),
        ("–û–ª–µ–∫—Å—ñ–π", ["—ñ"]),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", []),  # Does not contain Ukrainian symbols
        ("–î–∞—Ä—ñ—è", ["—ñ"]),
        ("–ü–µ—Ç—Ä–æ", []),  # Does not contain Ukrainian symbols
    ])
    def test_ukrainian_character_detection(self, name, expected_ukrainian_chars):
        """Parameterized test for Ukrainian character detection"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–æ–ª–µ–∫—Å—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:121: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–û–ª–µ–∫—Å—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-expected_ukrainian_chars2] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8d5ef0>
name = '–í–æ–ª–æ–¥–∏–º–∏—Ä', expected_ukrainian_chars = []

    @pytest.mark.parametrize("name,expected_ukrainian_chars", [
        ("–°–µ—Ä–≥—ñ–π", ["—ñ"]),
        ("–û–ª–µ–∫—Å—ñ–π", ["—ñ"]),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", []),  # Does not contain Ukrainian symbols
        ("–î–∞—Ä—ñ—è", ["—ñ"]),
        ("–ü–µ—Ç—Ä–æ", []),  # Does not contain Ukrainian symbols
    ])
    def test_ukrainian_character_detection(self, name, expected_ukrainian_chars):
        """Parameterized test for Ukrainian character detection"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–≤–æ–ª–æ–¥–∏–º–∏—Ä', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:121: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–í–æ–ª–æ–¥–∏–º–∏—Ä': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0414\u0430\u0440\u0456\u044f-expected_ukrainian_chars3] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b862a80>
name = '–î–∞—Ä—ñ—è', expected_ukrainian_chars = ['—ñ']

    @pytest.mark.parametrize("name,expected_ukrainian_chars", [
        ("–°–µ—Ä–≥—ñ–π", ["—ñ"]),
        ("–û–ª–µ–∫—Å—ñ–π", ["—ñ"]),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", []),  # Does not contain Ukrainian symbols
        ("–î–∞—Ä—ñ—è", ["—ñ"]),
        ("–ü–µ—Ç—Ä–æ", []),  # Does not contain Ukrainian symbols
    ])
    def test_ukrainian_character_detection(self, name, expected_ukrainian_chars):
        """Parameterized test for Ukrainian character detection"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–¥–∞—Ä—ñ—è', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:121: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u041f\u0435\u0442\u0440\u043e-expected_ukrainian_chars4] _

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8a5c50>
name = '–ü–µ—Ç—Ä–æ', expected_ukrainian_chars = []

    @pytest.mark.parametrize("name,expected_ukrainian_chars", [
        ("–°–µ—Ä–≥—ñ–π", ["—ñ"]),
        ("–û–ª–µ–∫—Å—ñ–π", ["—ñ"]),
        ("–í–æ–ª–æ–¥–∏–º–∏—Ä", []),  # Does not contain Ukrainian symbols
        ("–î–∞—Ä—ñ—è", ["—ñ"]),
        ("–ü–µ—Ç—Ä–æ", []),  # Does not contain Ukrainian symbols
    ])
    def test_ukrainian_character_detection(self, name, expected_ukrainian_chars):
        """Parameterized test for Ukrainian character detection"""
        # Act
        results = self.analyzer.analyze_word(name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:121: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_name_complexity_analysis _________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8f0d50>

    def test_name_complexity_analysis(self):
        """Test name complexity analysis"""
        # Act
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:339: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_________ TestUkrainianMorphologyAnalyzer.test_gender_correction_logic _________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b7ef690>

    def test_gender_correction_logic(self):
        """Critical test: checking gender correction logic"""
        # Act
        results = self.analyzer.analyze_word("–ü–µ—Ç—Ä–æ")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:166: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
____ TestUkrainianMorphologyAnalyzer.test_analyze_name_basic_functionality _____

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b855320>

    def test_analyze_name_basic_functionality(self):
        """Test basic functionality of name analysis"""
        # Act
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:177: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
___________ TestUkrainianMorphologyAnalyzer.test_short_name_handling ___________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b86b110>

    def test_short_name_handling(self):
        """Test handling of too short name"""
        # Act
        results = self.analyzer.analyze_word("–ê")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.1, 'gender': None, 'lemma': '–ê', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:199: AssertionError
_________ TestUkrainianMorphologyAnalyzer.test_auto_language_detection _________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b887610>

    def test_auto_language_detection(self):
        """Test automatic language detection"""
        # Arrange
        ukrainian_name = "–°–µ—Ä–≥—ñ–π"  # Contains Ukrainian letter '—ñ'
        russian_name = "–°–µ—Ä–≥–µ–π"   # Contains Russian letter '–µ'
    
        # Act
        uk_results = self.analyzer.analyze_word(ukrainian_name)
        ru_results = self.analyzer.analyze_word(russian_name)
        assert len(uk_results) > 0
        assert len(ru_results) > 0
        uk_result = uk_results[0]
        ru_result = ru_results[0]
    
        # Assert
>       assert isinstance(uk_result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:217: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥–µ–π': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_gender_exceptions_dictionary _______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b887480>

    def test_gender_exceptions_dictionary(self):
        """Test gender exceptions dictionary"""
        # Act & Assert
        # Check male names
        for male_name in ['–ü–µ—Ç—Ä–æ', '–Ü–≤–∞–Ω', '–°–µ—Ä–≥—ñ–π', '–í–æ–ª–æ–¥–∏–º–∏—Ä']:
            results = self.analyzer.analyze_word(male_name)
            assert len(results) > 0
            result = results[0]
>           assert isinstance(result, MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:238: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_phonetic_variants_generation _______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8874d0>

    def test_phonetic_variants_generation(self):
        """Test generation of phonetic variants"""
        # Arrange
        name_with_phonetic_patterns = "–°–µ—Ä–≥—ñ–π"  # Contains '–≥' which can be replaced
    
        # Act
        results = self.analyzer.analyze_word(name_with_phonetic_patterns)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:282: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_regional_transliterations ________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8875c0>

    def test_regional_transliterations(self):
        """Test regional transliterations"""
        # Arrange
        ukrainian_name = "–°–µ—Ä–≥—ñ–π"  # Contains Ukrainian letter '—ñ'
    
        # Act
        results = self.analyzer.analyze_word(ukrainian_name)
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:296: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
__________ TestUkrainianMorphologyAnalyzer.test_get_all_forms_method ___________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0780>

    def test_get_all_forms_method(self):
        """Test method for getting all name forms"""
        # Act
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:307: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_is_ukrainian_name_detection _______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0910>

    def test_is_ukrainian_name_detection(self):
        """Test Ukrainian name detection"""
        # Act & Assert
        results1 = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        results2 = self.analyzer.analyze_word("–ë–æ–≥–¥–∞–Ω")
        results3 = self.analyzer.analyze_word("–Ü–≤–∞–Ω–µ–Ω–∫–æ")
        assert len(results1) > 0
        assert len(results2) > 0
        assert len(results3) > 0
        result1 = results1[0]
        result2 = results2[0]
        result3 = results3[0]
    
        # Assert
>       assert isinstance(result1, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:324: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ë–æ–≥–¥–∞–Ω': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–Ü–≤–∞–Ω–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_complexity_level_calculation _______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0960>

    def test_complexity_level_calculation(self):
        """Test complexity level calculation"""
        # Act & Assert - using real analysis methods
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
>       assert result.confidence >= 0.0
               ^^^^^^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'confidence'

tests/unit/test_ukrainian_morphology.py:348: AttributeError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
__________ TestUkrainianMorphologyAnalyzer.test_basic_transliteration __________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e09b0>

    def test_basic_transliteration(self):
        """Test basic transliteration"""
        # Act - using real analysis method
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:359: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_language_detection_internal _______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0a00>

    def test_language_detection_internal(self):
        """Test internal language detection"""
        # Act & Assert - using real analysis methods
        results1 = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        results2 = self.analyzer.analyze_word("–°–µ—Ä–≥–µ–π")
        assert len(results1) > 0
        assert len(results2) > 0
        result1 = results1[0]
        result2 = results2[0]
    
        # Check that analysis works for both variants
>       assert isinstance(result1, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:373: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥–µ–π': 'MorphologicalAnalysis' object has no attribute 'get'
___ TestUkrainianMorphologyAnalyzer.test_pymorphy_analysis_failure_handling ____

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0a50>
mock_pymorphy = <MagicMock name='_analyze_with_pymorphy' id='24573182368'>

    @patch.object(UkrainianMorphologyAnalyzer, '_analyze_with_pymorphy')
    def test_pymorphy_analysis_failure_handling(self, mock_pymorphy):
        """Test handling of pymorphy analysis error"""
        # Arrange
        mock_pymorphy.side_effect = Exception("Pymorphy analysis failed")
    
        # Act
        results = self.analyzer.analyze_word("–¢–µ—Å—Ç")
        assert len(results) > 0
        result = results[0]
    
        # Assert
        # Should work even with pymorphy error
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': None, 'lemma': '—Ç–µ—Å—Ç', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:389: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–¢–µ—Å—Ç': Pymorphy analysis failed
______ TestUkrainianMorphologyAnalyzer.test_generate_pymorphy_declensions ______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0aa0>

    def test_generate_pymorphy_declensions(self):
        """Test generation of declensions via pymorphy3"""
        # Act - using real analysis method
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:400: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_extract_gender_with_name_tags ______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0af0>

    def test_extract_gender_with_name_tags(self):
        """Test extraction of gender with name tags"""
        # Act - using real analysis method
        results = self.analyzer.analyze_word("–î–∞—Ä—å—è")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': 'femn', 'lemma': '–¥–∞—Ä—å—è', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:411: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—å—è': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_extract_gender_by_endings ________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0b40>

    def test_extract_gender_by_endings(self):
        """Test gender determination by endings"""
        # Act - using real analysis methods
        results1 = self.analyzer.analyze_word("–ù–æ–≤–∏–π")
        results2 = self.analyzer.analyze_word("–ù–æ–≤–∞")
        assert len(results1) > 0
        assert len(results2) > 0
        result1 = results1[0]
        result2 = results2[0]
    
        # Assert
>       assert isinstance(result1, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': None, 'lemma': '–Ω–æ–≤–∏–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:425: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ù–æ–≤–∏–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ù–æ–≤–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_____ TestUkrainianMorphologyAnalyzer.test_apply_regional_transliteration ______

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0b90>

    def test_apply_regional_transliteration(self):
        """Test application of regional transliteration"""
        # Act - using real analysis method
        results = self.analyzer.analyze_word("–°–µ—Ä–≥—ñ–π")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:438: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_whitespace_name_handling _________

self = <tests.unit.test_ukrainian_morphology.TestUkrainianMorphologyAnalyzer object at 0x16b8e0be0>

    def test_whitespace_name_handling(self):
        """Test handling of names with whitespace"""
        # Act
        results = self.analyzer.analyze_word("  –°–µ—Ä–≥—ñ–π  ")
        assert len(results) > 0
        result = results[0]
    
        # Assert
>       assert isinstance(result, MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '—Å–µ—Ä–≥—ñ–π', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology.py:449: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
___ TestUkrainianMorphologyAnalyzer.test_analyze_word_gender_detection_petro ___

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b87f890>

    def test_analyze_word_gender_detection_petro(self):
        """Test that analyze_word correctly determines gender for "–ü–µ—Ç—Ä–æ" """
        # Mock pymorphy3 response
        mock_parse = Mock()
        mock_parse.normal_form = "–ü–µ—Ç—Ä–æ"
        mock_parse.score = 1.0
    
        self.mock_pymorphy.parse.return_value = [mock_parse]
    
        result = self.analyzer.analyze_word('–ü–µ—Ç—Ä–æ')
    
        # Check result structure
        assert isinstance(result, list)
        assert len(result) > 0
>       assert isinstance(result[0], MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:63: AssertionError
___ TestUkrainianMorphologyAnalyzer.test_analyze_word_gender_detection_daria ___

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b87f9d0>

    def test_analyze_word_gender_detection_daria(self):
        """Test that analyze_word correctly determines gender for "–î–∞—Ä—ñ—è" """
        # Mock pymorphy3 response
        mock_parse = Mock()
        mock_parse.normal_form = "–î–∞—Ä—ñ—è"
        mock_parse.score = 1.0
    
        self.mock_pymorphy.parse.return_value = [mock_parse]
    
        result = self.analyzer.analyze_word('–î–∞—Ä—ñ—è')
    
        # Check result structure
        assert isinstance(result, list)
        assert len(result) > 0
>       assert isinstance(result[0], MorphologicalAnalysis)
E       AssertionError: assert False
E        +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'femn', 'lemma': '–¥–∞—Ä—ñ—è', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:79: AssertionError
________ TestUkrainianMorphologyAnalyzer.test_analyze_word_unknown_name ________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8a09d0>

    def test_analyze_word_unknown_name(self):
        """Test analysis of unknown name"""
        # Mock pymorphy3 response for unknown name
        mock_parse = Mock()
        mock_parse.normal_form = "–¢–µ—Å—Ç"
        mock_parse.score = 0.5
    
        self.mock_pymorphy.parse.return_value = [mock_parse]
    
        result = self.analyzer.analyze_word("–¢–µ—Å—Ç")
    
        # Should return fallback analysis
        assert isinstance(result, list)
        assert len(result) > 0
        if result:  # If there are results
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': None, 'lemma': '—Ç–µ—Å—Ç', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:96: AssertionError
_________ TestUkrainianMorphologyAnalyzer.test_analyze_word_short_name _________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8a08a0>

    def test_analyze_word_short_name(self):
        """Test analysis of short name"""
        result = self.analyzer.analyze_word("–ê–±–≤–≥–¥")
    
        # Should return fallback analysis for short names
        assert isinstance(result, list)
        assert len(result) > 0
        if result:  # If there are results
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.3, 'gender': None, 'lemma': '–∞–±–≤–≥–¥', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:106: AssertionError
_______ TestUkrainianMorphologyAnalyzer.test_is_known_word_special_name ________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8b0c00>

    def test_is_known_word_special_name(self):
        """Test is_known_word for special name"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        result = self.analyzer.is_known_word(test_name)
    
        # Should return True for special names
>       assert result is True
E       assert False is True

tests/unit/test_ukrainian_morphology_unit.py:147: AssertionError
_________ TestUkrainianMorphologyAnalyzer.test_get_gender_special_name _________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8cc750>

    def test_get_gender_special_name(self):
        """Test gender detection for special name"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        results = self.analyzer.analyze_word(test_name)
        assert len(results) > 0
    
        result = results[0]
        # Should return correct gender for special names
>       assert result.gender == 'masc'  # Petro is masculine
               ^^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'gender'

tests/unit/test_ukrainian_morphology_unit.py:174: AttributeError
_________ TestUkrainianMorphologyAnalyzer.test_get_gender_unknown_name _________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8b8aa0>

    def test_get_gender_unknown_name(self):
        """Test gender detection for unknown name"""
        test_name = "–¢–µ—Å—Ç"
    
        results = self.analyzer.analyze_word(test_name)
        # May return empty results for unknown words
        if len(results) > 0:
            result = results[0]
            # Should return analysis result, gender may be None for unknown words
>           assert isinstance(result.lemma, str)
                              ^^^^^^^^^^^^
E           AttributeError: 'dict' object has no attribute 'lemma'

tests/unit/test_ukrainian_morphology_unit.py:185: AttributeError
________ TestUkrainianMorphologyAnalyzer.test_get_variants_special_name ________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8b8b90>

    def test_get_variants_special_name(self):
        """Test getting variants for special name"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        results = self.analyzer.analyze_word(test_name)
        # May return empty results for unknown words
        if len(results) > 0:
            result = results[0]
            # Should return analysis result with lemma and gender
>           assert isinstance(result.lemma, str)
                              ^^^^^^^^^^^^
E           AttributeError: 'dict' object has no attribute 'lemma'

tests/unit/test_ukrainian_morphology_unit.py:198: AttributeError
________ TestUkrainianMorphologyAnalyzer.test_get_variants_unknown_name ________

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8f7a10>

    def test_get_variants_unknown_name(self):
        """Test getting variants for unknown name"""
        test_name = "–¢–µ—Å—Ç"
    
        results = self.analyzer.analyze_word(test_name)
        assert len(results) > 0
    
        result = results[0]
        # Should return analysis result with lemma
>       assert isinstance(result.lemma, str)
                          ^^^^^^^^^^^^
E       AttributeError: 'dict' object has no attribute 'lemma'

tests/unit/test_ukrainian_morphology_unit.py:211: AttributeError
______ TestUkrainianMorphologyAnalyzer.test_get_diminutives_special_name _______

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b8f7cb0>

    def test_get_diminutives_special_name(self):
        """Test getting diminutives for special name"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        results = self.analyzer.analyze_word(test_name)
        # May return empty results for unknown words
        if len(results) > 0:
            result = results[0]
            # Should return analysis result with lemma and gender
>           assert isinstance(result.lemma, str)
                              ^^^^^^^^^^^^
E           AttributeError: 'dict' object has no attribute 'lemma'

tests/unit/test_ukrainian_morphology_unit.py:223: AttributeError
______ TestUkrainianMorphologyAnalyzer.test_get_diminutives_unknown_name _______

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b7f3ee0>

    def test_get_diminutives_unknown_name(self):
        """Test getting diminutives for unknown name"""
        test_name = "–¢–µ—Å—Ç"
    
        results = self.analyzer.analyze_word(test_name)
        # May return empty results for unknown words
        if len(results) > 0:
            result = results[0]
            # Should return analysis result with lemma
>           assert isinstance(result.lemma, str)
                              ^^^^^^^^^^^^
E           AttributeError: 'dict' object has no attribute 'lemma'

tests/unit/test_ukrainian_morphology_unit.py:237: AttributeError
____ TestUkrainianMorphologyAnalyzer.test_analyze_name_basic_functionality _____

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b7e77d0>

    def test_analyze_name_basic_functionality(self):
        """Test basic analyze_name functionality"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        result = self.analyzer.analyze_word(test_name)
    
        # Should return analysis result
        assert isinstance(result, list)
        # May return empty results for unknown words
        if len(result) > 0:
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:250: AssertionError
__ TestUkrainianMorphologyAnalyzer.test_analyze_name_with_language_detection ___

self = <tests.unit.test_ukrainian_morphology_unit.TestUkrainianMorphologyAnalyzer object at 0x16b7e7890>

    def test_analyze_name_with_language_detection(self):
        """Test analyze_name with language detection"""
        test_name = "–ü–µ—Ç—Ä–æ"
    
        result = self.analyzer.analyze_word(test_name)
    
        # Should return analysis result
        assert isinstance(result, list)
        # May return empty results for unknown words
        if len(result) > 0:
>           assert isinstance(result[0], MorphologicalAnalysis)
E           AssertionError: assert False
E            +  where False = isinstance({'case': None, 'confidence': 0.8, 'gender': 'masc', 'lemma': '–ø–µ—Ç—Ä–æ', ...}, MorphologicalAnalysis)

tests/unit/test_ukrainian_morphology_unit.py:262: AssertionError
____________________ TestUnicodeService.test_final_cleanup _____________________

self = <tests.unit.test_unicode_service.TestUnicodeService object at 0x16b8b9130>
unicode_service = <src.ai_service.layers.unicode.unicode_service.UnicodeService object at 0x3feca2ff0>

    def test_final_cleanup(self, unicode_service):
        """Test final text cleanup"""
        # Arrange
        messy_text = "  Multiple   spaces  \t\n  "
    
        # Act
        result = unicode_service.normalize_text(messy_text)
    
        # Assert
        normalized = result['normalized']
>       assert normalized == "multiple spaces"  # Should be cleaned and converted to lowercase
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert 'Multiple spaces' == 'multiple spaces'
E         
E         - multiple spaces
E         ? ^
E         + Multiple spaces
E         ? ^

tests/unit/test_unicode_service.py:181: AssertionError
________ TestUnicodeService.test_unicode_normalization_failure_handling ________

args = (<tests.unit.test_unicode_service.TestUnicodeService object at 0x16b938050>,)
keywargs = {'unicode_service': <src.ai_service.layers.unicode.unicode_service.UnicodeService object at 0x3fec39790>}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x16b907690>

    def __enter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
>           return next(self.gen)
                   ^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x16b87be30>
patched = <function TestUnicodeService.test_unicode_normalization_failure_handling at 0x16b90fce0>
args = (<tests.unit.test_unicode_service.TestUnicodeService object at 0x16b938050>,)
keywargs = {'unicode_service': <src.ai_service.layers.unicode.unicode_service.UnicodeService object at 0x3fec39790>}

    @contextlib.contextmanager
    def decoration_helper(self, patched, args, keywargs):
        extra_args = []
        with contextlib.ExitStack() as exit_stack:
            for patching in patched.patchings:
>               arg = exit_stack.enter_context(patching)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1405: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib.ExitStack object at 0x3fec8e030>
cm = <unittest.mock._patch object at 0x16b87be30>

    def enter_context(self, cm):
        """Enters the supplied context manager.
    
        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        """
        # We look up the special methods on the type to match the with
        # statement.
        cls = type(cm)
        try:
            _enter = cls.__enter__
            _exit = cls.__exit__
        except AttributeError:
            raise TypeError(f"'{cls.__module__}.{cls.__qualname__}' object does "
                            f"not support the context manager protocol") from None
>       result = _enter(cm)
                 ^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:530: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x16b87be30>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
>       self.target = self.getter()
                      ^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1481: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'src.ai_service.services.unicode_service.unicodedata'

    def resolve_name(name):
        """
        Resolve a name to an object.
    
        It is expected that `name` will be a string in one of the following
        formats, where W is shorthand for a valid Python identifier and dot stands
        for a literal period in these pseudo-regexes:
    
        W(.W)*
        W(.W)*:(W(.W)*)?
    
        The first form is intended for backward compatibility only. It assumes that
        some part of the dotted name is a package, and the rest is an object
        somewhere within that package, possibly nested inside other objects.
        Because the place where the package stops and the object hierarchy starts
        can't be inferred by inspection, repeated attempts to import must be done
        with this form.
    
        In the second form, the caller makes the division point clear through the
        provision of a single colon: the dotted name to the left of the colon is a
        package to be imported, and the dotted name to the right is the object
        hierarchy within that package. Only one import is needed in this form. If
        it ends with the colon, then a module object is returned.
    
        The function will return an object (which might be a module), or raise one
        of the following exceptions:
    
        ValueError - if `name` isn't in a recognised format
        ImportError - if an import failed when it shouldn't have
        AttributeError - if a failure occurred when traversing the object hierarchy
                         within the imported package to get to the desired object.
        """
        global _NAME_PATTERN
        if _NAME_PATTERN is None:
            # Lazy import to speedup Python startup time
            import re
            dotted_words = r'(?!\d)(\w+)(\.(?!\d)(\w+))*'
            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'
                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',
                                       re.UNICODE)
    
        m = _NAME_PATTERN.match(name)
        if not m:
            raise ValueError(f'invalid format: {name!r}')
        gd = m.groupdict()
        if gd.get('cln'):
            # there is a colon - a one-step import is all that's needed
            mod = importlib.import_module(gd['pkg'])
            parts = gd.get('obj')
            parts = parts.split('.') if parts else []
        else:
            # no colon - have to iterate to find the package boundary
            parts = name.split('.')
            modname = parts.pop(0)
            # first part *must* be a module/package.
            mod = importlib.import_module(modname)
            while parts:
                p = parts[0]
                s = f'{modname}.{p}'
                try:
                    mod = importlib.import_module(s)
                    parts.pop(0)
                    modname = s
                except ImportError:
                    break
        # if we reach this point, mod is the module, already imported, and
        # parts is the list of parts in the object hierarchy to be traversed, or
        # an empty list if just the module is wanted.
        result = mod
        for p in parts:
>           result = getattr(result, p)
                     ^^^^^^^^^^^^^^^^^^
E           AttributeError: module 'src.ai_service.services' has no attribute 'unicode_service'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pkgutil.py:528: AttributeError
__________________ TestUnicodeService.test_case_normalization __________________

self = <tests.unit.test_unicode_service.TestUnicodeService object at 0x16b93c110>
unicode_service = <src.ai_service.layers.unicode.unicode_service.UnicodeService object at 0x4ce87bef0>

    def test_case_normalization(self, unicode_service):
        """Test case normalization"""
        # Arrange
        mixed_case_text = "MiXeD CaSe TeXt"
    
        # Act
        result = unicode_service.normalize_text(mixed_case_text)
    
        # Assert
>       assert result['normalized'].islower()
E       AssertionError: assert False
E        +  where False = <built-in method islower of str object at 0x3fecb42f0>()
E        +    where <built-in method islower of str object at 0x3fecb42f0> = 'MiXeD CaSe TeXt'.islower

tests/unit/test_unicode_service.py:265: AssertionError
________________ TestUnifiedOrchestrator.test_complete_pipeline ________________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b954f50>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4fd0b1230>
mock_services = {'embeddings_service': <Mock id='22275849392'>, 'language_service': <Mock id='17114115312'>, 'normalization_service': <Mock id='17114116992'>, 'signals_service': <Mock id='17114117664'>, ...}

    async def test_complete_pipeline(self, orchestrator, mock_services):
        """Test complete 9-layer pipeline execution"""
    
        result = await orchestrator.process(
            text="Test input –Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤",
            remove_stop_words=True,
            preserve_names=True,
            enable_advanced_features=True,
            generate_variants=True,
            generate_embeddings=True
        )
    
        # Verify result structure
>       assert isinstance(result, UnifiedUnifiedProcessingResult)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       NameError: name 'UnifiedUnifiedProcessingResult' is not defined

tests/unit/test_unified_orchestrator.py:137: NameError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
______ TestUnifiedOrchestrator.test_normalization_flags_passed_correctly _______

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b954cd0>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56d8641f0>
mock_services = {'embeddings_service': <Mock id='17152625360'>, 'language_service': <Mock id='17152633760'>, 'normalization_service': <Mock id='17152635776'>, 'signals_service': <Mock id='17152636784'>, ...}

    async def test_normalization_flags_passed_correctly(self, orchestrator, mock_services):
        """Test that normalization flags are passed correctly to the service"""
    
        await orchestrator.process(
            text="Test",
            remove_stop_words=False,
            preserve_names=False,
            enable_advanced_features=False
        )
    
        # Verify normalization service received correct flags
        call_args = mock_services["normalization_service"].normalize_async.call_args
>       assert call_args[1]["remove_stop_words"] is False
               ^^^^^^^^^^^^
E       TypeError: 'NoneType' object is not subscriptable

tests/unit/test_unified_orchestrator.py:171: TypeError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
___________ TestUnifiedOrchestrator.test_optional_services_disabled ____________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8a1940>
mock_services = {'embeddings_service': <Mock id='20545357536'>, 'language_service': <Mock id='17152866160'>, 'normalization_service': <Mock id='20545355856'>, 'signals_service': <Mock id='20545368624'>, ...}

    async def test_optional_services_disabled(self, mock_services):
        """Test orchestrator with optional services disabled"""
    
        orchestrator = UnifiedOrchestrator(
            validation_service=mock_services["validation_service"],
            language_service=mock_services["language_service"],
            unicode_service=mock_services["unicode_service"],
            normalization_service=mock_services["normalization_service"],
            signals_service=mock_services["signals_service"],
            # No optional services
            enable_smart_filter=False,
            enable_variants=False,
            enable_embeddings=False
        )
    
        result = await orchestrator.process(text="Test")
    
        # Core processing should work
>       assert result.success is True
E       assert False is True
E        +  where False = UnifiedProcessingResult(original_text='Test', language=<Mock name='mock.detect_language_config_driven().language' id='...None, processing_time=0.0004811286926269531, success=False, errors=["object Mock can't be used in 'await' expression"]).success

tests/unit/test_unified_orchestrator.py:220: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 290, in process
    signals_result = await self.signals_service.extract_signals(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text=context.original_text, normalization_result=norm_result, language=context.language
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_________________ TestUnifiedOrchestrator.test_error_handling __________________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b9530b0>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56d8654a0>
mock_services = {'embeddings_service': <Mock id='20545365936'>, 'language_service': <Mock id='17152859104'>, 'normalization_service': <Mock id='17152624352'>, 'signals_service': <Mock id='20545369632'>, ...}

    async def test_error_handling(self, orchestrator, mock_services):
        """Test error handling in the pipeline"""
    
        # Make normalization service fail
        mock_services["normalization_service"].normalize_async = AsyncMock(
            side_effect=Exception("Normalization failed")
        )
    
        result = await orchestrator.process(text="Test")
    
        # Should handle error gracefully
        assert result.success is False
        assert len(result.errors) > 0
>       assert "Normalization failed" in str(result.errors)
E       assert 'Normalization failed' in '["object Mock can\'t be used in \'await\' expression"]'
E        +  where '["object Mock can\'t be used in \'await\' expression"]' = str(["object Mock can't be used in 'await' expression"])
E        +    where ["object Mock can't be used in 'await' expression"] = UnifiedProcessingResult(original_text='Test', language='unknown', language_confidence=0.0, normalized_text='', tokens=...None, processing_time=8.606910705566406e-05, success=False, errors=["object Mock can't be used in 'await' expression"]).errors

tests/unit/test_unified_orchestrator.py:244: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_______________ TestUnifiedOrchestrator.test_performance_warning _______________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8b1480>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x56e2e5160>
mock_services = {'embeddings_service': <Mock id='6102462352'>, 'language_service': <Mock id='20545366608'>, 'normalization_service': <Mock id='20545362240'>, 'signals_service': <Mock id='20545358880'>, ...}

    async def test_performance_warning(self, orchestrator, mock_services):
        """Test performance warning for slow processing"""
    
        # Make normalization artificially slow
        import asyncio
        async def slow_normalize(*args, **kwargs):
            await asyncio.sleep(0.15)  # 150ms - above 100ms threshold
            return NormalizationResult(
                normalized="test",
                tokens=["test"],
                trace=[],
                success=True
            )
    
        mock_services["normalization_service"].normalize_async = slow_normalize
    
        result = await orchestrator.process(text="Test")
    
        # Should complete but be slow
>       assert result.success is True
E       assert False is True
E        +  where False = UnifiedProcessingResult(original_text='Test', language='unknown', language_confidence=0.0, normalized_text='', tokens=...None, processing_time=8.916854858398438e-05, success=False, errors=["object Mock can't be used in 'await' expression"]).success

tests/unit/test_unified_orchestrator.py:265: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_______________ TestUnifiedOrchestrator.test_signals_integration _______________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8cc850>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x3fcb79710>
mock_services = {'embeddings_service': <Mock id='17152864816'>, 'language_service': <Mock id='17152855072'>, 'normalization_service': <Mock id='17152857088'>, 'signals_service': <Mock id='17152862464'>, ...}

    async def test_signals_integration(self, orchestrator, mock_services):
        """Test signals service integration with normalization results"""
    
        result = await orchestrator.process(text="Test")
    
        # Verify signals service received normalization result
        call_args = mock_services["signals_service"].extract_signals.call_args
>       assert call_args is not None  # Service was called
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       assert None is not None

tests/unit/test_unified_orchestrator.py:300: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_______________ TestUnifiedOrchestrator.test_trace_preservation ________________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8ccd50>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x3fcb7ad00>
mock_services = {'embeddings_service': <Mock id='20545363920'>, 'language_service': <Mock id='20545356192'>, 'normalization_service': <Mock id='20545360560'>, 'signals_service': <Mock id='20545363584'>, ...}

    async def test_trace_preservation(self, orchestrator, mock_services):
        """Test that token traces are preserved through the pipeline"""
    
        result = await orchestrator.process(text="Test")
    
        # Verify traces are preserved
>       assert len(result.trace) == 2
E       assert 0 == 2
E        +  where 0 = len([])
E        +    where [] = UnifiedProcessingResult(original_text='Test', language='unknown', language_confidence=0.0, normalized_text='', tokens=...None, processing_time=7.891654968261719e-05, success=False, errors=["object Mock can't be used in 'await' expression"]).trace

tests/unit/test_unified_orchestrator.py:311: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
__________________ TestUnifiedOrchestrator.test_language_hint __________________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8b99a0>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4d7dea000>
mock_services = {'embeddings_service': <Mock id='17152637456'>, 'language_service': <Mock id='17152624016'>, 'normalization_service': <Mock id='17152633088'>, 'signals_service': <Mock id='17152624688'>, ...}

    async def test_language_hint(self, orchestrator, mock_services):
        """Test language hint override"""
    
        await orchestrator.process(
            text="Test",
            language_hint="en"
        )
    
        # Should use hint instead of detection
        call_args = mock_services["normalization_service"].normalize_async.call_args
>       assert call_args[1]["language"] == "en"
               ^^^^^^^^^^^^
E       TypeError: 'NoneType' object is not subscriptable

tests/unit/test_unified_orchestrator.py:327: TypeError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
______________ TestUnifiedOrchestrator.test_result_serialization _______________

self = <tests.unit.test_unified_orchestrator.TestUnifiedOrchestrator object at 0x16b8b98b0>
orchestrator = <ai_service.core.unified_orchestrator.UnifiedOrchestrator object at 0x4d7debee0>
mock_services = {'embeddings_service': <Mock id='17114105568'>, 'language_service': <Mock id='20810430320'>, 'normalization_service': <Mock id='20540831936'>, 'signals_service': <Mock id='17114118000'>, ...}

    async def test_result_serialization(self, orchestrator, mock_services):
        """Test that result can be serialized to dict"""
    
        result = await orchestrator.process(text="Test")
    
        data = result.to_dict()
    
        assert isinstance(data, dict)
        assert data["original_text"] == "Test"
>       assert data["normalized_text"] == "–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤"
E       AssertionError: assert '' == '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤'
E         
E         - –Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤

tests/unit/test_unified_orchestrator.py:338: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_ test_ukrainian_full_normalization[\u0414\u043b\u044f \u0416\u0435\u043d\u0456 \u0413\u0430\u043b\u0438\u0447\u0430 \u0437 \u0433\u0440\u0443\u043f\u0438 O.Torvald-\u0404\u0432\u0433\u0435\u043d \u0413\u0430\u043b\u0438\u0447] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–î–ª—è –ñ–µ–Ω—ñ –ì–∞–ª–∏—á–∞ –∑ –≥—Ä—É–ø–∏ O.Torvald', expected_name = '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á –ó.', tokens=['–Ñ–≤–≥–µ–Ω', '–ì–∞–ª–∏—á', '–ó.'], trace=[TokenTrace(token='–ñ–µ–Ω—ñ', role...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á', but got '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á –ó.'
E       assert '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á –ó.' == '–Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á'
E         
E         - –Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á
E         + –Ñ–≤–≥–µ–Ω –ì–∞–ª–∏—á –ó.
E         ?            +++

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_ukrainian_full_normalization[\u0417\u0443\u0441\u0442\u0440\u0456\u0447 \u0437 \u041b\u0456\u043d\u043e\u044e \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e-\u041b\u0456\u043d\u0430 \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–ó—É—Å—Ç—Ä—ñ—á –∑ –õ—ñ–Ω–æ—é –ö–æ—Å—Ç–µ–Ω–∫–æ', expected_name = '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ó. –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ', tokens=['–ó.', '–õ—ñ–Ω–∞', '–ö–æ—Å—Ç–µ–Ω–∫–æ'], trace=[TokenTrace(token='–∑', rol...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ', but got '–ó. –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'
E       assert '–ó. –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ' == '–õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ'
E         
E         - –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ
E         + –ó. –õ—ñ–Ω–∞ –ö–æ—Å—Ç–µ–Ω–∫–æ
E         ? +++

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_ukrainian_full_normalization[\u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0432 \u0437 \u0412\u0430\u043b\u0435\u0440\u0456\u0454\u043c \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u043c-\u0412\u0430\u043b\u0435\u0440\u0456\u0439 \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u0439] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–†–æ–∑–º–æ–≤–ª—è–≤ –∑ –í–∞–ª–µ—Ä—ñ—î–º –ó–∞–ª—É–∂–Ω–∏–º', expected_name = '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ó. –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π', tokens=['–ó.', '–í–∞–ª–µ—Ä—ñ–π', '–ó–∞–ª—É–∂–Ω–∏–π'], trace=[TokenTrace(token='–∑...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π', but got '–ó. –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'
E       assert '–ó. –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π' == '–í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π'
E         
E         - –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π
E         + –ó. –í–∞–ª–µ—Ä—ñ–π –ó–∞–ª—É–∂–Ω–∏–π
E         ? +++

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_ukrainian_full_normalization[\u0414\u043b\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u0430 \u0421.\u0412.-\u0406\u0432\u0430\u043d\u043e\u0432-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e \u0421.\u0412.] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–î–ª—è –Ü–≤–∞–Ω–æ–≤–∞-–ü–µ—Ç—Ä–µ–Ω–∫–∞ –°.–í.', expected_name = '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°.–í.'

    @pytest.mark.parametrize("input_text, expected_name", ukrainian_test_cases)
    def test_ukrainian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="uk")
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°. –í.', tokens=['–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ', '–°.', '–í.'], trace=[TokenTrace(toke...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°.–í.'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°.–í.', but got '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°. –í.'
E       assert '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°. –í.' == '–Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°.–í.'
E         
E         - –Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°.–í.
E         + –Ü–≤–∞–Ω–æ–≤-–ü–µ—Ç—Ä–µ–Ω–∫–æ –°. –í.
E         ?                   +

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_russian_full_normalization[\u0414\u043b\u044f \u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–î–ª—è –ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω—ã –ü—É–≥–∞—á–µ–≤–æ–π'
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
    
        # Debug output for failing cases
        if "–í—ã—Å–æ—Ü–∫–æ–≥–æ" in input_text:
            print(f"\nDEBUG - Input: '{input_text}'")
            print(f"DEBUG - Expected: '{expected_name}'")
            print(f"DEBUG - Actual: '{result.normalized}'")
    
            # Force create a fresh service to bypass any caching issues
            from ai_service.layers.normalization.normalization_service import NormalizationService
            fresh_service = NormalizationService()
    
            # Test with fresh service
            fresh_result = fresh_service.normalize(input_text, language="ru")
            print(f"DEBUG - Fresh service result: '{fresh_result.normalized}'")
    
            # Test morphology with fresh service
            fresh_morph_test = fresh_service._morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru')
            print(f"DEBUG - Fresh _morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru') = '{fresh_morph_test}'")
    
            fresh_ru_morph = fresh_service._get_morph('ru')
            if fresh_ru_morph:
                print(f"DEBUG - Fresh ru_morph available: {fresh_ru_morph.morph_analyzer is not None}")
                if fresh_ru_morph.morph_analyzer:
                    print(f"DEBUG - Fresh ru_morph type: {type(fresh_ru_morph.morph_analyzer)}")
                else:
                    # Test direct pymorphy3 initialization in test environment
                    print("DEBUG - Testing direct pymorphy3 in test env:")
                    import sys
                    print(f"DEBUG - Python executable: {sys.executable}")
                    print(f"DEBUG - Python path length: {len(sys.path)}")
                    try:
                        import pymorphy3
                        test_analyzer = pymorphy3.MorphAnalyzer(lang="ru")
                        test_parses = test_analyzer.parse('–í—ã—Å–æ—Ü–∫–æ–≥–æ')
                        print(f"DEBUG - Direct pymorphy3 works: {len(test_parses)} parses")
                        print(f"DEBUG - Direct result: {test_parses[0].normal_form if test_parses else 'No parses'}")
                    except Exception as e:
                        print(f"DEBUG - Direct pymorphy3 error: {e}")
                        print(f"DEBUG - Type of error: {type(e)}")
                        import traceback
                        print(f"DEBUG - Traceback: {traceback.format_exc()}")
            else:
                print("DEBUG - Fresh ru_morph is None!")
    
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤', tokens=['–ê–ª–ª—ã', '–ë–æ—Ä–∏—Å–æ–≤–Ω', '–ü—É–≥–∞—á–µ–≤'], trace=[TokenTrace(toke...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞', but got '–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤'
E       assert '–ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤' == '–ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞'
E         
E         - –ê–ª–ª–∞ –ë–æ—Ä–∏—Å–æ–≤–Ω–∞ –ü—É–≥–∞—á–µ–≤–∞
E         ?    ^         -        -
E         + –ê–ª–ª—ã –ë–æ—Ä–∏—Å–æ–≤–Ω –ü—É–≥–∞—á–µ–≤
E         ?    ^

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_russian_full_normalization[\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c \u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å –ü–µ—Ç—Ä—É –ß–∞–π–∫–æ–≤—Å–∫–æ–º—É'
expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
    
        # Debug output for failing cases
        if "–í—ã—Å–æ—Ü–∫–æ–≥–æ" in input_text:
            print(f"\nDEBUG - Input: '{input_text}'")
            print(f"DEBUG - Expected: '{expected_name}'")
            print(f"DEBUG - Actual: '{result.normalized}'")
    
            # Force create a fresh service to bypass any caching issues
            from ai_service.layers.normalization.normalization_service import NormalizationService
            fresh_service = NormalizationService()
    
            # Test with fresh service
            fresh_result = fresh_service.normalize(input_text, language="ru")
            print(f"DEBUG - Fresh service result: '{fresh_result.normalized}'")
    
            # Test morphology with fresh service
            fresh_morph_test = fresh_service._morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru')
            print(f"DEBUG - Fresh _morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru') = '{fresh_morph_test}'")
    
            fresh_ru_morph = fresh_service._get_morph('ru')
            if fresh_ru_morph:
                print(f"DEBUG - Fresh ru_morph available: {fresh_ru_morph.morph_analyzer is not None}")
                if fresh_ru_morph.morph_analyzer:
                    print(f"DEBUG - Fresh ru_morph type: {type(fresh_ru_morph.morph_analyzer)}")
                else:
                    # Test direct pymorphy3 initialization in test environment
                    print("DEBUG - Testing direct pymorphy3 in test env:")
                    import sys
                    print(f"DEBUG - Python executable: {sys.executable}")
                    print(f"DEBUG - Python path length: {len(sys.path)}")
                    try:
                        import pymorphy3
                        test_analyzer = pymorphy3.MorphAnalyzer(lang="ru")
                        test_parses = test_analyzer.parse('–í—ã—Å–æ—Ü–∫–æ–≥–æ')
                        print(f"DEBUG - Direct pymorphy3 works: {len(test_parses)} parses")
                        print(f"DEBUG - Direct result: {test_parses[0].normal_form if test_parses else 'No parses'}")
                    except Exception as e:
                        print(f"DEBUG - Direct pymorphy3 error: {e}")
                        print(f"DEBUG - Type of error: {type(e)}")
                        import traceback
                        print(f"DEBUG - Traceback: {traceback.format_exc()}")
            else:
                print("DEBUG - Fresh ru_morph is None!")
    
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º', tokens=['–ü–µ—Ç—Ä', '–ß–∞–π–∫–æ–≤—Å–∫–æ–º'], trace=[TokenTrace(token='–ü–µ—Ç—Ä—É', role...re_female': 0, 'score_male': 3, 'gap': 3}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π', but got '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º'
E       assert '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º' == '–ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π'
E         
E         - –ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–∏–π
E         ?              ^^
E         + –ü–µ—Ç—Ä –ß–∞–π–∫–æ–≤—Å–∫–æ–º
E         ?              ^^

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_russian_full_normalization[\u0412\u0441\u0442\u0440\u0435\u0447\u0430 \u0441 \u0410\u043d\u043d\u043e\u0439 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u043e\u0439-\u0410\u043d\u043d\u0430 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u0430] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–í—Å—Ç—Ä–µ—á–∞ —Å –ê–Ω–Ω–æ–π –ê—Ö–º–∞—Ç–æ–≤–æ–π', expected_name = '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
    
        # Debug output for failing cases
        if "–í—ã—Å–æ—Ü–∫–æ–≥–æ" in input_text:
            print(f"\nDEBUG - Input: '{input_text}'")
            print(f"DEBUG - Expected: '{expected_name}'")
            print(f"DEBUG - Actual: '{result.normalized}'")
    
            # Force create a fresh service to bypass any caching issues
            from ai_service.layers.normalization.normalization_service import NormalizationService
            fresh_service = NormalizationService()
    
            # Test with fresh service
            fresh_result = fresh_service.normalize(input_text, language="ru")
            print(f"DEBUG - Fresh service result: '{fresh_result.normalized}'")
    
            # Test morphology with fresh service
            fresh_morph_test = fresh_service._morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru')
            print(f"DEBUG - Fresh _morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru') = '{fresh_morph_test}'")
    
            fresh_ru_morph = fresh_service._get_morph('ru')
            if fresh_ru_morph:
                print(f"DEBUG - Fresh ru_morph available: {fresh_ru_morph.morph_analyzer is not None}")
                if fresh_ru_morph.morph_analyzer:
                    print(f"DEBUG - Fresh ru_morph type: {type(fresh_ru_morph.morph_analyzer)}")
                else:
                    # Test direct pymorphy3 initialization in test environment
                    print("DEBUG - Testing direct pymorphy3 in test env:")
                    import sys
                    print(f"DEBUG - Python executable: {sys.executable}")
                    print(f"DEBUG - Python path length: {len(sys.path)}")
                    try:
                        import pymorphy3
                        test_analyzer = pymorphy3.MorphAnalyzer(lang="ru")
                        test_parses = test_analyzer.parse('–í—ã—Å–æ—Ü–∫–æ–≥–æ')
                        print(f"DEBUG - Direct pymorphy3 works: {len(test_parses)} parses")
                        print(f"DEBUG - Direct result: {test_parses[0].normal_form if test_parses else 'No parses'}")
                    except Exception as e:
                        print(f"DEBUG - Direct pymorphy3 error: {e}")
                        print(f"DEBUG - Type of error: {type(e)}")
                        import traceback
                        print(f"DEBUG - Traceback: {traceback.format_exc()}")
            else:
                print("DEBUG - Fresh ru_morph is None!")
    
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–°. –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞', tokens=['–°.', '–ê–Ω–Ω–∞', '–ê—Ö–º–∞—Ç–æ–≤–∞'], trace=[TokenTrace(token='—Å', rol...re_female': 5, 'score_male': 0, 'gap': 5}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞', but got '–°. –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'
E       assert '–°. –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞' == '–ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞'
E         
E         - –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞
E         + –°. –ê–Ω–Ω–∞ –ê—Ö–º–∞—Ç–æ–≤–∞
E         ? +++

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ test_russian_full_normalization[\u0417\u0430\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0442 \u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432\u0430 \u041c.\u042e.-\u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432 \u041c.\u042e.] _

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = '–ó–∞—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ç –õ–µ—Ä–º–æ–Ω—Ç–æ–≤–∞ –ú.–Æ.', expected_name = '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú.–Æ.'

    @pytest.mark.parametrize("input_text, expected_name", russian_test_cases)
    def test_russian_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="ru")
    
        # Debug output for failing cases
        if "–í—ã—Å–æ—Ü–∫–æ–≥–æ" in input_text:
            print(f"\nDEBUG - Input: '{input_text}'")
            print(f"DEBUG - Expected: '{expected_name}'")
            print(f"DEBUG - Actual: '{result.normalized}'")
    
            # Force create a fresh service to bypass any caching issues
            from ai_service.layers.normalization.normalization_service import NormalizationService
            fresh_service = NormalizationService()
    
            # Test with fresh service
            fresh_result = fresh_service.normalize(input_text, language="ru")
            print(f"DEBUG - Fresh service result: '{fresh_result.normalized}'")
    
            # Test morphology with fresh service
            fresh_morph_test = fresh_service._morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru')
            print(f"DEBUG - Fresh _morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru') = '{fresh_morph_test}'")
    
            fresh_ru_morph = fresh_service._get_morph('ru')
            if fresh_ru_morph:
                print(f"DEBUG - Fresh ru_morph available: {fresh_ru_morph.morph_analyzer is not None}")
                if fresh_ru_morph.morph_analyzer:
                    print(f"DEBUG - Fresh ru_morph type: {type(fresh_ru_morph.morph_analyzer)}")
                else:
                    # Test direct pymorphy3 initialization in test environment
                    print("DEBUG - Testing direct pymorphy3 in test env:")
                    import sys
                    print(f"DEBUG - Python executable: {sys.executable}")
                    print(f"DEBUG - Python path length: {len(sys.path)}")
                    try:
                        import pymorphy3
                        test_analyzer = pymorphy3.MorphAnalyzer(lang="ru")
                        test_parses = test_analyzer.parse('–í—ã—Å–æ—Ü–∫–æ–≥–æ')
                        print(f"DEBUG - Direct pymorphy3 works: {len(test_parses)} parses")
                        print(f"DEBUG - Direct result: {test_parses[0].normal_form if test_parses else 'No parses'}")
                    except Exception as e:
                        print(f"DEBUG - Direct pymorphy3 error: {e}")
                        print(f"DEBUG - Type of error: {type(e)}")
                        import traceback
                        print(f"DEBUG - Traceback: {traceback.format_exc()}")
            else:
                print("DEBUG - Fresh ru_morph is None!")
    
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:111: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú. –Æ.', tokens=['–õ–µ—Ä–º–æ–Ω—Ç–æ–≤', '–ú.', '–Æ.'], trace=[TokenTrace(token='–õ–µ—Ä–º–æ–Ω—Ç–æ–≤...re_female': 0, 'score_male': 2, 'gap': 2}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú.–Æ.'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú.–Æ.', but got '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú. –Æ.'
E       assert '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú. –Æ.' == '–õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú.–Æ.'
E         
E         - –õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú.–Æ.
E         + –õ–µ—Ä–º–æ–Ω—Ç–æ–≤ –ú. –Æ.
E         ?             +

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
___ test_english_full_normalization[Sent to ELON MUSK for X corp-Elon Musk] ____

normalization_service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5befb97d0>
input_text = 'Sent to ELON MUSK for X corp', expected_name = 'Elon Musk'

    @pytest.mark.parametrize("input_text, expected_name", english_test_cases)
    def test_english_full_normalization(normalization_service, input_text, expected_name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏–º–µ–Ω."""
        result = normalization_service.normalize(input_text, language="en")
>       assert_normalized_name(result, expected_name)

tests/unit/text_processing/test_normalization_logic.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

result = NormalizationResult(normalized='Elon Musk X', tokens=['Elon', 'Musk', 'X'], trace=[TokenTrace(token='ELON', role='give...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')
expected_name = 'Elon Musk'

    def assert_normalized_name(result: NormalizationResult, expected_name: str):
        """
        Asserts that the normalized result string equals the expected name.
        This is a strict assertion.
        """
>       assert result.normalized == expected_name, f"Expected '{expected_name}', but got '{result.normalized}'"
E       AssertionError: Expected 'Elon Musk', but got 'Elon Musk X'
E       assert 'Elon Musk X' == 'Elon Musk'
E         
E         - Elon Musk
E         + Elon Musk X
E         ?          ++

tests/unit/text_processing/test_normalization_logic.py:18: AssertionError
_ TestNormalizationResultFields.test_normalization_result_basic_serialization __

self = <tests.unit.text_processing.test_normalization_result_fields.TestNormalizationResultFields object at 0x16b8a3bb0>
service = <src.ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c3e92250>

    def test_normalization_result_basic_serialization(self, service):
        """Test that NormalizationResult can be converted to dict."""
        text = "–ü–µ—Ä–µ–∫–∞–∑ –∫–æ—à—Ç—ñ–≤ –Ω–∞ —ñ–º'—è –ü–µ—Ç—Ä–æ –Ü–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ"
        result = service.normalize(text, language="uk")
    
        # Test conversion to dict using dataclasses.asdict
        import dataclasses
>       result_dict = dataclasses.asdict(result)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/unit/text_processing/test_normalization_result_fields.py:110: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = NormalizationResult(normalized='–ü–µ—Ç—Ä–æ –Ü–≤–∞–Ω–æ–≤–∏—á –ö–æ–≤–∞–ª–µ–Ω–∫–æ', tokens=['–ü–µ—Ç—Ä–æ', '–Ü–≤–∞–Ω–æ–≤–∏—á', '–ö–æ–≤–∞–ª–µ–Ω–∫–æ'], trace=[TokenTrac...re_female': 0, 'score_male': 6, 'gap': 6}}], person_gender=None, gender_confidence=None, organizations=[], org_core='')

    def asdict(obj, *, dict_factory=dict):
        """Return the fields of a dataclass instance as a new dictionary mapping
        field names to field values.
    
        Example usage::
    
          @dataclass
          class C:
              x: int
              y: int
    
          c = C(1, 2)
          assert asdict(c) == {'x': 1, 'y': 2}
    
        If given, 'dict_factory' will be used instead of built-in dict.
        The function applies recursively to field values that are
        dataclass instances. This will also look into built-in containers:
        tuples, lists, and dicts. Other objects are copied with 'copy.deepcopy()'.
        """
        if not _is_dataclass_instance(obj):
>           raise TypeError("asdict() should be called on dataclass instances")
E           TypeError: asdict() should be called on dataclass instances

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/dataclasses.py:1358: TypeError
_________ TestNormalizationService.test_normalize_russian_complex_text _________

self = <tests.unit.text_processing.test_normalization_service.TestNormalizationService object at 0x16b9f4a70>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x56edbe650>

    def test_normalize_russian_complex_text(self, service):
        """Test normalization with complex Russian text"""
        text = "–ü–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –Ω–∞ –∏–º—è –ò–≤–∞–Ω–∞ –ü–µ—Ç—Ä–æ–≤–∞ –æ—Ç –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤–æ–π"
        result = service.normalize(text, language="ru")
    
        assert result.success
        assert "–ò–≤–∞–Ω" in result.normalized
        assert "–ü–µ—Ç—Ä–æ–≤" in result.normalized
>       assert "–ê–Ω–Ω–∞" in result.normalized
E       AssertionError: assert '–ê–Ω–Ω–∞' in '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤'
E        +  where '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤' = NormalizationResult(normalized='–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤', tokens=['–ò–≤–∞–Ω', '–ü–µ—Ç—Ä–æ–≤', '–ê–Ω–Ω—ã', '–°–º–∏—Ä–Ω–æ–≤'], trace=[TokenT...re_female': 0, 'score_male': 7, 'gap': 7}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service.py:226: AssertionError
________ TestNormalizationService.test_normalize_ukrainian_complex_text ________

self = <tests.unit.text_processing.test_normalization_service.TestNormalizationService object at 0x16ba15e50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c44a8a50>

    def test_normalize_ukrainian_complex_text(self, service):
        """Test normalization with complex Ukrainian text"""
        text = "–ü–µ—Ä–µ–∫–∞–∑ –∫–æ—à—Ç—ñ–≤ –Ω–∞ —ñ–º'—è –Ü–≤–∞–Ω–∞ –ü–µ—Ç—Ä–æ–≤–∞ –≤—ñ–¥ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤–æ—ó"
        result = service.normalize(text, language="uk")
    
        assert result.success
        assert "–Ü–≤–∞–Ω" in result.normalized
        assert "–ü–µ—Ç—Ä–æ–≤" in result.normalized
>       assert "–ê–Ω–Ω–∞" in result.normalized
E       AssertionError: assert '–ê–Ω–Ω–∞' in '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤'
E        +  where '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤' = NormalizationResult(normalized='–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤', tokens=['–Ü–≤–∞–Ω', '–ü–µ—Ç—Ä–æ–≤', '–ê–Ω–Ω–∏', '–°–º—ñ—Ä–Ω–æ–≤'], trace=[TokenT...re_female': 0, 'score_male': 7, 'gap': 7}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service.py:237: AssertionError
_____________ TestNormalizationService.test_normalize_english_text _____________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16b9574d0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16ba16bd0>

    def test_normalize_english_text(self, service):
        """Test normalization of English text"""
        result = service.normalize("Hello world", language="en")
    
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:48: AssertionError
_____________ TestNormalizationService.test_normalize_russian_text _____________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16ba00770>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c5e6d9d0>

    def test_normalize_russian_text(self, service):
        """Test normalization of Russian text"""
        result = service.normalize("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", language="ru")
    
        assert result.success
>       assert "–ü—Ä–∏–≤–µ—Ç" in result.normalized
E       AssertionError: assert '–ü—Ä–∏–≤–µ—Ç' in ''
E        +  where '' = NormalizationResult(normalized='', tokens=[], trace=[], errors=[], language='ru', confidence=1.0, original_length=10, ..._core=[], organizations_core=[], persons=[], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:56: AssertionError
____________ TestNormalizationService.test_normalize_with_fallback _____________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16ba0cdd0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1dd0>

    def test_normalize_with_fallback(self, service):
        """Test normalization with fallback behavior"""
        result = service.normalize("Hello world", language="en")
    
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:72: AssertionError
_____ TestNormalizationService.test_normalize_with_auto_language_detection _____

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16ba28380>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1ed0>

    def test_normalize_with_auto_language_detection(self, service):
        """Test normalization with automatic language detection"""
>       result = service.normalize("Hello world", language="auto")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/unit/text_processing/test_normalization_service_fixed.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1ed0>, 'Hello world')
kwargs = {'language': 'auto'}, start_time = 1757965758.751371
execution_time = 0.003823995590209961

    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        start_time = time.time()
        try:
>           result = func(*args, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^

src/ai_service/utils/performance.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1ed0>, 'Hello world')
kwargs = {'language': 'auto'}

    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        # Basic memory monitoring without psutil dependency
        # Just track large input sizes for now
        try:
            # Check if first argument is a string and monitor its size
            if args and isinstance(args[0], str) and len(args[0]) > 1000:
                logger.info(f"Processing large input: {len(args[0])} characters")
    
>           return func(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^

src/ai_service/utils/performance.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1ed0>
text = 'Hello world', language = 'auto', remove_stop_words = True
preserve_names = True, enable_advanced_features = True

    @monitor_performance("normalize")
    @monitor_memory_usage
    def normalize(
        self,
        text: str,
        language: str = "auto",
        remove_stop_words: bool = True,
        preserve_names: bool = True,
        enable_advanced_features: bool = True,
    ) -> NormalizationResult:
        """
        Normalize name text using morphological pipeline
    
        Args:
            text: Input text containing person names
            language: Language code or 'auto' for detection
            remove_stop_words: If False, skip STOP_ALL filtering
            preserve_names: If False, be more aggressive with separators
            enable_advanced_features: If False, skip morphology and advanced features
    
        Returns:
            NormalizationResult with normalized text and trace
        """
>       return self._normalize_sync(
            text, language, remove_stop_words, preserve_names, enable_advanced_features
        )

src/ai_service/layers/normalization/normalization_service.py:390: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4fe4e1ed0>
text = 'Hello world'
language = <Mock name='LanguageDetectionService().detect_language_config_driven().language' id='24612044880'>
remove_stop_words = True, preserve_names = True, enable_advanced_features = True

    def _normalize_sync(
        self,
        text: str,
        language: str = "auto",
        remove_stop_words: bool = True,
        preserve_names: bool = True,
        enable_advanced_features: bool = True,
    ) -> NormalizationResult:
        """
        Normalize name text using morphological pipeline
    
        Args:
            text: Input text containing person names
            language: Language code or 'auto' for detection
            remove_stop_words: If False, skip STOP_ALL filtering
            preserve_names: If False, be more aggressive with separators
            enable_advanced_features: If False, skip morphology and advanced features
    
        Returns:
            NormalizationResult with normalized text and trace
        """
        start_time = time.time()
        errors = []
    
        # Input validation
        if not isinstance(text, str):
            errors.append("Input must be a string")
            return self._create_error_result(text, errors, start_time)
    
        if len(text) > 10000:  # Max length from config
            errors.append(f"Input too long: {len(text)} characters (max 10,000)")
            return self._create_error_result(text, errors, start_time)
    
        # Validate Unicode normalization
        try:
            # Test if string can be properly normalized
            unicodedata.normalize("NFC", text)
        except Exception as e:
            errors.append(f"Invalid Unicode input: {e}")
            return self._create_error_result(text, errors, start_time)
    
        try:
            # Language detection
            if language == "auto":
                from ...config import LANGUAGE_CONFIG
                lang_result = self.language_service.detect_language_config_driven(text, LANGUAGE_CONFIG)
                language = lang_result.language
                confidence = lang_result.confidence
            else:
                confidence = 1.0
    
            # Step 1: Strip noise and tokenize
            tokens = self._strip_noise_and_tokenize(
                text, language, remove_stop_words, preserve_names
            )
    
            # Step 2: Tag roles
            tagged_tokens = self._tag_roles(tokens, language)
            original_tagged_tokens = (
                tagged_tokens.copy()
            )  # Keep original for organization processing
    
            # Step 3: Normalize by role
            if language == "en":
                normalized_tokens, traces = self._normalize_english_tokens(
                    tagged_tokens, language, enable_advanced_features
                )
            elif language == "mixed":
                normalized_tokens, traces = self._normalize_mixed_tokens(
                    tagged_tokens, language, enable_advanced_features
                )
            else:
                normalized_tokens, traces = self._normalize_slavic_tokens(
                    tagged_tokens, language, enable_advanced_features
                )
    
            # Step 4: Separate personal and organization tokens
            person_tokens = []
            org_tokens = []
    
            for token in normalized_tokens:
                if token.startswith("__ORG__"):
                    org_tokens.append(token[7:])  # Remove "__ORG__" prefix
                else:
                    person_tokens.append(token)
    
            # Step 5: Reconstruct personal text with multiple persons detection
            normalized_text = self._reconstruct_text_with_multiple_persons(
                person_tokens, traces, language
            )
    
            # Step 6: Group organization tokens into phrases
            organizations = []
            if org_tokens:
                # Treat each org token as a separate organization
                for token in org_tokens:
                    if token:  # Skip empty tokens
                        organizations.append(token)
    
            processing_time = time.time() - start_time
    
            result = NormalizationResult(
                normalized=normalized_text,
                tokens=person_tokens,
                trace=traces,
                errors=errors,
                language=language,
                confidence=confidence,
                original_length=len(text),
                normalized_length=len(normalized_text),
                token_count=len(person_tokens),
                processing_time=processing_time,
                success=len(errors) == 0,
            )
    
            # Add organization fields
            result.organizations = organizations
            result.org_core = " ".join(organizations) if organizations else ""
            result.organizations_core = organizations  # For signals service
    
            # Group persons and add to result
            # Use original tagged tokens before normalization to preserve separators
            persons = self.group_persons_with_normalized_tokens(original_tagged_tokens, normalized_tokens, traces)
            result.persons = persons
    
            # Extract persons_core for signals service (list of token lists)
            persons_core = []
            if person_tokens:  # person_tokens is the list of normalized person tokens
                persons_core = [person_tokens]  # Wrap in list since it's one person
            result.persons_core = persons_core
    
            return result
    
        except Exception as e:
            self.logger.error(f"Normalization failed: {e}")
            errors.append(str(e))
    
            # Graceful degradation - return capitalized input
            fallback_text = self._graceful_fallback(text)
            processing_time = time.time() - start_time
    
>           return NormalizationResult(
                normalized=fallback_text,
                tokens=[fallback_text] if fallback_text else [],
                trace=[],
                errors=errors,
                language=language,
                confidence=0.0,
                original_length=len(text),
                normalized_length=len(fallback_text),
                token_count=1 if fallback_text else 0,
                processing_time=processing_time,
                success=False,
            )
E           pydantic_core._pydantic_core.ValidationError: 1 validation error for NormalizationResult
E           language
E             Input should be a valid string [type=string_type, input_value=<Mock name='LanguageDetec...guage' id='24612044880'>, input_type=Mock]
E               For further information visit https://errors.pydantic.dev/2.11/v/string_type

src/ai_service/layers/normalization/normalization_service.py:568: ValidationError
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.normalization.normalization_service:normalization_service.py:561 Normalization failed: 2 validation errors for NormalizationResult
language
  Input should be a valid string [type=string_type, input_value=<Mock name='LanguageDetec...guage' id='24612044880'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
confidence
  Input should be a valid number [type=float_type, input_value=<Mock name='LanguageDetec...dence' id='24612045216'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/float_type
ERROR    ai_service.utils.performance:performance.py:34 Error in normalize after 0.004s: 1 validation error for NormalizationResult
language
  Input should be a valid string [type=string_type, input_value=<Mock name='LanguageDetec...guage' id='24612044880'>, input_type=Mock]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
_______ TestNormalizationService.test_normalize_with_special_characters ________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16ba12b30>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c4198950>

    def test_normalize_with_special_characters(self, service):
        """Test normalization with special characters"""
        result = service.normalize("O'Connor", language="en")
    
        assert result.success
>       assert "O'Connor" in result.normalized
E       assert "O'Connor" in "O'connor"
E        +  where "O'connor" = NormalizationResult(normalized="O'connor", tokens=["O'connor"], trace=[TokenTrace(token="O'Connor", role='given', rule...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:132: AssertionError
_____________ TestNormalizationService.test_normalize_sync_method ______________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16b93ee10>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c0ad0ed0>

    def test_normalize_sync_method(self, service):
        """Test normalize_sync method"""
        result = service.normalize_sync("Hello world", language="en")
    
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:147: AssertionError
_____________ TestNormalizationService.test_normalize_async_method _____________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16b93eed0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c4a390d0>

    def test_normalize_async_method(self, service):
        """Test normalize_async method"""
        import asyncio
    
        async def run_test():
            result = await service.normalize_async("Hello world", language="en")
            assert result.success
            assert "Hello world" in result.normalized
    
>       asyncio.run(run_test())

tests/unit/text_processing/test_normalization_service_fixed.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

main = <coroutine object TestNormalizationService.test_normalize_async_method.<locals>.run_test at 0x5c56a4dc0>

    def run(main, *, debug=None, loop_factory=None):
        """Execute the coroutine and return the result.
    
        This function runs the passed coroutine, taking care of
        managing the asyncio event loop, finalizing asynchronous
        generators and closing the default executor.
    
        This function cannot be called when another asyncio event loop is
        running in the same thread.
    
        If debug is True, the event loop will be run in debug mode.
        If loop_factory is passed, it is used for new event loop creation.
    
        This function always creates a new event loop and closes it at the end.
        It should be used as a main entry point for asyncio programs, and should
        ideally only be called once.
    
        The executor is given a timeout duration of 5 minutes to shutdown.
        If the executor hasn't finished within that duration, a warning is
        emitted and the executor is closed.
    
        Example:
    
            async def main():
                await asyncio.sleep(1)
                print('hello')
    
            asyncio.run(main())
        """
        if events._get_running_loop() is not None:
            # fail fast with short traceback
            raise RuntimeError(
                "asyncio.run() cannot be called from a running event loop")
    
        with Runner(debug=debug, loop_factory=loop_factory) as runner:
>           return runner.run(main)
                   ^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py:195: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncio.runners.Runner object at 0x5c5642b50>
coro = <coroutine object TestNormalizationService.test_normalize_async_method.<locals>.run_test at 0x5c56a4dc0>

    def run(self, coro, *, context=None):
        """Run a coroutine inside the embedded event loop."""
        if not coroutines.iscoroutine(coro):
            raise ValueError("a coroutine was expected, got {!r}".format(coro))
    
        if events._get_running_loop() is not None:
            # fail fast with short traceback
            raise RuntimeError(
                "Runner.run() cannot be called from a running event loop")
    
        self._lazy_init()
    
        if context is None:
            context = self._context
        task = self._loop.create_task(coro, context=context)
    
        if (threading.current_thread() is threading.main_thread()
            and signal.getsignal(signal.SIGINT) is signal.default_int_handler
        ):
            sigint_handler = functools.partial(self._on_sigint, main_task=task)
            try:
                signal.signal(signal.SIGINT, sigint_handler)
            except ValueError:
                # `signal.signal` may throw if `threading.main_thread` does
                # not support signals (e.g. embedded interpreter with signals
                # not registered - see gh-91880)
                sigint_handler = None
        else:
            sigint_handler = None
    
        self._interrupt_count = 0
        try:
>           return self._loop.run_until_complete(task)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=True debug=False>
future = <Task finished name='Task-995' coro=<TestNormalizationService.test_normalize_async_method.<locals>.run_test() done, de... 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized")>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def run_test():
        result = await service.normalize_async("Hello world", language="en")
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:156: AssertionError
______________ TestNormalizationService.test_normalize_with_flags ______________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16b9f97b0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c576c3d0>

    def test_normalize_with_flags(self, service):
        """Test normalization with different flags"""
        result = service.normalize(
            "Hello world",
            language="en",
            remove_stop_words=False,
            preserve_names=True,
            enable_advanced_features=True
        )
    
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:171: AssertionError
_________ TestNormalizationService.test_normalize_russian_complex_text _________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16b9f5910>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c576c5d0>

    def test_normalize_russian_complex_text(self, service):
        """Test normalization with complex Russian text"""
        text = "–ü–µ—Ä–µ–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤ –Ω–∞ –∏–º—è –ò–≤–∞–Ω–∞ –ü–µ—Ç—Ä–æ–≤–∞ –æ—Ç –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤–æ–π"
        result = service.normalize(text, language="ru")
    
        assert result.success
        assert "–ò–≤–∞–Ω" in result.normalized
        assert "–ü–µ—Ç—Ä–æ–≤" in result.normalized
>       assert "–ê–Ω–Ω–∞" in result.normalized
E       AssertionError: assert '–ê–Ω–Ω–∞' in '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤'
E        +  where '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤' = NormalizationResult(normalized='–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω—ã –°–º–∏—Ä–Ω–æ–≤', tokens=['–ò–≤–∞–Ω', '–ü–µ—Ç—Ä–æ–≤', '–ê–Ω–Ω—ã', '–°–º–∏—Ä–Ω–æ–≤'], trace=[TokenT...re_female': 0, 'score_male': 7, 'gap': 7}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:216: AssertionError
________ TestNormalizationService.test_normalize_ukrainian_complex_text ________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationService object at 0x16ba2ec50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c6f7aed0>

    def test_normalize_ukrainian_complex_text(self, service):
        """Test normalization with complex Ukrainian text"""
        text = "–ü–µ—Ä–µ–∫–∞–∑ –∫–æ—à—Ç—ñ–≤ –Ω–∞ —ñ–º'—è –Ü–≤–∞–Ω–∞ –ü–µ—Ç—Ä–æ–≤–∞ –≤—ñ–¥ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤–æ—ó"
        result = service.normalize(text, language="uk")
    
        assert result.success
        assert "–Ü–≤–∞–Ω" in result.normalized
        assert "–ü–µ—Ç—Ä–æ–≤" in result.normalized
>       assert "–ê–Ω–Ω–∞" in result.normalized
E       AssertionError: assert '–ê–Ω–Ω–∞' in '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤'
E        +  where '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤' = NormalizationResult(normalized='–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –ê–Ω–Ω–∏ –°–º—ñ—Ä–Ω–æ–≤', tokens=['–Ü–≤–∞–Ω', '–ü–µ—Ç—Ä–æ–≤', '–ê–Ω–Ω–∏', '–°–º—ñ—Ä–Ω–æ–≤'], trace=[TokenT...re_female': 0, 'score_male': 7, 'gap': 7}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_fixed.py:227: AssertionError
__ TestNormalizationServiceConfiguration.test_diminutive_maps_initialization ___

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationServiceConfiguration object at 0x16ba3d7f0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c9412150>

    def test_diminutive_maps_initialization(self, service):
        """Test that diminutive maps are properly initialized"""
        assert isinstance(service.diminutive_maps, dict)
        # Should have maps for supported languages
>       assert 'en' in service.diminutive_maps
E       AssertionError: assert 'en' in {'ru': {'–∞–ª–µ–∫—Å': '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä', '–∞–ª–µ–∫—Å–∞': '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞', '–∞–ª–∏–Ω–∞': '–ê–ª–∏–Ω–∞', '–∞–ª–∏—Å': '–ê–ª–∏—Å–∞', ...}, 'uk': {'–∞–ª–µ–∫—Å': '–û–ª–µ–∫—Å–∞–Ω–¥—Ä', '–∞–ª–µ–∫—Å–∞': '–û–ª–µ–∫—Å–∞–Ω–¥—Ä–∞', '–∞–ª–∏–Ω–∞': '–ê–ª–∏–Ω–∞', '–∞–ª–∫–∞': '–ê–ª–ª–∞', ...}}
E        +  where {'ru': {'–∞–ª–µ–∫—Å': '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä', '–∞–ª–µ–∫—Å–∞': '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞', '–∞–ª–∏–Ω–∞': '–ê–ª–∏–Ω–∞', '–∞–ª–∏—Å': '–ê–ª–∏—Å–∞', ...}, 'uk': {'–∞–ª–µ–∫—Å': '–û–ª–µ–∫—Å–∞–Ω–¥—Ä', '–∞–ª–µ–∫—Å–∞': '–û–ª–µ–∫—Å–∞–Ω–¥—Ä–∞', '–∞–ª–∏–Ω–∞': '–ê–ª–∏–Ω–∞', '–∞–ª–∫–∞': '–ê–ª–ª–∞', ...}} = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c9412150>.diminutive_maps

tests/unit/text_processing/test_normalization_service_fixed.py:292: AssertionError
__________ TestNormalizationResult.test_normalization_result_creation __________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationResult object at 0x16b957b10>

    def test_normalization_result_creation(self):
        """Test NormalizationResult creation"""
        from ai_service.contracts.base_contracts import NormalizationResult
    
>       result = NormalizationResult(
            original_text="test",
            language="en",
            language_confidence=0.9,
            normalized_text="test",
            tokens=["test"],
            trace=[],
            signals=None,
            variants=None,
            embeddings=None,
            decision=None,
            processing_time=0.1,
            success=True,
            errors=[]
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for NormalizationResult
E       normalized
E         Field required [type=missing, input_value={'original_text': 'test',...ss': True, 'errors': []}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.11/v/missing

tests/unit/text_processing/test_normalization_service_fixed.py:304: ValidationError
_________ TestNormalizationResult.test_normalization_result_error_case _________

self = <tests.unit.text_processing.test_normalization_service_fixed.TestNormalizationResult object at 0x16b957c50>

    def test_normalization_result_error_case(self):
        """Test NormalizationResult error case"""
        from ai_service.contracts.base_contracts import NormalizationResult
    
>       result = NormalizationResult(
            original_text="test",
            language="en",
            language_confidence=0.9,
            normalized_text="",
            tokens=[],
            trace=[],
            signals=None,
            variants=None,
            embeddings=None,
            decision=None,
            processing_time=0.1,
            success=False,
            errors=["Test error"]
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for NormalizationResult
E       normalized
E         Field required [type=missing, input_value={'original_text': 'test',...errors': ['Test error']}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.11/v/missing

tests/unit/text_processing/test_normalization_service_fixed.py:328: ValidationError
_____________ TestNormalizationService.test_normalize_english_text _____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b957d90>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16ba2f9d0>

    def test_normalize_english_text(self, service):
        """Test normalization of English text"""
        result = service.normalize("Hello world", language="en")
    
        assert result.success
>       assert "Hello world" in result.normalized
E       AssertionError: assert 'Hello world' in 'Hello World'
E        +  where 'Hello World' = NormalizationResult(normalized='Hello World', tokens=['Hello', 'World'], trace=[TokenTrace(token='Hello', role='given'...re_female': 0, 'score_male': 0, 'gap': 0}}], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_old.py:49: AssertionError
_____________ TestNormalizationService.test_normalize_russian_text _____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba00d60>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5ca1384d0>

    def test_normalize_russian_text(self, service):
        """Test normalization of Russian text"""
        result = service.normalize("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", language="ru")
    
        assert result.success
>       assert "–ü—Ä–∏–≤–µ—Ç" in result.normalized
E       AssertionError: assert '–ü—Ä–∏–≤–µ—Ç' in ''
E        +  where '' = NormalizationResult(normalized='', tokens=[], trace=[], errors=[], language='ru', confidence=1.0, original_length=10, ..._core=[], organizations_core=[], persons=[], person_gender=None, gender_confidence=None, organizations=[], org_core='').normalized

tests/unit/text_processing/test_normalization_service_old.py:57: AssertionError
_________ TestNormalizationService.test_tokenize_text_fallback_to_nltk _________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba3ef90>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5ca138550>

    def test_tokenize_text_fallback_to_nltk(self, service):
        """Test tokenization fallback to NLTK when SpaCy model not available"""
        # Set spacy model to None to force fallback
>       service.language_configs['en']['spacy_model'] = None
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:71: AttributeError
__________ TestNormalizationService.test_tokenize_text_basic_fallback __________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba285a0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c972b2d0>

    def test_tokenize_text_basic_fallback(self, service):
        """Test tokenization basic fallback when neither SpaCy nor NLTK available"""
        # Set both spacy model and NLTK to None to force basic fallback
>       service.language_configs['en']['spacy_model'] = None
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:84: AttributeError
___________ TestNormalizationService.test_remove_stop_words_english ____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba286b0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c419afd0>

    def test_remove_stop_words_english(self, service):
        """Test stop words removal for English"""
        # Mock stop words directly in language_configs
>       service.language_configs['en']['stop_words'] = {"the", "is", "a", "an"}
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:95: AttributeError
___________ TestNormalizationService.test_remove_stop_words_russian ____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba24b50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4ff4453d0>

    def test_remove_stop_words_russian(self, service):
        """Test stop words removal for Russian"""
        # Mock stop words directly in language_configs
>       service.language_configs['ru']['stop_words'] = {"–∏", "–≤", "–Ω–∞", "—Å"}
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:105: AttributeError
___________ TestNormalizationService.test_remove_stop_words_fallback ___________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba24c50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x4896e77d0>

    def test_remove_stop_words_fallback(self, service):
        """Test stop words removal fallback when NLTK not available"""
>       with patch('src.ai_service.layers.normalization.normalization_service._nltk_stopwords', None):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/unit/text_processing/test_normalization_service_old.py:114: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c3c8b8b0>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c3c8b8b0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.ai_service.layers.normalization.normalization_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/normalization/normalization_service.py'> does not have the attribute '_nltk_stopwords'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
_____________ TestNormalizationService.test_apply_stemming_english _____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b8bbc50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c61f7b50>

    def test_apply_stemming_english(self, service):
        """Test stemming for English"""
        # Mock the stemmer in the language config directly
        mock_stemmer = Mock()
        mock_stemmer.stem.side_effect = ["run", "jump", "sleep"]
>       service.language_configs['en']['stemmer'] = mock_stemmer
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:127: AttributeError
_____________ TestNormalizationService.test_apply_stemming_russian _____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b8bb6b0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c0f50ad0>

    def test_apply_stemming_russian(self, service):
        """Test stemming for Russian"""
        # Mock the stemmer in the language config directly
        mock_stemmer = Mock()
        mock_stemmer.stem.side_effect = ["–±–µ–≥", "–ø—Ä—ã–∂–∫", "—Å–ø"]
>       service.language_configs['ru']['stemmer'] = mock_stemmer
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:140: AttributeError
____________ TestNormalizationService.test_apply_stemming_ukrainian ____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba12f90>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x56e4fb150>

    def test_apply_stemming_ukrainian(self, service):
        """Test stemming for Ukrainian"""
        # Mock the stemmer in the language config directly
        mock_stemmer = Mock()
        mock_stemmer.stem.side_effect = ["–±—ñ–≥", "—Å—Ç—Ä–∏–±–∫", "—Å–ø"]
>       service.language_configs['uk']['stemmer'] = mock_stemmer
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:153: AttributeError
____________ TestNormalizationService.test_apply_stemming_fallback _____________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16ba12a50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x56d925550>

    def test_apply_stemming_fallback(self, service):
        """Test stemming fallback when stemmers not available"""
        # Set stemmer to None in language config
>       service.language_configs['en']['stemmer'] = None
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:164: AttributeError
__________ TestNormalizationService.test_apply_lemmatization_english ___________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b93b930>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x56d9256d0>

    def test_apply_lemmatization_english(self, service):
        """Test lemmatization for English"""
        # Mock the SpaCy model in language config directly
        mock_nlp = Mock()
        mock_token1 = Mock()
        mock_token1.lemma_ = "run"
        mock_token1.is_space = False
        mock_token2 = Mock()
        mock_token2.lemma_ = "jump"
        mock_token2.is_space = False
    
        mock_doc = Mock()
        mock_doc.__iter__ = Mock(return_value=iter([mock_token1, mock_token2]))
        mock_nlp.return_value = mock_doc
    
>       service.language_configs['en']['spacy_model'] = mock_nlp
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:187: AttributeError
__________ TestNormalizationService.test_apply_lemmatization_russian ___________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b93f650>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5ba95cd50>

    def test_apply_lemmatization_russian(self, service):
        """Test lemmatization for Russian"""
        # Mock the SpaCy model in language config directly
        mock_nlp = Mock()
        mock_token1 = Mock()
        mock_token1.lemma_ = "–±–µ–≥–∞—Ç—å"
        mock_token1.is_space = False
    
        mock_doc = Mock()
        mock_doc.__iter__ = Mock(return_value=iter([mock_token1]))
        mock_nlp.return_value = mock_doc
    
>       service.language_configs['ru']['spacy_model'] = mock_nlp
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:207: AttributeError
__________ TestNormalizationService.test_apply_lemmatization_fallback __________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationService object at 0x16b93f4d0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c4b3a9d0>

    def test_apply_lemmatization_fallback(self, service):
        """Test lemmatization fallback when SpaCy not available"""
        # Set spacy model to None in language config
>       service.language_configs['en']['spacy_model'] = None
        ^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'NormalizationService' object has no attribute 'language_configs'

tests/unit/text_processing/test_normalization_service_old.py:218: AttributeError
___ TestNormalizationServiceConfiguration.test_initialization_without_spacy ____

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationServiceConfiguration object at 0x16ba6c2d0>

    def test_initialization_without_spacy(self):
        """Test service initialization when SpaCy is not available"""
>       with patch('src.ai_service.layers.normalization.normalization_service.SPACY_AVAILABLE', False), \
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch('src.ai_service.layers.normalization.normalization_service.nlp_en', None), \
             patch('src.ai_service.layers.normalization.normalization_service.nlp_ru', None), \
             patch('src.ai_service.layers.normalization.normalization_service.nlp_uk', None):

tests/unit/text_processing/test_normalization_service_old.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f04b50>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f04b50>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.ai_service.layers.normalization.normalization_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/normalization/normalization_service.py'> does not have the attribute 'SPACY_AVAILABLE'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
____ TestNormalizationServiceConfiguration.test_initialization_without_nltk ____

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationServiceConfiguration object at 0x16ba6c410>

    def test_initialization_without_nltk(self):
        """Test service initialization when NLTK is not available"""
>       with patch('src.ai_service.layers.normalization.normalization_service.NLTK_AVAILABLE', False), \
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch('src.ai_service.layers.normalization.normalization_service._nltk_stopwords', None), \
             patch('src.ai_service.layers.normalization.normalization_service.porter_stemmer', None):

tests/unit/text_processing/test_normalization_service_old.py:570: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f05230>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f05230>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.ai_service.layers.normalization.normalization_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/normalization/normalization_service.py'> does not have the attribute 'NLTK_AVAILABLE'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
_ TestNormalizationServiceConfiguration.test_initialization_minimal_dependencies _

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationServiceConfiguration object at 0x16ba00fc0>

    async def test_initialization_minimal_dependencies(self):
        """Test service initialization with minimal dependencies"""
>       with patch('src.ai_service.layers.normalization.normalization_service.SPACY_AVAILABLE', False), \
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch('src.ai_service.layers.normalization.normalization_service.NLTK_AVAILABLE', False):

tests/unit/text_processing/test_normalization_service_old.py:579: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f057b0>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f057b0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.ai_service.layers.normalization.normalization_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/normalization/normalization_service.py'> does not have the attribute 'SPACY_AVAILABLE'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
________ TestNormalizationServiceConfiguration.test_cache_functionality ________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationServiceConfiguration object at 0x16ba010f0>

    async def test_cache_functionality(self):
        """Test caching functionality"""
>       with patch('src.ai_service.layers.normalization.normalization_service.nlp_en'), \
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
             patch('src.ai_service.layers.normalization.normalization_service.nlp_ru'), \
             patch('src.ai_service.layers.normalization.normalization_service.nlp_uk'):

tests/unit/text_processing/test_normalization_service_old.py:606: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f05bd0>

    def __enter__(self):
        """Perform the patch."""
        if self.is_started:
            raise RuntimeError("Patch is already started")
    
        new, spec, spec_set = self.new, self.spec, self.spec_set
        autospec, kwargs = self.autospec, self.kwargs
        new_callable = self.new_callable
        self.target = self.getter()
    
        # normalise False to None
        if spec is False:
            spec = None
        if spec_set is False:
            spec_set = None
        if autospec is False:
            autospec = None
    
        if spec is not None and autospec is not None:
            raise TypeError("Can't specify spec and autospec")
        if ((spec is not None or autospec is not None) and
            spec_set not in (True, None)):
            raise TypeError("Can't provide explicit spec_set *and* spec or autospec")
    
>       original, local = self.get_original()
                          ^^^^^^^^^^^^^^^^^^^

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x5c2f05bd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'src.ai_service.layers.normalization.normalization_service' from '/Users/dariapavlova/Desktop/ai-service/src/ai_service/layers/normalization/normalization_service.py'> does not have the attribute 'nlp_en'

/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: AttributeError
_________ TestNormalizationResult.test_normalization_result_error_case _________

self = <tests.unit.text_processing.test_normalization_service_old.TestNormalizationResult object at 0x16ba6c690>

    def test_normalization_result_error_case(self):
        """Test NormalizationResult for error scenarios"""
        result = NormalizationResult(
            success=False,
            normalized="Test text",
            tokens=[],
            trace=[],
            language="unknown",
            confidence=0.0,
            original_length=9,
            normalized_length=9,
            token_count=0,
            processing_time=0.05,
            errors=["Processing failed"]
        )
    
        assert result.success == False
>       assert result.error == "Processing failed"
               ^^^^^^^^^^^^

tests/unit/text_processing/test_normalization_service_old.py:675: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = NormalizationResult(normalized='Test text', tokens=[], trace=[], errors=['Processing failed'], language='unknown', con....05, success=False, persons_core=None, organizations_core=None, persons=[], person_gender=None, gender_confidence=None)
item = 'error'

    def __getattr__(self, item: str) -> Any:
        private_attributes = object.__getattribute__(self, '__private_attributes__')
        if item in private_attributes:
            attribute = private_attributes[item]
            if hasattr(attribute, '__get__'):
                return attribute.__get__(self, type(self))  # type: ignore
    
            try:
                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items
                return self.__pydantic_private__[item]  # type: ignore
            except KeyError as exc:
                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
        else:
            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.
            # See `BaseModel.__repr_args__` for more details
            try:
                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')
            except AttributeError:
                pydantic_extra = None
    
            if pydantic_extra:
                try:
                    return pydantic_extra[item]
                except KeyError as exc:
                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc
            else:
                if hasattr(self.__class__, item):
                    return super().__getattribute__(item)  # Raises AttributeError if appropriate
                else:
                    # this is the current error
>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
E                   AttributeError: 'NormalizationResult' object has no attribute 'error'. Did you mean: 'errors'?

venv/lib/python3.13/site-packages/pydantic/main.py:991: AttributeError
____________________ TestUnicodeService.test_final_cleanup _____________________

self = <tests.unit.text_processing.test_unicode_service.TestUnicodeService object at 0x16ba98500>
unicode_service = <src.ai_service.layers.unicode.unicode_service.UnicodeService object at 0x56ec877d0>

    def test_final_cleanup(self, unicode_service):
        """Test final text cleanup"""
        # Arrange
        messy_text = "  Multiple   spaces  \t\n  "
    
        # Act
        result = unicode_service.normalize_text(messy_text)
    
        # Assert
        normalized = result['normalized']
        # UnicodeService doesn't perform space cleanup or case conversion - that's done by other services
>       assert normalized == "  Multiple   spaces  \t\n  "  # Should be unchanged by UnicodeService
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert 'Multiple spaces' == '  Multiple   spaces  \t\n  '
E         
E         -   Multiple   spaces  	
E         ? --         --      ----
E         + Multiple spaces
E         -

tests/unit/text_processing/test_unicode_service.py:182: AssertionError
___________ TestCanaryOverfit.test_context_words_never_become_names ____________

self = <tests.unit.utilities.test_canary_overfit.TestCanaryOverfit object at 0x16ba6ed50>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16bb0c8d0>

    def test_context_words_never_become_names(self, service):
        """Test that context words like '—Ç–∞', '–∏', 'and', '—Ä–∞–∑–æ–º', '–ø—Ä–∞—Ü—é—é—Ç—å' never become given/surname"""
        # Test case from the requirement: "–ü.–Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ, –¢–û–í "–ü–†–ò–í–ê–¢–ë–ê–ù–ö" —Ç–∞ –ü–µ—Ç—Ä–æ—Å—è–Ω –ø—Ä–∞—Ü—é—é—Ç—å —Ä–∞–∑–æ–º"
        text = '–ü.–Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ, –¢–û–í "–ü–†–ò–í–ê–¢–ë–ê–ù–ö" —Ç–∞ –ü–µ—Ç—Ä–æ—Å—è–Ω –ø—Ä–∞—Ü—é—é—Ç—å —Ä–∞–∑–æ–º'
        result = service.normalize(text, language='uk', preserve_names=True)
    
        # Check that context words are not in normalized output
        normalized = result.normalized.lower()
        context_words = ['—Ç–∞', '–ø—Ä–∞—Ü—é—é—Ç—å', '—Ä–∞–∑–æ–º']
    
        for context_word in context_words:
            assert context_word not in normalized, f"Context word '{context_word}' should not appear in normalized output: {result.normalized}"
    
        # Check that only actual names are preserved
        expected_names = ['–ø.—ñ.', '–∫–æ–≤–∞–ª–µ–Ω–∫–æ', '–ø–µ—Ç—Ä–æ—Å—è–Ω']
        for name in expected_names:
>           assert name in normalized, f"Expected name '{name}' not found in normalized output: {result.normalized}"
E           AssertionError: Expected name '–ø.—ñ.' not found in normalized output: –ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ –ü–µ—Ç—Ä–æ—Å—è–Ω
E           assert '–ø.—ñ.' in '–ø. —ñ. –∫–æ–≤–∞–ª–µ–Ω–∫–æ –ø–µ—Ç—Ä–æ—Å—è–Ω'

tests/unit/utilities/test_canary_overfit.py:34: AssertionError
________________ TestCanaryOverfit.test_ukrainian_context_words ________________

self = <tests.unit.utilities.test_canary_overfit.TestCanaryOverfit object at 0x16ba6e850>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x16baf3ed0>

    def test_ukrainian_context_words(self, service):
        """Test Ukrainian context words are never treated as names"""
        context_words = ['—Ç–∞', '—ñ', '–∞–±–æ', '–∞–ª–µ', '—â–æ–±', '—è–∫', '—â–æ', '—Ö—Ç–æ', '–¥–µ', '–∫–æ–ª–∏', '—á–æ–º—É']
        context_words.extend(['–ø—Ä–∞—Ü—é—é—Ç—å', '–ø—Ä–∞—Ü—é—î', '–ø—Ä–∞—Ü—é—é', '–ø—Ä–∞—Ü—é—î–º–æ', '–ø—Ä–∞—Ü—é—î—Ç–µ', '–ø—Ä–∞—Ü—é–≤–∞—Ç–∏'])
        context_words.extend(['—Ä–∞–∑–æ–º', '–æ–∫—Ä–µ–º–æ', '—Ç—É—Ç', '—Ç–∞–º', '—Ç–µ–ø–µ—Ä', '–∑–∞—Ä–∞–∑'])
        context_words.extend(['–¥—É–∂–µ', '–¥–æ—Å–∏—Ç—å', '–º–∞–π–∂–µ', '–∑–æ–≤—Å—ñ–º', '–ø–æ–≤–Ω—ñ—Å—Ç—é', '—á–∞—Å—Ç–∫–æ–≤–æ'])
        context_words.extend(['–¥–æ–±—Ä–µ', '–ø–æ–≥–∞–Ω–æ', '–∫—Ä–∞—â–µ', '–≥—ñ—Ä—à–µ', '–Ω–∞–π–∫—Ä–∞—â–µ', '–Ω–∞–π–≥—ñ—Ä—à–µ'])
        context_words.extend(['–º–æ–∂–µ', '–º–æ–∂–Ω–∞', '–º–æ–∂–ª–∏–≤–æ', '–π–º–æ–≤—ñ—Ä–Ω–æ', '–∑–≤–∏—á–∞–π–Ω–æ'])
        context_words.extend(['—Ç–∞–∫', '–Ω—ñ', '–º–æ–∂–ª–∏–≤–æ'])
    
        for context_word in context_words:
            # Test each context word in a sentence with actual names
            text = f'–Ü–≤–∞–Ω {context_word} –ü–µ—Ç—Ä–æ –ö–æ–≤–∞–ª–µ–Ω–∫–æ'
            result = service.normalize(text, language='uk', preserve_names=True)
    
            # Context word should not appear in normalized output
>           assert context_word not in result.normalized.lower(), f"Context word '{context_word}' should not appear in normalized output: {result.normalized}"
E           AssertionError: Context word '—ñ' should not appear in normalized output: –Ü–≤–∞–Ω –Ü. –ü–µ—Ç—Ä–æ –ö–æ–≤–∞–ª–µ–Ω–∫–æ
E           assert '—ñ' not in '—ñ–≤–∞–Ω —ñ. –ø–µ—Ç—Ä–æ –∫–æ–≤–∞–ª–µ–Ω–∫–æ'
E             
E             '—ñ' is contained here:
E               —ñ–≤–∞–Ω —ñ. –ø–µ—Ç—Ä–æ –∫–æ–≤–∞–ª–µ–Ω–∫–æ
E             ? +

tests/unit/utilities/test_canary_overfit.py:55: AssertionError
_________________ TestCanaryOverfit.test_russian_context_words _________________

self = <tests.unit.utilities.test_canary_overfit.TestCanaryOverfit object at 0x16ba029e0>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5c6cca4d0>

    def test_russian_context_words(self, service):
        """Test Russian context words are never treated as names"""
        context_words = ['–∏', '–∏–ª–∏', '–Ω–æ', '—á—Ç–æ–±—ã', '–∫–∞–∫', '—á—Ç–æ', '–∫—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É']
        context_words.extend(['—Ä–∞–±–æ—Ç–∞—é—Ç', '—Ä–∞–±–æ—Ç–∞–µ—Ç', '—Ä–∞–±–æ—Ç–∞—é', '—Ä–∞–±–æ—Ç–∞–µ–º', '—Ä–∞–±–æ—Ç–∞–µ—Ç–µ', '—Ä–∞–±–æ—Ç–∞—Ç—å'])
        context_words.extend(['–≤–º–µ—Å—Ç–µ', '–æ—Ç–¥–µ–ª—å–Ω–æ', '–∑–¥–µ—Å—å', '—Ç–∞–º', '—Ç–µ–ø–µ—Ä—å', '—Å–µ–π—á–∞—Å'])
        context_words.extend(['–æ—á–µ–Ω—å', '–¥–æ–≤–æ–ª—å–Ω–æ', '–ø–æ—á—Ç–∏', '—Å–æ–≤—Å–µ–º', '–ø–æ–ª–Ω–æ—Å—Ç—å—é', '—á–∞—Å—Ç–∏—á–Ω–æ'])
        context_words.extend(['—Ö–æ—Ä–æ—à–æ', '–ø–ª–æ—Ö–æ', '–ª—É—á—à–µ', '—Ö—É–∂–µ', '–ª—É—á—à–∏–π', '—Ö—É–¥—à–∏–π'])
        context_words.extend(['–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ', '–≤–æ–∑–º–æ–∂–Ω–æ', '–≤–µ—Ä–æ—è—Ç–Ω–æ', '–æ–±—ã—á–Ω–æ'])
        context_words.extend(['–¥–∞', '–Ω–µ—Ç', '–≤–æ–∑–º–æ–∂–Ω–æ'])
    
        for context_word in context_words:
            # Test each context word in a sentence with actual names
            text = f'–ò–≤–∞–Ω {context_word} –ü–µ—Ç—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ'
            result = service.normalize(text, language='ru', preserve_names=True)
    
            # Context word should not appear in normalized output
>           assert context_word not in result.normalized.lower(), f"Context word '{context_word}' should not appear in normalized output: {result.normalized}"
E           AssertionError: Context word '–∏' should not appear in normalized output: –ò–≤–∞–Ω –ü–µ—Ç—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ
E           assert '–∏' not in '–∏–≤–∞–Ω –ø–µ—Ç—Ä –∫–æ–≤–∞–ª–µ–Ω–∫–æ'
E             
E             '–∏' is contained here:
E               –∏–≤–∞–Ω –ø–µ—Ç—Ä –∫–æ–≤–∞–ª–µ–Ω–∫–æ
E             ? +

tests/unit/utilities/test_canary_overfit.py:78: AssertionError
_____________ TestCanaryOverfit.test_mixed_language_context_words ______________

self = <tests.unit.utilities.test_canary_overfit.TestCanaryOverfit object at 0x16baeef90>
service = <ai_service.layers.normalization.normalization_service.NormalizationService object at 0x5ca177e50>

    def test_mixed_language_context_words(self, service):
        """Test mixed language context words are never treated as names"""
        # Test case with mixed Ukrainian and English context words
        text = '–ü.–Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ and –¢–û–í "–ü–†–ò–í–ê–¢–ë–ê–ù–ö" —Ç–∞ –ü–µ—Ç—Ä–æ—Å—è–Ω work together —Ä–∞–∑–æ–º'
        result = service.normalize(text, language='uk', preserve_names=True)
    
        # Context words should not appear in normalized output
        context_words = ['and', '—Ç–∞', 'work', 'together', '—Ä–∞–∑–æ–º']
        normalized = result.normalized.lower()
    
        for context_word in context_words:
>           assert context_word not in normalized, f"Context word '{context_word}' should not appear in normalized output: {result.normalized}"
E           AssertionError: Context word 'and' should not appear in normalized output: –ü. –Ü. –ö–æ–≤–∞–ª–µ–Ω–∫–æ And –ü–µ—Ç—Ä–æ—Å—è–Ω Work Together
E           assert 'and' not in '–ø. —ñ. –∫–æ–≤–∞–ª...ork together'
E             
E             'and' is contained here:
E               –ø. —ñ. –∫–æ–≤–∞–ª–µ–Ω–∫–æ and –ø–µ—Ç—Ä–æ—Å—è–Ω work together
E             ?                 +++

tests/unit/utilities/test_canary_overfit.py:119: AssertionError
________________ TestInputValidator.test_homoglyph_replacement _________________

self = <tests.unit.utilities.test_input_validation.TestInputValidator object at 0x16ba6fd90>
validator = <src.ai_service.utils.input_validation.InputValidator object at 0x5befd2490>

    def test_homoglyph_replacement(self, validator):
        """Test homoglyph character replacement"""
        # Arrange
        text_with_homoglyphs = "P–∞vl–æv"  # Contains Cyrillic '–∞' and '–æ'
    
        # Act
        result = validator.validate_and_sanitize(text_with_homoglyphs, remove_homoglyphs=True)
    
        # Assert
        assert result.is_valid is True
>       assert result.sanitized_text == "Pavlov"  # Should be normalized
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AssertionError: assert 'P–∞vl–æv' == 'Pavlov'
E         
E         - Pavlov
E         + P–∞vl–æv

tests/unit/utilities/test_input_validation.py:48: AssertionError
_______ TestInputValidator.test_suspicion_analysis_high_homoglyph_ratio ________

self = <tests.unit.utilities.test_input_validation.TestInputValidator object at 0x16ba6aa90>
validator = <src.ai_service.utils.input_validation.InputValidator object at 0x5c18881f0>

    def test_suspicion_analysis_high_homoglyph_ratio(self, validator):
        """Test suspicion analysis for high homoglyph ratio"""
        # Arrange
        homoglyph_text = "N–∞m–µ"  # 50% homoglyphs (Cyrillic –∞, –µ)
    
        # Act
        analysis = validator.is_text_suspicious(homoglyph_text)
    
        # Assert
>       assert analysis['is_suspicious'] is True
E       assert False is True

tests/unit/utilities/test_input_validation.py:207: AssertionError
=============================== warnings summary ===============================
tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_smart_filter_skip
tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_validation_error
tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_language_detection_failure
tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_normalization_failure
  /Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py:188: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    if not validation_result.get("should_process", True):
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_normalization_failure
  /opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:2247: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited
    def __init__(self, name, parent):
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
____________________________ test_diminutive_forms _____________________________
----------------------------- Captured stdout call -----------------------------
üîç Testing Diminutive Forms
==================================================

Input: '–ü–µ—Ç—Ä–∏–∫'
Expected base: '–ü–µ—Ç—Ä–æ'
Forms: ["Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 1897, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,masc,inan ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 316, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 2),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 1897, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,masc,inan gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 316, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 488, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 316, 3),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Name,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 1897, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 488, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 3),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 1897, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 488, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 488, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 488, 2),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 316, 7),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 488, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,masc,inan nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 316, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 1897, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,masc,inan accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 316, 5),))", '–ü–µ—Ç—Ä–∏–∫', "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 1897, 2),))"]
‚ùå Expected base form '–ü–µ—Ç—Ä–æ' NOT found
   Available forms: ["Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 1897, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,masc,inan ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 316, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 2),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 1897, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,masc,inan gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 316, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 488, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 316, 3),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Name,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 1897, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 488, 6),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 3),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 1897, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–º', 488, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 488, 1),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 488, 2),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 316, 7),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 488, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,masc,inan nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 316, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–∞', 1897, 4),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,masc,inan accs'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 316, 5),))", '–ü–µ—Ç—Ä–∏–∫', "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim loct'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫', tag=OpencorporaTag('NOUN,Surn,Fixd,femn,anim nomn'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫', 9, 0),))", "Parse(word='–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏–∫–æ–≤—ñ', 1897, 2),))"]

Input: '–°–∞—à–∫–æ'
Expected base: '–û–ª–µ–∫—Å–∞–Ω–¥—Ä'
Forms: ['–°–∞—à–∫–æ', "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 407, 4),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim nomn'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 365, 0),))", "Parse(word='—Å–∞—à–∫–æ–º', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–º', 407, 5),))", "Parse(word='—Å–∞—à–∫–∏', tag=OpencorporaTag('NOUN,Name,femn,anim gent'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∏', 265, 1),))", "Parse(word='—Å–∞—à–∫—É', tag=OpencorporaTag('NOUN,Name,femn,anim accs'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫—É', 265, 3),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 365, 2),))", "Parse(word='—Å–∞—à–∫–æ', tag=OpencorporaTag('NOUN,Name,anim masc,nomn'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ', 407, 0),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim datv'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 265, 2),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 407, 1),))", "Parse(word='—Å–∞—à–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–≤—ñ', 407, 2),))", "Parse(word='—Å–∞—à–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–≤—ñ', 407, 6),))", "Parse(word='—Å–∞—à–∫–æ—é', tag=OpencorporaTag('NOUN,Name,femn,anim ablt'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ—é', 265, 4),))", "Parse(word='—Å–∞—à–∫–∏', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∏', 365, 1),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 365, 5),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim loct'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 265, 5),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,femn,anim nomn'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 265, 0),))", "Parse(word='—Å–∞—à–∫–æ—é', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ—é', 365, 4),))", "Parse(word='—Å–∞—à–∫—É', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫—É', 365, 3),))"]
‚ùå Expected base form '–û–ª–µ–∫—Å–∞–Ω–¥—Ä' NOT found
   Available forms: ['–°–∞—à–∫–æ', "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 407, 4),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim nomn'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 365, 0),))", "Parse(word='—Å–∞—à–∫–æ–º', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–º', 407, 5),))", "Parse(word='—Å–∞—à–∫–∏', tag=OpencorporaTag('NOUN,Name,femn,anim gent'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∏', 265, 1),))", "Parse(word='—Å–∞—à–∫—É', tag=OpencorporaTag('NOUN,Name,femn,anim accs'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫—É', 265, 3),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 365, 2),))", "Parse(word='—Å–∞—à–∫–æ', tag=OpencorporaTag('NOUN,Name,anim masc,nomn'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ', 407, 0),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim datv'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 265, 2),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 407, 1),))", "Parse(word='—Å–∞—à–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–≤—ñ', 407, 2),))", "Parse(word='—Å–∞—à–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='—Å–∞—à–∫–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ–≤—ñ', 407, 6),))", "Parse(word='—Å–∞—à–∫–æ—é', tag=OpencorporaTag('NOUN,Name,femn,anim ablt'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ—é', 265, 4),))", "Parse(word='—Å–∞—à–∫–∏', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∏', 365, 1),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 365, 5),))", "Parse(word='—Å–∞—à—Ü—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim loct'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à—Ü—ñ', 265, 5),))", "Parse(word='—Å–∞—à–∫–∞', tag=OpencorporaTag('NOUN,Name,femn,anim nomn'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–∞', 265, 0),))", "Parse(word='—Å–∞—à–∫–æ—é', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫–æ—é', 365, 4),))", "Parse(word='—Å–∞—à–∫—É', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='—Å–∞—à–∫–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '—Å–∞—à–∫—É', 365, 3),))"]

Input: '–í–æ–≤—á–∏–∫'
Expected base: '–í–æ–ª–æ–¥–∏–º–∏—Ä'
Forms: ["Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,datv'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 197, 2),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,masc,inan gent'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 316, 1),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–º', tag=OpencorporaTag('NOUN,anim masc,ablt'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–º', 197, 5),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,anim masc,accs'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 197, 4),))", "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,anim masc,nomn'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 197, 0),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–º', tag=OpencorporaTag('NOUN,masc,inan ablt'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–º', 316, 6),))", "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,masc,inan accs'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 316, 5),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan loct'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 316, 7),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,anim masc,gent'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 197, 1),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,loct'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 197, 6),))", '–í–æ–≤—á–∏–∫', "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,masc,inan nomn'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 316, 0),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan datv'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 316, 3),))"]
‚ùå Expected base form '–í–æ–ª–æ–¥–∏–º–∏—Ä' NOT found
   Available forms: ["Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,datv'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 197, 2),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,masc,inan gent'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 316, 1),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–º', tag=OpencorporaTag('NOUN,anim masc,ablt'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–º', 197, 5),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,anim masc,accs'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 197, 4),))", "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,anim masc,nomn'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 197, 0),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–º', tag=OpencorporaTag('NOUN,masc,inan ablt'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–º', 316, 6),))", "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,masc,inan accs'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 316, 5),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan loct'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 316, 7),))", "Parse(word='–≤–æ–≤—á–∏–∫–∞', tag=OpencorporaTag('NOUN,anim masc,gent'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–∞', 197, 1),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,loct'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 197, 6),))", '–í–æ–≤—á–∏–∫', "Parse(word='–≤–æ–≤—á–∏–∫', tag=OpencorporaTag('NOUN,masc,inan nomn'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫', 316, 0),))", "Parse(word='–≤–æ–≤—á–∏–∫–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan datv'), normal_form='–≤–æ–≤—á–∏–∫', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≤–æ–≤—á–∏–∫–æ–≤—ñ', 316, 3),))"]

Input: '–ñ–µ–Ω—è'
Expected base: '–Ñ–≤–≥–µ–Ω'
Forms: ["Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim loct'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 5),))", "Parse(word='–∂–µ–Ω–µ—é', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω–µ—é', 786, 4),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 1),))", '–ñ–µ–Ω—è', "Parse(word='–∂–µ–Ω—é', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—é', 786, 3),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim datv'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 2),))", "Parse(word='–∂–µ–Ω—è', tag=OpencorporaTag('NOUN,Name,masc,anim nomn'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—è', 786, 0),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 2),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 5),))", "Parse(word='–∂–µ–Ω–µ—é', tag=OpencorporaTag('NOUN,Name,femn,anim ablt'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω–µ—é', 413, 4),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim gent'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 1),))", "Parse(word='–∂–µ–Ω—è', tag=OpencorporaTag('NOUN,Name,femn,anim nomn'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—è', 413, 0),))", "Parse(word='–∂–µ–Ω—é', tag=OpencorporaTag('NOUN,Name,femn,anim accs'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—é', 413, 3),))"]
‚ùå Expected base form '–Ñ–≤–≥–µ–Ω' NOT found
   Available forms: ["Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim loct'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 5),))", "Parse(word='–∂–µ–Ω–µ—é', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω–µ—é', 786, 4),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 1),))", '–ñ–µ–Ω—è', "Parse(word='–∂–µ–Ω—é', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—é', 786, 3),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim datv'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 2),))", "Parse(word='–∂–µ–Ω—è', tag=OpencorporaTag('NOUN,Name,masc,anim nomn'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—è', 786, 0),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 2),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 786, 5),))", "Parse(word='–∂–µ–Ω–µ—é', tag=OpencorporaTag('NOUN,Name,femn,anim ablt'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω–µ—é', 413, 4),))", "Parse(word='–∂–µ–Ω—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim gent'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—ñ', 413, 1),))", "Parse(word='–∂–µ–Ω—è', tag=OpencorporaTag('NOUN,Name,femn,anim nomn'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—è', 413, 0),))", "Parse(word='–∂–µ–Ω—é', tag=OpencorporaTag('NOUN,Name,femn,anim accs'), normal_form='–∂–µ–Ω—è', score=1.0, methods_stack=((DictionaryAnalyzer(), '–∂–µ–Ω—é', 413, 3),))"]

Input: '–î–∞—à–µ–Ω—å–∫–∞'
Expected base: '–î–∞—Ä—ñ—è'
Forms: ["Parse(word='–¥–∞—à–µ–Ω—å–∫—ñ–π', tag=OpencorporaTag('ADJF femn,datv'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—ñ–π', 5, 11), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∞', tag=OpencorporaTag('NOUN,inan femn,nomn'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∞', 55, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å—Ü—ñ', tag=OpencorporaTag('NOUN,inan femn,datv'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å—Ü—ñ', 55, 2), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å—Ü—ñ', tag=OpencorporaTag('NOUN,inan femn,loct'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å—Ü—ñ', 55, 5), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∞', tag=OpencorporaTag('ADJF femn,nomn'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∞', 5, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∏', tag=OpencorporaTag('NOUN,inan femn,gent'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∏', 55, 1), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—ó', tag=OpencorporaTag('ADJF femn,gent'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—ó', 5, 10), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—É', tag=OpencorporaTag('NOUN,inan femn,accs'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—É', 55, 3), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—é', tag=OpencorporaTag('ADJF femn,ablt'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—é', 5, 13), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—ñ–π', tag=OpencorporaTag('ADJF femn,loct'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—ñ–π', 5, 14), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—é', tag=OpencorporaTag('NOUN,inan femn,ablt'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—é', 55, 4), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—É', tag=OpencorporaTag('ADJF femn,accs'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—É', 5, 12), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", '–î–∞—à–µ–Ω—å–∫–∞']
‚ùå Expected base form '–î–∞—Ä—ñ—è' NOT found
   Available forms: ["Parse(word='–¥–∞—à–µ–Ω—å–∫—ñ–π', tag=OpencorporaTag('ADJF femn,datv'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—ñ–π', 5, 11), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∞', tag=OpencorporaTag('NOUN,inan femn,nomn'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∞', 55, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å—Ü—ñ', tag=OpencorporaTag('NOUN,inan femn,datv'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å—Ü—ñ', 55, 2), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å—Ü—ñ', tag=OpencorporaTag('NOUN,inan femn,loct'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å—Ü—ñ', 55, 5), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∞', tag=OpencorporaTag('ADJF femn,nomn'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∞', 5, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–∏', tag=OpencorporaTag('NOUN,inan femn,gent'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–∏', 55, 1), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—ó', tag=OpencorporaTag('ADJF femn,gent'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—ó', 5, 10), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—É', tag=OpencorporaTag('NOUN,inan femn,accs'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—É', 55, 3), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—é', tag=OpencorporaTag('ADJF femn,ablt'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—é', 5, 13), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—ñ–π', tag=OpencorporaTag('ADJF femn,loct'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—ñ–π', 5, 14), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫–æ—é', tag=OpencorporaTag('NOUN,inan femn,ablt'), normal_form='–¥–∞—à–µ–Ω—å–∫–∞', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫–æ—é', 55, 4), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", "Parse(word='–¥–∞—à–µ–Ω—å–∫—É', tag=OpencorporaTag('ADJF femn,accs'), normal_form='–¥–∞—à–µ–Ω—å–∫–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–¥–∞—à–µ–Ω—å–∫—É', 5, 12), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ–Ω—å–∫–∞')))", '–î–∞—à–µ–Ω—å–∫–∞']

==================================================
Test completed!
_________ TestE2ESanctionsScreening.test_russian_person_with_documents _________
------------------------------ Captured log setup ------------------------------
WARNING  ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'ai_service.layers.variants.ukrainian_morphology'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:150 Failed to initialize variants service: 'VariantGenerationService' object has no attribute 'initialize'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:161 Failed to initialize embeddings service: EmbeddingService.__init__() missing 1 required positional argument: 'config'
___________ TestMultilingualEmbeddings.test_name_variants_similarity ___________
----------------------------- Captured stdout call -----------------------------
Similarity between 'Ivan Petrov' and '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤': 0.912
Similarity between 'Ivan Petrov' and '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤': 0.973
Similarity between '–Ü–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤' and '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤': 0.929
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 4974.04ms > 100ms
________ TestMultilingualEmbeddings.test_organization_names_similarity _________
----------------------------- Captured stdout call -----------------------------
Similarity between 'PrivatBank' and '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫': 0.898
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(2 texts): 3369.41ms > 100ms
_______ TestMultilingualEmbeddings.test_unrelated_strings_low_similarity _______
----------------------------- Captured stdout call -----------------------------
Similarity between 'Ivan Petrov' and 'PrivatBank': 0.255
Similarity between 'Ivan Petrov' and 'random text here': 0.038
Similarity between 'Ivan Petrov' and 'completely different': 0.050
Similarity between 'Ivan Petrov' and 'unrelated content': 0.093
Similarity between 'PrivatBank' and 'random text here': 0.037
Similarity between 'PrivatBank' and 'completely different': 0.006
Similarity between 'PrivatBank' and 'unrelated content': 0.037
Similarity between 'random text here' and 'completely different': 0.103
Similarity between 'random text here' and 'unrelated content': 0.400
Similarity between 'completely different' and 'unrelated content': 0.245
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(5 texts): 4162.09ms > 100ms
______________ TestMultilingualEmbeddings.test_mixed_script_names ______________
----------------------------- Captured stdout call -----------------------------
Similarity between 'Ivan –ü–µ—Ç—Ä–æ–≤' and '–Ü–≤–∞–Ω Petrov': 0.920
Similarity between 'Ivan –ü–µ—Ç—Ä–æ–≤' and '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤': 0.997
Similarity between '–Ü–≤–∞–Ω Petrov' and '–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤': 0.928
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 5572.84ms > 100ms
_______ TestMultilingualEmbeddings.test_common_names_different_languages _______
----------------------------- Captured stdout call -----------------------------
Similarity between 'Alexander' and '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.953
Similarity between 'Alexander' and '–û–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.907
Similarity between '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä' and '–û–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.980
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 6276.09ms > 100ms
____________ TestMultilingualEmbeddings.test_organization_variants _____________
----------------------------- Captured stdout call -----------------------------
Similarity between 'PrivatBank' and '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫': 0.898
Similarity between 'PrivatBank' and '–ü–†–ò–í–ê–¢–ë–ê–ù–ö': 0.379
Similarity between 'PrivatBank' and 'privatbank': 0.953
Similarity between '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫' and '–ü–†–ò–í–ê–¢–ë–ê–ù–ö': 0.423
Similarity between '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫' and 'privatbank': 0.955
Similarity between '–ü–†–ò–í–ê–¢–ë–ê–ù–ö' and 'privatbank': 0.357
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(4 texts): 4414.82ms > 100ms
_______ TestMultilingualEmbeddings.test_embedding_dimensions_consistency _______
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(7 texts): 5321.57ms > 100ms
_________ TestMultilingualEmbeddings.test_preprocessing_effectiveness __________
----------------------------- Captured stdout call -----------------------------
Similarity between preprocessed texts 0 and 1: 0.912
Similarity between preprocessed texts 0 and 2: 0.973
Similarity between preprocessed texts 1 and 2: 0.929
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 4925.78ms > 100ms
____________________ test_critical_ukrainian_normalization _____________________
----------------------------- Captured stdout call -----------------------------
‚úÖ Critical test passed: –û–ø–ª–∞—Ç–∞ –æ—Ç –ü–µ—Ç—Ä–∞ –ü–æ—Ä–æ—à–µ–Ω–∫–∞ –ø–æ –î–æ–≥–æ–≤–æ—Ä—É 123 -> ['–ü–µ—Ç—Ä–æ', '–ü–æ—Ä–æ—à–µ–Ω–∫–æ']
________ TestNormalizationPipeline.test_language_detection_consistency _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestNormalizationPipeline.test_variant_generation_integration _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_________ TestOrchestratorDecisionIntegration.test_high_risk_scenario __________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:415 Slow processing: 0.139s for text: John Doe from ACME Corp with ID 123456789...
_____ TestPipelineEnd2End.test_pipeline_integration[ukrainian_simple_name] _____
------------------------------ Captured log setup ------------------------------
WARNING  ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'ai_service.layers.variants.ukrainian_morphology'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:150 Failed to initialize variants service: 'VariantGenerationService' object has no attribute 'initialize'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:161 Failed to initialize embeddings service: EmbeddingService.__init__() missing 1 required positional argument: 'config'
_________________________ test_normalization_directly __________________________
----------------------------- Captured stdout call -----------------------------
üß™ Testing Normalization Service Directly
==================================================
‚ùå Error testing normalization: module 'ai_service.services' has no attribute 'normalization_service'
----------------------------- Captured stderr call -----------------------------
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/tests/integration/test_simple_normalization.py", line 29, in test_normalization_directly
    with patch('ai_service.services.normalization_service._nltk_stopwords') as mock_stopwords, \
         ~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1481, in __enter__
    self.target = self.getter()
                  ~~~~~~~~~~~^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pkgutil.py", line 528, in resolve_name
    result = getattr(result, p)
AttributeError: module 'ai_service.services' has no attribute 'normalization_service'
_________________________ test_strict_name_extraction __________________________
----------------------------- Captured stdout call -----------------------------
üîç Strict Name Extraction Test (No Mocks)
============================================================
‚ö†Ô∏è  Skipping test - CleanOrchestratorService not available
_______________________ test_ukrainian_morphology_simple _______________________
----------------------------- Captured stdout call -----------------------------
üîç Ukrainian Morphology Simple Test
==================================================
Input: '–°–µ—Ä–≥–µ—è'
Forms: ["Parse(word='—Å–µ—Ä–≥–µ—è', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ—è', 303, 1), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ—î–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ—î–º', 303, 5), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ–π', tag=OpencorporaTag('NOUN,anim masc,nomn'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ–π', 208, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))", "Parse(word='—Å–µ—Ä–≥–µ—î–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,datv'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ—î–≤—ñ', 208, 2), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))", '–°–µ—Ä–≥–µ—è', "Parse(word='—Å–µ—Ä–≥–µ—è', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ—è', 303, 4), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ—è', tag=OpencorporaTag('NOUN,anim masc,accs'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ—è', 208, 4), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))", "Parse(word='—Å–µ—Ä–≥–µ–π', tag=OpencorporaTag('NOUN,Surn,masc,anim nomn'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ–π', 303, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ—î–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ—î–≤—ñ', 303, 6), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ—î–º', tag=OpencorporaTag('NOUN,anim masc,ablt'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ—î–º', 208, 5), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))", "Parse(word='—Å–µ—Ä–≥–µ—î–≤—ñ', tag=OpencorporaTag('NOUN,anim masc,loct'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ—î–≤—ñ', 208, 6), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))", "Parse(word='—Å–µ—Ä–≥–µ—î–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((FakeDictionary(), '—Å–µ—Ä–≥–µ—î–≤—ñ', 303, 2), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–µ—Ä–≥–µ—è')))", "Parse(word='—Å–µ—Ä–≥–µ—è', tag=OpencorporaTag('NOUN,anim masc,gent'), normal_form='—Å–µ—Ä–≥–µ–π', score=1.0, methods_stack=((DictionaryAnalyzer(), '–≥–µ—è', 208, 1), (UnknownPrefixAnalyzer(score_multiplier=0.5), '—Å–µ—Ä')))"]
Types: ['str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str']
All strings: ‚úÖ
Has nominative form: ‚ùå
------------------------------
Input: '–í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞'
Forms: ['–í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', tag=OpencorporaTag('NOUN,Surn,masc,anim nomn'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á', 90, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á–∞', 90, 1), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á–µ–º', 90, 5), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', tag=OpencorporaTag('NOUN,Patr,masc,anim gent'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', 28, 1), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', 90, 6), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', tag=OpencorporaTag('ADJF femn,nomn'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', 5, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á–∞', 90, 4), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', tag=OpencorporaTag('NOUN,Patr,masc,anim datv'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', 28, 2), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—ñ–π', tag=OpencorporaTag('ADJF femn,loct'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—ñ–π', 5, 14), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—ñ–π', tag=OpencorporaTag('ADJF femn,datv'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—ñ–π', 5, 11), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', tag=OpencorporaTag('NOUN,Patr,masc,anim loct'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', 28, 6), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–º', tag=OpencorporaTag('NOUN,Patr,masc,anim ablt'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–º', 28, 5), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—É', tag=OpencorporaTag('ADJF femn,accs'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á—É', 5, 12), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', tag=OpencorporaTag('NOUN,Patr,masc,anim accs'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∞', 28, 4), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–æ—é', tag=OpencorporaTag('ADJF femn,ablt'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–æ—é', 5, 13), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', tag=OpencorporaTag('NOUN,Patr,masc,anim nomn'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', 28, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á', score=1.0, methods_stack=((DictionaryAnalyzer(), '–º–∏—Ä–æ–≤–∏—á–µ–≤—ñ', 90, 2), (UnknownPrefixAnalyzer(score_multiplier=0.5), '–≤–ª–∞–¥–∏')))", "Parse(word='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–æ—ó', tag=OpencorporaTag('ADJF femn,gent'), normal_form='–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–∏–π', score=1.0, methods_stack=((FakeDictionary(), '–≤–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á–æ—ó', 5, 10), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), '–æ–≤–∏—á–∞')))"]
Types: ['str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str']
All strings: ‚úÖ
Has nominative form: ‚ùå
------------------------------
Input: '–ü–µ—Ç—Ä–æ–≤–∞'
Forms: ["Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ–π', tag=OpencorporaTag('ADJF femn,loct'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ–π', 24, 14),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ–π', tag=OpencorporaTag('ADJF femn,datv'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ–π', 24, 11),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤–∞', 285, 1),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∞', 26, 1),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ', tag=OpencorporaTag('NOUN,masc,inan loct'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ', 286, 5),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∞', tag=OpencorporaTag('NOUN,masc,inan gent'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∞', 286, 1),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∏–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∏–º', 26, 4),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤', tag=OpencorporaTag('NOUN,masc,inan nomn'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤', 286, 0),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤—ñ', 285, 9),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∞', tag=OpencorporaTag('NOUN,Surn,femn,anim nomn'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∞', 27, 0),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ', tag=OpencorporaTag('NOUN,Surn,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ', 26, 5),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–æ—ó', tag=OpencorporaTag('ADJF femn,gent'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–æ—ó', 24, 10),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∞', 26, 3),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤–∏–º', tag=OpencorporaTag('NOUN,Surn,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤–∏–º', 285, 7),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–æ—ó', tag=OpencorporaTag('NOUN,Surn,femn,anim gent'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–æ—ó', 27, 1),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤–∞', tag=OpencorporaTag('NOUN,Surn,masc,anim accs'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤–∞', 285, 5),))", '–ü–µ—Ç—Ä–æ–≤–∞', "Parse(word='–ø–µ—Ç—Ä–æ–≤–æ—é', tag=OpencorporaTag('NOUN,Surn,femn,anim ablt'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–æ—é', 27, 4),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—É', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—É', 26, 2),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤', tag=OpencorporaTag('NOUN,Surn,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–æ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤', 26, 0),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–∞', tag=OpencorporaTag('ADJF femn,nomn'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–∞', 24, 9),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–æ—é', tag=OpencorporaTag('ADJF femn,ablt'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–æ—é', 24, 13),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—É', tag=OpencorporaTag('NOUN,Surn,femn,anim accs'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—É', 27, 3),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ–π', tag=OpencorporaTag('NOUN,Surn,femn,anim loct'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ–π', 27, 5),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—É', tag=OpencorporaTag('NOUN,masc,inan datv'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—É', 286, 2),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤–æ–º', tag=OpencorporaTag('NOUN,masc,inan ablt'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤–æ–º', 286, 4),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤', tag=OpencorporaTag('NOUN,masc,inan accs'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤', 286, 3),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—É', tag=OpencorporaTag('ADJF femn,accs'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—É', 24, 12),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤', tag=OpencorporaTag('NOUN,Surn,masc,anim nomn'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤', 285, 0),))", "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ–π', tag=OpencorporaTag('NOUN,Surn,femn,anim datv'), normal_form='–ø–µ—Ç—Ä–æ–≤–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ–π', 27, 2),))", "Parse(word='–ø–µ—Ç—Ä—ñ–≤—É', tag=OpencorporaTag('NOUN,Surn,masc,anim datv'), normal_form='–ø–µ—Ç—Ä—ñ–≤', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ–≤—É', 285, 3),))"]
Types: ['str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str']
All strings: ‚úÖ
Has nominative form: ‚ùå
------------------------------
Input: '–ü–µ—Ç—Ä–∞'
Forms: ["Parse(word='–ø–µ—Ç—Ä—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim loct'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ', 2461, 6),))", "Parse(word='–ø–µ—Ç—Ä—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim loct'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ', 264, 5),))", "Parse(word='–ø–µ—Ç—Ä–∏', tag=OpencorporaTag('NOUN,Name,femn,anim gent'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∏', 264, 1),))", '–ü–µ—Ç—Ä–∞', "Parse(word='–ø–µ—Ç—Ä–æ–≤—ñ', tag=OpencorporaTag('NOUN,Name,masc,anim datv'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–≤—ñ', 2461, 2),))", "Parse(word='–ø–µ—Ç—Ä–æ–º', tag=OpencorporaTag('NOUN,Name,masc,anim ablt'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ–º', 2461, 5),))", "Parse(word='–ø–µ—Ç—Ä—ñ', tag=OpencorporaTag('NOUN,Name,femn,anim datv'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—ñ', 264, 2),))", "Parse(word='–ø–µ—Ç—Ä–∞', tag=OpencorporaTag('NOUN,Name,masc,anim gent'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∞', 2461, 1),))", "Parse(word='–ø–µ—Ç—Ä–∞', tag=OpencorporaTag('NOUN,Name,anim femn,nomn'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∞', 264, 0),))", "Parse(word='–ø–µ—Ç—Ä—É', tag=OpencorporaTag('NOUN,Name,femn,anim accs'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä—É', 264, 3),))", "Parse(word='–ø–µ—Ç—Ä–æ', tag=OpencorporaTag('NOUN,Name,anim masc,nomn'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ', 2461, 0),))", "Parse(word='–ø–µ—Ç—Ä–∞', tag=OpencorporaTag('NOUN,Name,masc,anim accs'), normal_form='–ø–µ—Ç—Ä–æ', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–∞', 2461, 4),))", "Parse(word='–ø–µ—Ç—Ä–æ—é', tag=OpencorporaTag('NOUN,Name,femn,anim ablt'), normal_form='–ø–µ—Ç—Ä–∞', score=1.0, methods_stack=((DictionaryAnalyzer(), '–ø–µ—Ç—Ä–æ—é', 264, 4),))"]
Types: ['str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str']
All strings: ‚úÖ
Has nominative form: ‚ùå
------------------------------
Test completed!
______________ TestEmbeddingsPerformance.test_warmup_performance _______________
----------------------------- Captured stdout call -----------------------------
‚è±Ô∏è  warmup_encode_batch: 6175.27ms
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(10 texts): 6169.07ms > 100ms
_____________ TestEmbeddingsPerformance.test_batch_performance_p95 _____________
----------------------------- Captured stdout call -----------------------------

üìä Performance Results:
   Average latency: 84.55ms
   P95 latency: 176.20ms
   Max latency: 176.20ms
   Total batches: 19
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(10 texts): 13399.52ms > 100ms
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(50 texts): 113.72ms > 100ms
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(50 texts): 125.03ms > 100ms
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(50 texts): 105.75ms > 100ms
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(50 texts): 175.87ms > 100ms
__________ TestEmbeddingsPerformance.test_repeated_batch_performance ___________
----------------------------- Captured stdout call -----------------------------

üîÑ Repeated Batch Performance:
   First run: 4834.64ms
   Second run: 87.58ms
   Speedup: 55.20x
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(20 texts): 4833.52ms > 100ms
__________ TestEmbeddingsPerformance.test_single_vs_batch_performance __________
----------------------------- Captured stdout call -----------------------------

‚ö° Single vs Batch Performance:
   Single encodes: 5540.06ms
   Batch encode: 117.33ms
   Batch efficiency: 47.22x
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(10 texts): 112.78ms > 100ms
____________ TestEmbeddingsPerformance.test_large_batch_performance ____________
----------------------------- Captured stdout call -----------------------------
‚è±Ô∏è  large_batch_encode: 6747.88ms
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(200 texts): 6745.10ms > 100ms
_______ TestEmbeddingsPerformance.test_empty_and_single_text_performance _______
----------------------------- Captured stdout call -----------------------------

üîç Edge Case Performance:
   Empty batch: 0.00ms
   Single text: 18.34ms
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(1 texts): 6158.63ms > 100ms
________ TestLanguageDetectionPerformance.test_single_pass_performance _________
----------------------------- Captured stdout call -----------------------------

Testing performance with 10000 texts...
Performance metrics:
  Total texts processed: 10000
  Total processing time: 0.141s
  Average time per text: 0.014ms
  Texts per second: 71062
  WARNING: Processing took 0.141s (target: <0.1s)
_________ TestLanguageDetectionPerformance.test_edge_case_performance __________
----------------------------- Captured stdout call -----------------------------

Edge case performance:
  Processed 10 edge cases in 0.0001s
  Average time per edge case: 0.009ms
______________ TestMainEndpoints.test_process_text_internal_error ______________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.main:main.py:425 Error processing text: Processing failed
_________________ TestMainEndpoints.test_startup_event_failure _________________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.main:main.py:277 Error initializing orchestrator: Init failed
________________ TestMainEndpoints.test_error_handler_responses ________________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.main:main.py:422 Service unavailable: Service down
ERROR    ai_service.main:main.py:425 Error processing text: Internal error
_________ TestOrchestratorFactory.test_service_initialization_mocking __________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'ai_service.layers.variants.ukrainian_morphology'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:150 Failed to initialize variants service: 'VariantGenerationService' object has no attribute 'initialize'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:161 Failed to initialize embeddings service: EmbeddingService.__init__() missing 1 required positional argument: 'config'
______ TestOrchestratorFactory.test_service_initialization_error_handling ______
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.orchestrator_factory:orchestrator_factory.py:93 Failed to initialize validation service: Service init failed
ERROR    ai_service.core.orchestrator_factory:orchestrator_factory.py:204 Failed to create orchestrator: Validation service: Service init failed
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/orchestrator_factory.py", line 90, in create_orchestrator
    validation_service = ValidationService()
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1228, in _execute_mock_call
    raise effect
Exception: Service init failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/orchestrator_factory.py", line 94, in create_orchestrator
    raise ServiceInitializationError(f"Validation service: {e}")
ai_service.exceptions.ServiceInitializationError: Validation service: Service init failed
_________ TestOrchestratorFactoryIntegration.test_factory_performance __________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:139 Failed to initialize smart filter adapter: object Mock can't be used in 'await' expression
WARNING  ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'ai_service.layers.variants.ukrainian_morphology'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:150 Failed to initialize variants service: 'VariantGenerationService' object has no attribute 'initialize'
WARNING  ai_service.core.orchestrator_factory:orchestrator_factory.py:161 Failed to initialize embeddings service: EmbeddingService.__init__() missing 1 required positional argument: 'config'
__________ TestEmbeddingServiceErrorHandling.test_model_encode_error ___________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.embeddings.embedding_service:embedding_service.py:276 Failed to encode texts: Model encode error
_________ TestEmbeddingServiceErrorHandling.test_memory_error_handling _________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.embeddings.embedding_service:embedding_service.py:276 Failed to encode texts: Out of memory
____________ TestOptimizedEmbeddingService.test_faiss_acceleration _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:optimized_embedding_service.py:391 FAISS search failed, falling back to numpy: FAISS not available
______________ TestOptimizedEmbeddingService.test_error_handling _______________
------------------------------ Captured log call -------------------------------
WARNING  sentence_transformers.SentenceTransformer:SentenceTransformer.py:2046 No sentence-transformers model found with name sentence-transformers/invalid_model_name. Creating a new one with mean pooling.
ERROR    ai_service.layers.embeddings.embedding_service:optimized_embedding_service.py:210 Failed to load optimized model invalid_model_name: sentence-transformers/invalid_model_name is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
ERROR    ai_service.layers.embeddings.embedding_service:optimized_embedding_service.py:342 Failed to generate optimized embeddings: 'types.SimpleNamespace' object has no attribute 'device'
_____________ TestSmartFilterAdapter.test_error_handling_fallback ______________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.smart_filter.smart_filter_adapter:smart_filter_adapter.py:111 SmartFilter processing failed for text: test input... Error: Service error
____________________ test_orchestrator_with_metrics_service ____________________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.requests.total
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.requests.active
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.layer.validation
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.layer.unicode_normalization
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.layer.language_detection
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: language_detection.confidence
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: language_detection.detected.en
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.layer.normalization
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: normalization.confidence
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: normalization.token_count
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.layer.signals
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: signals.confidence
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: signals.persons_count
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: signals.organizations_count
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.total_time
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.requests.active
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: processing.requests.successful
_____________________ TestMetricsService.test_alert_system _____________________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:338 Alert triggered: test.alert_metric_gt_10.0 - Alert: value 15.0 is greater than threshold 10.0
____________________ TestMetricsService.test_alert_cooldown ____________________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:338 Alert triggered: test.cooldown_metric_gt_5.0 - Value 10.0 exceeds threshold 5.0
________________ TestMetricsService.test_memory_usage_tracking _________________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.0
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.1
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.2
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.3
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.4
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.5
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.6
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.7
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.8
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.9
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.10
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.11
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.12
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.13
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.14
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.15
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.16
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.17
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.18
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.19
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.20
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.21
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.22
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.23
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.24
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.25
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.26
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.27
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.28
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.29
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.30
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.31
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.32
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.33
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.34
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.35
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.36
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.37
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.38
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.39
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.40
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.41
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.42
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.43
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.44
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.45
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.46
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.47
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.48
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.49
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.50
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.51
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.52
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.53
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.54
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.55
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.56
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.57
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.58
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.59
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.60
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.61
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.62
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.63
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.64
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.65
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.66
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.67
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.68
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.69
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.70
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.71
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.72
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.73
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.74
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.75
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.76
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.77
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.78
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.79
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.80
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.81
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.82
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.83
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.84
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.85
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.86
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.87
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.88
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.89
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.90
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.91
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.92
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.93
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.94
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.95
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.96
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.97
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.98
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.99
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.100
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.101
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.102
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.103
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.104
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.105
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.106
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.107
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.108
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.109
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.110
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.111
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.112
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.113
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.114
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.115
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.116
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.117
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.118
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.119
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.120
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.121
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.122
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.123
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.124
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.125
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.126
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.127
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.128
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.129
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.130
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.131
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.132
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.133
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.134
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.135
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.136
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.137
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.138
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.139
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.140
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.141
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.142
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.143
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.144
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.145
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.146
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.147
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.148
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.149
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.150
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.151
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.152
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.153
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.154
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.155
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.156
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.157
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.158
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.159
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.160
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.161
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.162
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.163
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.164
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.165
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.166
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.167
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.168
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.169
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.170
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.171
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.172
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.173
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.174
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.175
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.176
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.177
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.178
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.179
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.180
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.181
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.182
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.183
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.184
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.185
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.186
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.187
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.188
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.189
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.190
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.191
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.192
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.193
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.194
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.195
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.196
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.197
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.198
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: memory.test.199
____________________ TestMetricsService.test_error_handling ____________________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: 
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: None
WARNING  ai_service.monitoring.metrics_service:metrics_service.py:192 Recording value for unregistered metric: test.record_histogram
____________ TestOrchestratorMetrics.test_variants_failure_metrics _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:321 Variant generation failed: Variants failed
___________ TestOrchestratorMetrics.test_embeddings_failure_metrics ____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:347 Embedding generation failed: Embeddings failed
____________ TestOrchestratorMetrics.test_decision_failure_metrics _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:396 Decision engine failed: Decision failed
_____________ TestOrchestratorMetrics.test_slow_processing_metrics _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:415 Slow processing: 0.500s for text: test input...
___________ TestOrchestratorMetrics.test_exception_handling_metrics ____________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: Unexpected error
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 247, in process
    lang_result = self.language_service.detect_language_config_driven(
        unicode_normalized,  # Use unicode-normalized text for language detection
        LANGUAGE_CONFIG
    )
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1169, in __call__
    return self._mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1173, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 1228, in _execute_mock_call
    raise effect
RuntimeError: Unexpected error
___________ TestRussianMorphology.test_get_all_forms_with_exception ____________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.russian_morphology:russian_morphology.py:470 Error getting word forms for '–¢–µ—Å—Ç': Parser error
__________ TestRussianMorphology.test_batch_process_names_with_errors __________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.russian_morphology:russian_morphology.py:888 Error processing name '–ú–∞—Ä–∏—è': Processing error
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0421\u0435\u0440\u0433\u0456\u0439-masc-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041e\u043b\u0435\u043d\u0430-femn-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–û–ª–µ–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-masc-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–í–æ–ª–æ–¥–∏–º–∏—Ä': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0414\u0430\u0440\u0456\u044f-femn-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041f\u0435\u0442\u0440\u043e-masc-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u0410\u043d\u043d\u0430-femn-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ê–Ω–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041c\u0438\u0445\u0430\u0439\u043b\u043e-masc-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ú–∏—Ö–∞–π–ª–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_gender_detection_for_ukrainian_names[\u041a\u0430\u0442\u0435\u0440\u0438\u043d\u0430-femn-uk] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ö–∞—Ç–µ—Ä–∏–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_________ TestUkrainianMorphologyAnalyzer.test_diminutives_generation __________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_transliteration_generation ________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e-expected_endings0] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u0406\u0432\u0430\u043d\u0435\u043d\u043a\u043e-expected_endings1] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–Ü–≤–∞–Ω–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u041c\u0435\u043b\u044c\u043d\u0438\u043a-expected_endings2] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ú–µ–ª—å–Ω–∏–∫': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_surname_endings[\u0428\u0435\u0432\u0447\u0435\u043d\u043a\u043e-expected_endings3] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–®–µ–≤—á–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_edge_cases_handling[\u0421\u0435\u0440\u0433\u0456\u0439-expected_result2] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0421\u0435\u0440\u0433\u0456\u0439-expected_ukrainian_chars0] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u041e\u043b\u0435\u043a\u0441\u0456\u0439-expected_ukrainian_chars1] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–û–ª–µ–∫—Å—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-expected_ukrainian_chars2] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–í–æ–ª–æ–¥–∏–º–∏—Ä': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u0414\u0430\u0440\u0456\u044f-expected_ukrainian_chars3] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
_ TestUkrainianMorphologyAnalyzer.test_ukrainian_character_detection[\u041f\u0435\u0442\u0440\u043e-expected_ukrainian_chars4] _
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_name_complexity_analysis _________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_________ TestUkrainianMorphologyAnalyzer.test_gender_correction_logic _________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
____ TestUkrainianMorphologyAnalyzer.test_analyze_name_basic_functionality _____
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_________ TestUkrainianMorphologyAnalyzer.test_auto_language_detection _________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥–µ–π': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_gender_exceptions_dictionary _______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ü–µ—Ç—Ä–æ': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–Ü–≤–∞–Ω': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–í–æ–ª–æ–¥–∏–º–∏—Ä': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ú–∞—Ä—ñ—è': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–û–ª–µ–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ê–Ω–Ω–∞': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_phonetic_variants_generation _______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_regional_transliterations ________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
__________ TestUkrainianMorphologyAnalyzer.test_get_all_forms_method ___________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_is_ukrainian_name_detection _______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ë–æ–≥–¥–∞–Ω': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–Ü–≤–∞–Ω–µ–Ω–∫–æ': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_complexity_level_calculation _______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
__________ TestUkrainianMorphologyAnalyzer.test_basic_transliteration __________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_______ TestUkrainianMorphologyAnalyzer.test_language_detection_internal _______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥–µ–π': 'MorphologicalAnalysis' object has no attribute 'get'
___ TestUkrainianMorphologyAnalyzer.test_pymorphy_analysis_failure_handling ____
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–¢–µ—Å—Ç': Pymorphy analysis failed
______ TestUkrainianMorphologyAnalyzer.test_generate_pymorphy_declensions ______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
______ TestUkrainianMorphologyAnalyzer.test_extract_gender_with_name_tags ______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–î–∞—Ä—å—è': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_extract_gender_by_endings ________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ù–æ–≤–∏–π': 'MorphologicalAnalysis' object has no attribute 'get'
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–ù–æ–≤–∞': 'MorphologicalAnalysis' object has no attribute 'get'
_____ TestUkrainianMorphologyAnalyzer.test_apply_regional_transliteration ______
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
________ TestUkrainianMorphologyAnalyzer.test_whitespace_name_handling _________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_____________ TestDecisionLogic.test_update_thresholds_invalid_key _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.smart_filter.decision_logic:decision_logic.py:656 Unknown threshold key: invalid_key
______________ TestSmartFilterService.test_service_words_cleaning ______________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.smart_filter.smart_filter_service:smart_filter_service.py:479 _clean_service_words is deprecated - use context-aware analysis instead
_____________ TestDecisionLogic.test_update_thresholds_invalid_key _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.smart_filter.decision_logic:decision_logic.py:656 Unknown threshold key: invalid_key
____________ TestEmbeddingContract.test_encode_batch_returns_2x384 _____________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(2 texts): 4330.94ms > 100ms
__________ TestEmbeddingContract.test_encode_batch_mixed_valid_empty ___________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(4 texts): 4348.88ms > 100ms
_______ TestEmbeddingModelSwitch.test_model_switch_with_batch_processing _______
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(4 texts): 8506.61ms > 100ms
___________ TestEmbeddingPreprocessor.test_include_attrs_future_flag ___________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.services.embedding_preprocessor:embedding_preprocessor.py:77 include_attrs=True not yet implemented, using default behavior
_____ TestEmbeddingsCanaryNames.test_multilingual_name_triangle_similarity _____
----------------------------- Captured stdout call -----------------------------
Similarity 'Oleksandr' ~ '–û–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.632
Similarity 'Oleksandr' ~ '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.620
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä' ~ '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä': 0.980
Min similarity: 0.620
Avg similarity: 0.744
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 3302.11ms > 100ms
_________ TestEmbeddingsCanaryNames.test_name_vs_noise_low_similarity __________
----------------------------- Captured stdout call -----------------------------
Similarity 'Ivan Petrov' ~ 'invoice 12345': 0.002
Similarity 'Ivan Petrov' ~ 'document 67890': 0.259
Similarity 'Ivan Petrov' ~ 'report 2023': 0.259
Similarity 'Ivan Petrov' ~ 'file 98765': 0.110
Similarity 'Ivan Petrov' ~ 'data 54321': 0.105
Similarity 'Ivan Petrov' ~ 'system 11111': -0.019
Similarity 'Ivan Petrov' ~ 'error 404': 0.039
Similarity 'Ivan Petrov' ~ 'status 200': 0.114
Similarity 'Anna Smith' ~ 'invoice 12345': 0.114
Similarity 'Anna Smith' ~ 'document 67890': 0.244
Similarity 'Anna Smith' ~ 'report 2023': 0.261
Similarity 'Anna Smith' ~ 'file 98765': 0.166
Similarity 'Anna Smith' ~ 'data 54321': 0.161
Similarity 'Anna Smith' ~ 'system 11111': 0.144
Similarity 'Anna Smith' ~ 'error 404': 0.148
Similarity 'Anna Smith' ~ 'status 200': 0.247
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'invoice 12345': 0.143
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'document 67890': 0.276
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'report 2023': 0.280
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'file 98765': 0.177
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'data 54321': 0.149
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'system 11111': 0.099
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'error 404': 0.086
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'status 200': 0.185
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'invoice 12345': 0.026
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'document 67890': 0.080
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'report 2023': 0.121
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'file 98765': -0.003
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'data 54321': 0.010
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'system 11111': -0.018
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'error 404': -0.008
Similarity '–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω' ~ 'status 200': 0.056
Max name-noise similarity: 0.280
Avg name-noise similarity: 0.125
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(4 texts): 3314.05ms > 100ms
__ TestEmbeddingsCanaryNames.test_organization_vs_personal_names_distinction ___
----------------------------- Captured stdout call -----------------------------
Similarity 'Ivan Petrov' ~ 'Apple Inc': 0.084
Similarity 'Ivan Petrov' ~ 'Microsoft Corporation': 0.043
Similarity 'Ivan Petrov' ~ '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫': 0.226
Similarity 'Ivan Petrov' ~ '–û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞': 0.522
Similarity 'Anna Smith' ~ 'Apple Inc': 0.236
Similarity 'Anna Smith' ~ 'Microsoft Corporation': 0.252
Similarity 'Anna Smith' ~ '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫': 0.205
Similarity 'Anna Smith' ~ '–û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞': 0.349
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'Apple Inc': 0.029
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ 'Microsoft Corporation': 0.090
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ '–ü—Ä–∏–≤–∞—Ç–±–∞–Ω–∫': 0.193
Similarity '–û–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–æ–≤–∞–ª–µ–Ω–∫–æ' ~ '–û–û–û –†–æ–≥–∞ –∏ –ö–æ–ø—ã—Ç–∞': 0.777
Avg personal-org similarity: 0.251
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 4102.02ms > 100ms
_________ TestEmbeddingsCanaryNames.test_empty_and_whitespace_handling _________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(4 texts): 3603.40ms > 100ms
________ TestEmbeddingsCanaryNames.test_preprocessing_removes_dates_ids ________
----------------------------- Captured stdout call -----------------------------
Preprocessing similarity 0: 1.000
Preprocessing similarity 1: 1.000
Preprocessing similarity 2: 1.000
------------------------------ Captured log call -------------------------------
WARNING  ai_service.layers.embeddings.embedding_service:embedding_service.py:184 Slow encode_batch(3 texts): 4083.00ms > 100ms
____________ TestMorphologyIntegration.test_ukrainian_name_analysis ____________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.ukrainian_morphology:ukrainian_morphology.py:158 Error analyzing word '–°–µ—Ä–≥—ñ–π': 'MorphologicalAnalysis' object has no attribute 'get'
_____________ TestMorphologyIntegration.test_russian_name_analysis _____________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.normalization.morphology.russian_morphology:russian_morphology.py:152 Error analyzing word '–°–µ—Ä–≥–µ–π': 'MorphologicalAnalysis' object has no attribute 'get'
___ TestLanguageDetectionCanaryRandomNoise.test_random_noise_low_confidence ____
----------------------------- Captured stdout call -----------------------------

Random noise analysis:
  Total strings: 100
  Unknown language: 0 (0.0%)
  Mixed language: 45 (45.0%)
  Low confidence (‚â§0.8): 91 (91.0%)
  High confidence (>0.8): 9 (9.0%)
  Perfect confidence (1.0): 0

High confidence examples (may indicate overfitting):
  1. '–í—Ä8–§–∫–Æ8“ëCZ_5—ä fw{"y–î<T—å1&D5–õ–ë1...' -> ru (0.900)
  2. 'Lo –≠—ë)6yDJ!185–•–∞ { 8;-—ÉX!F–ú;—ç^...' -> ru (0.811)
  3. '–†–Ñ$\|35—á20C–ú1:2“ë<r{' –ô" —ã? <–†—î...' -> uk (0.967)
  4. '–¨4–ù–¶ & Pz–æ"—ä9 –ò–ø3–Ü—ä[j9—Å Z–≥–õ3b—ë...' -> ru (0.955)
  5. '9P9U–´–û—é–Ω–¶jnX7$8–ó ylIw43 –ï–ï37wY...' -> uk (0.894)
_____ TestUnifiedOrchestrator.test_process_with_language_detection_failure _____
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.core.unified_orchestrator:unified_orchestrator.py:396 Decision engine failed: max() iterable argument is empty
_______ TestUnifiedOrchestrator.test_process_with_normalization_failure ________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.core.unified_orchestrator:unified_orchestrator.py:396 Decision engine failed: max() iterable argument is empty
_____ TestUnifiedOrchestrator.test_process_with_language_detection_failure _____
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
_______ TestUnifiedOrchestrator.test_process_with_normalization_failure ________
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: object Mock can't be used in 'await' expression
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 202, in process
    filter_result = await self.smart_filter_service.should_process(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        context.sanitized_text
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
TypeError: object Mock can't be used in 'await' expression
____________ TestRunServiceScript.test_check_python_version_invalid ____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:29 Python 3.12 or higher required
ERROR    run_service:run_service.py:30 Current version: 3.13.7 (main, Aug 14 2025, 11:12:11) [Clang 17.0.0 (clang-1700.0.13.3)]
_____________ TestRunServiceScript.test_check_poetry_not_available _____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:47 Poetry not found
_____________ TestRunServiceScript.test_check_dependencies_failure _____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:60 Error installing dependencies: Dependency installation failed
____________ TestRunServiceScript.test_check_dependencies_exception ____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:63 Error: Unexpected error
_ TestRunServiceScript.test_check_spacy_models_some_missing_auto_install_success _
------------------------------ Captured log call -------------------------------
WARNING  run_service:run_service.py:82 SpaCy model en_core_web_sm not found
___ TestRunServiceScript.test_check_spacy_models_all_missing_no_auto_install ___
------------------------------ Captured log call -------------------------------
WARNING  run_service:run_service.py:82 SpaCy model en_core_web_sm not found
WARNING  run_service:run_service.py:82 SpaCy model ru_core_news_sm not found
ERROR    run_service:run_service.py:101 Error: Install failed
ERROR    run_service:run_service.py:101 Error: Install failed
____________ TestRunServiceScript.test_run_service_no_service_file _____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:118 Service file not found: <Mock id='17121257392'>
_______________ TestRunServiceScript.test_run_service_exception ________________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:135 Error starting service: Unexpected error
______________ TestRunServiceScript.test_main_python_check_fails _______________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:162 Some checks failed
______________ TestRunServiceScript.test_main_poetry_check_fails _______________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:162 Some checks failed
___________ TestRunServiceScript.test_main_dependencies_check_fails ____________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:162 Some checks failed
______________ TestRunServiceScript.test_main_models_check_fails _______________
------------------------------ Captured log call -------------------------------
ERROR    run_service:run_service.py:162 Some checks failed
________ TestTemplateBuilder.test_build_templates_batch_error_handling _________
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.layers.variants.template_builder:template_builder.py:244 Failed to create template for entity 0: Error
___________ TestTemplateBuilder.test_template_builder_error_handling ___________
------------------------------ Captured log call -------------------------------
ERROR    src.ai_service.layers.variants.template_builder:template_builder.py:180 Failed to create template for entity : Pattern generation failed
_________ TestUnifiedOrchestrator.test_backward_compatibility_methods __________
------------------------------ Captured log call -------------------------------
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:580 normalize_async is deprecated. Use process() instead.
WARNING  ai_service.core.unified_orchestrator:unified_orchestrator.py:609 extract_signals is deprecated. Use process() instead.
_____ TestUnifiedOrchestratorEdgeCases.test_service_initialization_failure _____
------------------------------ Captured log call -------------------------------
ERROR    ai_service.core.unified_orchestrator:unified_orchestrator.py:439 Processing failed: Service failed
Traceback (most recent call last):
  File "/Users/dariapavlova/Desktop/ai-service/src/ai_service/core/unified_orchestrator.py", line 180, in process
    validation_result = await self.validation_service.validate_and_sanitize(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        text
        ^^^^
    )
    ^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py", line 2321, in _execute_mock_call
    raise effect
Exception: Service failed
_____ TestVariantGenerationService.test_transliteration_variants_grigoriy ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_compound_surname_processing _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____ TestVariantGenerationService.test_basic_transliteration_functionality _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_multiple_transliteration_standards _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_phonetic_variants_generation ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_______ TestVariantGenerationService.test_visual_similarities_generation _______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
__________ TestVariantGenerationService.test_typo_variants_generation __________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_comprehensive_variants_generation ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____________ TestVariantGenerationService.test_empty_text_handling _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_none_text_handling _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_max_variants_limit _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_language_specific_processing ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
______ TestVariantGenerationService.test_find_best_matches_functionality _______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
___________ TestVariantGenerationService.test_similarity_calculation ___________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
__________ TestVariantGenerationService.test_keyboard_layout_variants __________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_morphological_variants_integration _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_______ TestVariantGenerationService.test_morphological_variants_mocked ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
___________ TestVariantGenerationService.test_processing_statistics ____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_duplicate_removal ______________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____ TestVariantGenerationService.test_case_preservation_and_normalization _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_special_characters_handling _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_performance_with_long_names _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_error_handling_in_transliteration ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_variant_scores_match_config _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_ test_russian_full_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0434\u043b\u044f \u0412\u043e\u043b\u043e\u0434\u0438 \u0412\u044b\u0441\u043e\u0446\u043a\u043e\u0433\u043e-\u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440 \u0412\u044b\u0441\u043e\u0446\u043a\u0438\u0439] _
----------------------------- Captured stdout call -----------------------------

DEBUG - Input: '–û–ø–ª–∞—Ç–∞ –¥–ª—è –í–æ–ª–æ–¥–∏ –í—ã—Å–æ—Ü–∫–æ–≥–æ'
DEBUG - Expected: '–í–ª–∞–¥–∏–º–∏—Ä –í—ã—Å–æ—Ü–∫–∏–π'
DEBUG - Actual: '–í–ª–∞–¥–∏–º–∏—Ä –í—ã—Å–æ—Ü–∫–∏–π'
DEBUG - Fresh service result: '–í–ª–∞–¥–∏–º–∏—Ä –í—ã—Å–æ—Ü–∫–∏–π'
DEBUG - Fresh _morph_nominal('–í—ã—Å–æ—Ü–∫–æ–≥–æ', 'ru') = '–í—ã—Å–æ—Ü–∫–∏–π'
DEBUG - Fresh ru_morph available: True
DEBUG - Fresh ru_morph type: <class 'pymorphy3.analyzer.MorphAnalyzer'>
________ TestUnicodeService.test_unicode_normalization_failure_handling ________
------------------------------ Captured log call -------------------------------
WARNING  src.ai_service.layers.unicode.unicode_service:unicode_service.py:359 Unicode normalization failed: Unicode normalization failed
_____ TestVariantGenerationService.test_transliteration_variants_grigoriy ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_compound_surname_processing _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____ TestVariantGenerationService.test_basic_transliteration_functionality _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_multiple_transliteration_standards _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_phonetic_variants_generation ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_______ TestVariantGenerationService.test_visual_similarities_generation _______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
__________ TestVariantGenerationService.test_typo_variants_generation __________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_comprehensive_variants_generation ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____________ TestVariantGenerationService.test_empty_text_handling _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_none_text_handling _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_max_variants_limit _____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_language_specific_processing ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
______ TestVariantGenerationService.test_find_best_matches_functionality _______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
___________ TestVariantGenerationService.test_similarity_calculation ___________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
__________ TestVariantGenerationService.test_keyboard_layout_variants __________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_morphological_variants_integration _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_______ TestVariantGenerationService.test_morphological_variants_mocked ________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
___________ TestVariantGenerationService.test_processing_statistics ____________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____________ TestVariantGenerationService.test_duplicate_removal ______________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
____ TestVariantGenerationService.test_case_preservation_and_normalization _____
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_special_characters_handling _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_performance_with_long_names _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
_____ TestVariantGenerationService.test_error_handling_in_transliteration ______
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________ TestVariantGenerationService.test_variant_scores_match_config _________
------------------------------ Captured log setup ------------------------------
WARNING  src.ai_service.layers.variants.variant_generation_service:variant_generation_service.py:392 Ukrainian morphology analyzer not available: No module named 'src.ai_service.layers.variants.ukrainian_morphology'
________________ TestValidationService.test_initialize_failure _________________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.validation.validation_service:validation_service.py:37 Failed to initialize ValidationService: Init failed
_____ TestValidationService.test_validate_and_sanitize_exception_handling ______
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.validation.validation_service:validation_service.py:72 Validation failed for text: test text... Error: Validation error
__________ TestValidationService.test_validate_and_sanitize_long_text __________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.validation.validation_service:validation_service.py:72 Validation failed for text: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa... Error: Text too long
_________ TestValidationService.test_validate_and_sanitize_none_input __________
------------------------------ Captured log call -------------------------------
ERROR    ai_service.layers.validation.validation_service:validation_service.py:72 Validation failed for text: None... Error: None input
- generated xml file: /Users/dariapavlova/Desktop/ai-service/reports/junit.xml -
============================= slowest 25 durations =============================
15.07s call     tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_batch_performance_p95
12.04s call     tests/unit/test_embedding_config.py::TestEmbeddingService::test_single_text_encoding
11.89s call     tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServicePerformance::test_model_cache_efficiency
10.90s call     tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_preserves_functionality
10.24s call     tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceIntegration::test_real_world_embedding_scenarios
10.19s call     tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_confidence_scores_limit
9.88s call     tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_confidence_scores_limit
9.70s call     tests/unit/test_embedding_config.py::TestEmbeddingService::test_multiple_texts_encoding
8.51s call     tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_with_batch_processing
8.39s setup    tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_compound_surnames
8.14s call     tests/unit/test_embedding_config.py::TestEmbeddingService::test_device_from_config
7.62s call     tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_single_text
7.59s call     tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceIntegration::test_multilingual_support
6.75s call     tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_large_batch_performance
6.63s call     tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_enable_index_ignored
6.63s call     tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServicePerformance::test_processing_time_tracking
6.28s call     tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_common_names_different_languages
6.22s setup    tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_ukrainian_name_pipeline
6.19s call     tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_empty_and_single_text_performance
6.19s call     tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_warmup_performance
5.68s call     tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_single_vs_batch_performance
5.57s call     tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_mixed_script_names
5.32s call     tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_embedding_dimensions_consistency
5.26s call     tests/unit/test_embedding_config.py::TestEmbeddingService::test_lazy_initialization
5.10s call     tests/unit/test_embedding_config.py::TestEmbeddingService::test_model_info
=========================== short test summary info ============================
PASSED tmp/tests/e2e/test_full_pipeline_risk.py::TestFullPipelineRiskE2E::test_full_pipeline_high_risk_scenario
PASSED tmp/tests/e2e/test_full_pipeline_risk.py::TestFullPipelineRiskE2E::test_decision_engine_integration_with_mock_data
PASSED tmp/tests/e2e/test_full_pipeline_risk.py::TestFullPipelineRiskE2E::test_api_response_format_with_risk_fields
PASSED tmp/tests/e2e/test_full_pipeline_risk.py::TestFullPipelineRiskE2E::test_pipeline_with_different_risk_levels
PASSED tmp/tests/e2e/test_full_pipeline_risk.py::TestFullPipelineRiskE2E::test_pipeline_error_handling
PASSED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_nightmare_scenario_gnatyuk_abdullaev
PASSED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_multilingual_nightmare
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_high_risk_sanctioned_individual
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_low_risk_common_name
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_homoglyph_obfuscation_detection
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_zero_width_character_obfuscation
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_mixed_cyrillic_latin_text
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_payment_context_screening
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_multi_language_entity_screening
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_error_recovery_and_graceful_degradation
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_risk_level_classification_accuracy
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_vector_similarity_integration
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_configuration_driven_processing
PASSED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_language_detection_integration
PASSED tmp/tests/integration/test_api_risk_response.py::TestAPIRiskResponse::test_process_endpoint_response_format
PASSED tmp/tests/integration/test_api_risk_response.py::TestAPIRiskResponse::test_process_endpoint_response_without_decision_engine
PASSED tmp/tests/integration/test_api_risk_response.py::TestAPIRiskResponse::test_decision_output_serialization
PASSED tmp/tests/integration/test_api_risk_response.py::TestAPIRiskResponse::test_risk_level_values
PASSED tmp/tests/integration/test_diminutive_forms.py::test_diminutive_forms
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_russian_person_with_documents
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_ukrainian_organization_with_legal_form
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_english_mixed_script_name
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_complex_payment_description
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_edge_case_compound_names
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_decision_engine_thresholds
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_metrics_collection
PASSED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_performance_benchmarks
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_name_variants_similarity
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_organization_names_similarity
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_unrelated_strings_low_similarity
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_mixed_script_names
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_common_names_different_languages
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_organization_variants
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_embedding_dimensions_consistency
PASSED tmp/tests/integration/test_embeddings_multilingual.py::TestMultilingualEmbeddings::test_preprocessing_effectiveness
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0437\u0430 \u043f\u043e\u0441\u043b\u0443\u0433\u0438, \u043f\u043b\u0430\u0442\u043d\u0438\u043a \u041f\u0435\u0442\u0440\u0438\u043a \u041f.-\u041f\u0435\u0442\u0440\u043e \u041f.]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u041f\u0435\u0442\u0440\u0443\u0441\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430, \u0437\u0430 \u0440\u0435\u043c\u043e\u043d\u0442-\u041f\u0435\u0442\u0440\u043e \u0406\u0432\u0430\u043d\u043e\u0432]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041f\u0435\u0440\u0435\u043a\u0430\u0437 \u0432\u0456\u0434 \u0412\u043e\u0432\u0447\u0438\u043a\u0430 \u0417\u0435\u043b\u0435\u043d\u0441\u044c\u043a\u043e\u0433\u043e \u0412. \u041e.-\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440 \u0417\u0435\u043b\u0435\u043d\u0441\u044c\u043a\u0438\u0439 \u0412. \u041e.]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041f\u043e\u0434\u0430\u0440\u0443\u043d\u043e\u043a \u0434\u043b\u044f \u0414\u0430\u0448\u0435\u043d\u044c\u043a\u0438 \u041a\u0432\u0456\u0442\u043a\u043e\u0432\u043e\u0457-\u0414\u0430\u0440\u0456\u044f \u041a\u0432\u0456\u0442\u043a\u043e\u0432\u0430]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0412\u0456\u0434 \u0421\u0430\u0448\u043a\u0430 \u041f\u043e\u043b\u043e\u0436\u0438\u043d\u0441\u044c\u043a\u043e\u0433\u043e \u0437\u0430 \u043a\u0432\u0438\u0442\u043a\u0438-\u041e\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440 \u041f\u043e\u043b\u043e\u0436\u0438\u043d\u0441\u044c\u043a\u0438\u0439]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0414\u044f\u043a\u0443\u0454\u043c\u043e \u0421\u0435\u0440\u0433\u0456\u0454\u0432\u0456 \u0416\u0430\u0434\u0430\u043d\u0443 \u0437\u0430 \u0442\u0432\u043e\u0440\u0447\u0456\u0441\u0442\u044c-\u0421\u0435\u0440\u0433\u0456\u0439 \u0416\u0430\u0434\u0430\u043d]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041f\u043e\u0434\u0430\u0440\u0443\u043d\u043e\u043a \u0434\u043b\u044f \u041e\u043a\u0441\u0430\u043d\u0438 \u0417\u0430\u0431\u0443\u0436\u043a\u043e-\u041e\u043a\u0441\u0430\u043d\u0430 \u0417\u0430\u0431\u0443\u0436\u043a\u043e]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041f\u043b\u0442\u0456\u0436 \u0432\u0456\u0434 \u0412'\u044f\u0447\u0435\u0441\u043b\u0430\u0432\u0430 \u0432\u0430\u043a\u0430\u0440\u0447\u0443\u043a\u0430 (\u043e\u043a\u0435\u0430\u043d \u0435\u043b\u044c\u0437\u0438)-\u0412'\u044f\u0447\u0435\u0441\u043b\u0430\u0432 \u0412\u0430\u043a\u0430\u0440\u0447\u0443\u043a]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u041f\u0435\u0440\u0435\u043a\u0430\u0437 \u041e\u041b\u0415\u0413\u0423 \u0421\u041a\u0420\u0418\u041f\u0426\u0406-\u041e\u043b\u0435\u0433 \u0421\u043a\u0440\u0438\u043f\u043a\u0430]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u0430 \u0421.\u0412.-\u0406\u0432\u0430\u043d\u043e\u0432-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e \u0421. \u0412.]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u041f\u0435\u0440\u0435\u0432\u043e\u0434 \u043e\u0442 \u0421\u0430\u0448\u0438 \u041f\u0443\u0448\u043a\u0438\u043d\u0430 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447\u0430-\u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440 \u041f\u0443\u0448\u043a\u0438\u043d \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0434\u043b\u044f \u0412\u043e\u043b\u043e\u0434\u0438 \u0412\u044b\u0441\u043e\u0446\u043a\u043e\u0433\u043e-\u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440 \u0412\u044b\u0441\u043e\u0446\u043a\u0438\u0439]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u041f\u043b\u0430\u0442\u0451\u0436 \u043e\u0442 \u0414\u0438\u043c\u044b \u041c\u0435\u0434\u0432\u0435\u0434\u0435\u0432\u0430-\u0414\u043c\u0438\u0442\u0440\u0438\u0439 \u041c\u0435\u0434\u0432\u0435\u0434\u0435\u0432]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u041f\u0435\u0440\u0435\u0432\u043e\u0434 \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u0418\u0432\u0430\u043d\u0443 \u0411\u0443\u043d\u0438\u043d\u0443-\u0418\u0432\u0430\u043d \u0411\u0443\u043d\u0438\u043d]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0434\u043b\u044f \u0415\u0441\u0435\u043d\u0438\u043d\u0430 \u0421. \u0410.-\u0415\u0441\u0435\u043d\u0438\u043d \u0421. \u0410.]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u0417\u0430\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0442 \u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432\u0430 \u041c.\u042e.-\u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432 \u041c. \u042e.]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[Payment from John Fitzgerald Kennedy-John Fitzgerald Kennedy]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[Transfer to Stephen E. King for services-Stephen E. King]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[For Mr. Sherlock Holmes, Baker st. 221b-Sherlock Holmes]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[Refund to Ms. Joanna Rowling-Joanna Rowling]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[From Bill Gates for charity-William Gates]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[For Liz Truss, former PM-Elizabeth Truss]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[Payment from Mike Johnson-Michael Johnson]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[For BARACK H. OBAMA, invoice 123-Barack H. Obama]
PASSED tmp/tests/integration/test_full_normalization_suite.py::test_critical_ukrainian_normalization
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_russian_male_name_with_patronymic
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_russian_female_name_only
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_russian_male_dative_case
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_ukrainian_invariant_surname_kovalenko
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_ukrainian_invariant_surname_sushko
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_ukrainian_invariant_surname_lemish
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_surname_only_without_name
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_multiple_persons_with_different_genders
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_confidence_gap_boundary_cases
PASSED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_trace_information_completeness
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_russian_language_in_results
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_ukrainian_language_in_results
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_english_language_in_results
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_mixed_language_in_results
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_unknown_language_in_results
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_confidence_range_validation
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_normalization_result_language_fields
PASSED tmp/tests/integration/test_lang_in_results.py::TestLanguageInResults::test_processing_result_language_fields
PASSED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_mixed_unicode_forms_detection
PASSED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_unicode_idempotency_protection
PASSED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_diacritics_normalization_stability
PASSED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_edge_cases_unicode_normalization
PASSED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_unicode_normalization_preserves_meaning
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_detection
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_normalization
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_smart_filter
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_signals
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_birthdate_proximity
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_full_flow
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_edge_cases
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_confidence_scoring
PASSED tmp/tests/integration/test_mixed_language_flow.py::TestMixedLanguageFlow::test_mixed_language_token_traces
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_in_ukrainian_context
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_in_russian_context
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_positional_inference
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_mixed_script_multiple_persons
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_with_apostrophes
PASSED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_not_demoted_to_unknown
PASSED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_language_detection_consistency
PASSED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_variant_generation_integration
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_high_risk_scenario
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_skip_scenario_smartfilter_false
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_medium_risk_scenario
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_low_risk_scenario
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_decision_engine_disabled
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_decision_input_creation
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_risk_level_determination
PASSED tmp/tests/integration/test_orchestrator_decision_integration.py::TestOrchestratorDecisionIntegration::test_decision_reasons_generation
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_single_person_normalization
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_multiple_persons_with_conjunction
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_with_patronymics
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_with_initials
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_with_comma_separator
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_with_mixed_separators
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_with_non_person_tokens
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_persons_data_structure
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_empty_text
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_text_without_persons
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_ukrainian_persons
PASSED tmp/tests/integration/test_persons_grouping.py::TestPersonsGroupingIntegration::test_english_persons
PASSED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[ukrainian_simple_name]
PASSED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[ukrainian_full_name_with_patronymic]
PASSED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[person_with_birth_date]
PASSED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[noise_context_should_filter]
PASSED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_performance_requirements
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_initials_only
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_english_initials_with_surname
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_mixed_initials_and_full_name
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_russian_organization_ooo
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_ukrainian_organization_tov
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_english_organization_llc
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_organization_with_person_name
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_multiple_organizations
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_person_and_organization_mixed
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_organization_with_quotes
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_initials_with_organization
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_multiple_legal_forms
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_organization_with_numbers
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_foreign_organization
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_initials_without_periods
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_organization_in_sentence
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_mixed_case_organization
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_organization_with_address
PASSED tmp/tests/integration/test_pipeline_initials_orgs.py::TestPipelineInitialsOrgsCase::test_no_unknown_in_normalized_output
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_full_name
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_name_with_apostrophe
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_hyphenated_name
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_mixed_english_ukrainian
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_mixed_english_russian
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_initials
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_name_with_title
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_transliterated_name
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_multiple_english_names
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_name_with_middle_initial
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_compound_surname
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_english_name_case_insensitive
PASSED tmp/tests/integration/test_pipeline_mixed_en.py::TestPipelineMixedEnglishCases::test_three_language_mix
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_empty_text
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_whitespace_only
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_numbers_only
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_punctuation_only
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_stop_words_only
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_random_gibberish
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_special_characters
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_emoji_only
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_very_long_text
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_mixed_scripts_nonsense
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_common_words_not_names
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_dates_and_addresses
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_currencies_and_amounts
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_technical_terms
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_medical_terms
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_country_and_city_names
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_brand_names
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_malformed_input
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_sql_injection_attempt
PASSED tmp/tests/integration/test_pipeline_negative_canaries.py::TestPipelineNegativeCanaries::test_no_unknown_tokens_in_output
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_full_name_with_patronymic
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_full_name_with_patronymic
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_female_name_with_patronymic
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_female_name_with_patronymic
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_double_surname
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_double_surname
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_initials
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_initials
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_compound_name
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_compound_name
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_apostrophe
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_apostrophe
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_multiple_ukrainian_names
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_multiple_russian_names
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_typos
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_typos
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_numbers
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_numbers
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_punctuation
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_punctuation
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_with_extra_spaces
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_with_extra_spaces
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_ukrainian_name_case_insensitive
PASSED tmp/tests/integration/test_pipeline_ru_uk_cases.py::TestPipelineRuUkCases::test_russian_name_case_insensitive
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u0421\u0435\u0440\u0433\u0456\u0454\u0432\u0456 \u0416\u0430\u0434\u0430\u043d\u0443-\u0421\u0435\u0440\u0433\u0456\u0439 \u0416\u0430\u0434\u0430\u043d-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u041e\u043a\u0441\u0430\u043d\u0456 \u0417\u0430\u0431\u0443\u0436\u043a\u043e-\u041e\u043a\u0441\u0430\u043d\u0430 \u0417\u0430\u0431\u0443\u0436\u043a\u043e-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u041f\u0435\u0442\u0440\u0430 \u0418\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u043e \u0418\u0432\u0430\u043d\u043e\u0432-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u043e\u0442 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u0430 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447\u0430-\u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447-ru]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u0434\u043b\u044f \u0406\u0432\u0430\u043d\u0456\u0432\u043d\u0438-\u0406\u0432\u0430\u043d\u0456\u0432\u043d\u0430-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u0414\u043b\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u0430 \u0421.\u0412.-\u0406\u0432\u0430\u043d\u043e\u0432-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e \u0421. \u0412.-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[Payment from JOHN DOE-John Doe-en]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0432\u0456\u0434 \u041f\u0435\u0442\u0440\u0430 \u041f\u043e\u0440\u043e\u0448\u0435\u043d\u043a\u0430-\u041f\u0435\u0442\u0440\u043e \u041f\u043e\u0440\u043e\u0448\u0435\u043d\u043a\u043e-uk]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u0415\u0441\u0435\u043d\u0438\u043d \u0441. \u0430.-\u0415\u0441\u0435\u043d\u0438\u043d \u0421. \u0410.-ru]
PASSED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u043f\u0443\u0448\u043a\u0438\u043d \u0430 \u0441-\u041f\u0443\u0448\u043a\u0438\u043d \u0410. \u0421.-ru]
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_russian_complex_sentence
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_ukrainian_complex_sentence
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_mixed_case_names
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_compound_surnames
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_quoted_names
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_organizations_with_personal_names
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_diminutives_in_context
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_ukrainian_diminutives_in_context
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_english_names_in_ukrainian_context
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_initial_handling_in_sentences
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_patronymic_variations
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_ukrainian_surname_variations
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_error_handling_malformed_input
PASSED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_confidence_scoring
PASSED tmp/tests/integration/test_simple_normalization.py::test_normalization_directly
PASSED tmp/tests/integration/test_strict_name_extraction.py::test_strict_name_extraction
PASSED tmp/tests/integration/test_ukrainian_morphology_simple.py::test_ukrainian_morphology_simple
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_text_normalization
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_stemming_in_normalization
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_language_detection
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_stop_words_removal
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_unicode_handling
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_mixed_language_text
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_empty_and_short_text
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_special_characters
PASSED tmp/tests/integration/test_ukrainian_normalization.py::TestUkrainianNormalization::test_ukrainian_performance
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_warmup_performance
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_batch_performance_p95
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_repeated_batch_performance
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_single_vs_batch_performance
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_large_batch_performance
PASSED tmp/tests/performance/test_embeddings_perf.py::TestEmbeddingsPerformance::test_empty_and_single_text_performance
PASSED tmp/tests/performance/test_lang_perf.py::TestLanguageDetectionPerformance::test_single_pass_performance
PASSED tmp/tests/performance/test_lang_perf.py::TestLanguageDetectionPerformance::test_debug_details_completeness
PASSED tmp/tests/performance/test_lang_perf.py::TestLanguageDetectionPerformance::test_memory_efficiency
PASSED tmp/tests/performance/test_lang_perf.py::TestLanguageDetectionPerformance::test_edge_case_performance
PASSED tmp/tests/performance/test_lang_perf.py::TestLanguageDetectionPerformance::test_character_counting_accuracy
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_health_check_no_orchestrator
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_health_check_with_orchestrator
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_process_text_endpoint_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_process_text_no_orchestrator
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_process_text_internal_error
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_process_text_validation_error
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_normalize_text_endpoint_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_process_batch_endpoint_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_search_similar_endpoint_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_startup_event_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_startup_event_failure
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_admin_status_endpoint_unauthorized
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_admin_status_endpoint_invalid_token
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_admin_status_endpoint_success
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_cors_configuration
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_request_validation_models
PASSED tmp/tests/unit/api/test_main_endpoints.py::TestMainEndpoints::test_error_handler_responses
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_high_confidence_match_decision
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_weak_match_decision
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_needs_review_decision
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_no_match_decision
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_insufficient_data_decision
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_evidence_extraction
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_risk_factor_identification
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_context_sensitive_decisions
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_reasoning_generation
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_recommendations_generation
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_batch_decisions
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngine::test_threshold_updates
PASSED tmp/tests/unit/core/test_decision_engine.py::TestDecisionEngineIntegration::test_real_processing_result_decision
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_factory_initialization
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_create_testing_orchestrator_minimal
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_create_testing_orchestrator_full
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_create_production_orchestrator
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_create_orchestrator_custom_config
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_service_initialization_mocking
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_service_initialization_error_handling
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_optional_services_configuration
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_factory_singleton_pattern
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactory::test_service_dependency_injection
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactoryIntegration::test_real_service_creation
PASSED tmp/tests/unit/core/test_orchestrator_factory.py::TestOrchestratorFactoryIntegration::test_factory_performance
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_initialization
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_default_model_configuration
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_load_model_success
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_load_model_error
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_model_caching
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_single_text
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_multiple_texts
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_with_normalization
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_batch_processing
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_empty_input
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_encode_none_input
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceCore::test_embedding_result_format
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceErrorHandling::test_model_encode_error
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceErrorHandling::test_memory_error_handling
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServicePerformance::test_batch_size_optimization
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServicePerformance::test_processing_time_tracking
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServicePerformance::test_model_cache_efficiency
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceIntegration::test_multilingual_support
PASSED tmp/tests/unit/embeddings/test_embedding_service_comprehensive_fixed.py::TestEmbeddingServiceIntegration::test_real_world_embedding_scenarios
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_service_initialization
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_cache_key_generation
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_embedding_caching
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_cache_lru_eviction
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_optimized_embeddings_with_cache
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_optimized_embeddings_without_cache
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_performance_metrics_tracking
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_batch_optimization
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_gpu_availability_check
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_optimized_similarity_search
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_faiss_acceleration
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_numpy_similarity_search
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_cache_clearing
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_cache_warmup
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_error_handling
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_async_optimized_methods
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_performance_under_load
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_metrics_accumulation
PASSED tmp/tests/unit/embeddings/test_optimized_embedding_service.py::TestOptimizedEmbeddingService::test_thread_safety
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_invariant_surnames_unchanged
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_russian_feminine_adjustment
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_russian_masculine_adjustment
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_ukrainian_feminine_adjustment
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_ukrainian_masculine_adjustment
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_insufficient_confidence_gap
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_preserve_original_gendered_form
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_no_matching_endings
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_case_insensitive_matching
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_compound_surnames
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_edge_cases
PASSED tmp/tests/unit/layers/test_adjust_surname_gender.py::TestAdjustSurnameGender::test_confidence_gap_boundary
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_single_person
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_multiple_persons_with_conjunction
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_multiple_persons_with_comma
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_person_with_patronymic
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_person_with_initial
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_skip_non_person_tokens
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_empty_tokens
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_no_person_tokens
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_multiple_separators
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_ukrainian_separators
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_english_separators
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_person_data_structure
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_surname_adjustment_integration
PASSED tmp/tests/unit/layers/test_group_persons.py::TestGroupPersons::test_surname_adjustment_with_high_confidence
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_patronymic_male_clear
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_patronymic_female_clear
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_given_name_male_clear
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_given_name_female_clear
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_surname_male_ending
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_surname_female_ending
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_context_markers_female
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_context_markers_male
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_combined_indicators_strong_female
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_combined_indicators_strong_male
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_uncertain_gender
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_empty_input
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_mixed_indicators_female_wins
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_mixed_indicators_male_wins
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_initial_tokens_ignored
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_ukrainian_surname_endings
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_case_insensitive_matching
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_multiple_patronymics
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_multiple_given_names
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_edge_case_exactly_3_difference
PASSED tmp/tests/unit/layers/test_infer_gender.py::TestInferGender::test_unknown_role_tokens
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_normalization_result_structure
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_token_trace_completeness
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_organizations_core_separation
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_persons_core_structure
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_flag_behavior_real_impact
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_org_acronyms_always_unknown
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_ascii_no_morph_in_cyrillic
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_womens_surnames_preserved
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_serialization_compatibility
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_performance_requirements
PASSED tmp/tests/unit/layers/test_normalization_contracts.py::TestNormalizationContracts::test_error_handling
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_should_process_basic
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_classification_mapping
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_name_signals_extraction
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_company_signals_extraction
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_payment_signals_extraction
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_error_handling_fallback
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_initialization_required
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_signal_names_extraction
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapter::test_processing_time_tracking
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapterIntegration::test_full_initialization
PASSED tmp/tests/unit/layers/test_smart_filter_adapter.py::TestSmartFilterAdapterIntegration::test_claude_md_compliance
PASSED tmp/tests/unit/monitoring/test_metrics_basic.py::test_orchestrator_with_metrics_service
PASSED tmp/tests/unit/monitoring/test_metrics_basic.py::test_metrics_service_basic_operations
PASSED tmp/tests/unit/monitoring/test_metrics_basic.py::test_metrics_service_initialization
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_service_initialization
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_counter_metric
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_set_gauge_metric
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_record_histogram_metric
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_timer_metric
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_metric_definitions
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_alert_system
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_alert_cooldown
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_metric_cleanup
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_performance_report
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_system_health_check
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_metric_export
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_thread_safety
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_async_operations
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_memory_usage_tracking
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_metric_labels
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_bulk_operations
PASSED tmp/tests/unit/monitoring/test_metrics_service.py::TestMetricsService::test_error_handling
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_successful_processing_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_validation_failure_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_smart_filter_skip_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_normalization_failure_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_variants_failure_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_embeddings_failure_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_decision_failure_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_slow_processing_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_exception_handling_metrics
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_active_requests_gauge
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_language_detection_distribution
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_histogram_metrics_accuracy
PASSED tmp/tests/unit/monitoring/test_orchestrator_metrics.py::TestOrchestratorMetrics::test_metrics_without_optional_services
PASSED tmp/tests/unit/morphology/test_integration_morphology.py::TestMorphologyIntegration::test_language_detection_priority
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_morph_nominal_caching
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_morph_nominal_name_surn_priority
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_ukrainian_surname_enko_indeclinable
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_ukrainian_surname_sky_forms
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_ukrainian_surname_tsky_forms
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_ukrainian_surname_ov_forms
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_russian_diminutives_expansion
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_ukrainian_diminutives_expansion
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_english_nicknames_expansion
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_surname_gender_adjustment_male
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_surname_gender_adjustment_ukrainian
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_compound_surname_gender_adjustment
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_morphology_preserves_case
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_morphology_handles_compound_words
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_diminutives_with_morphology
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_advanced_features_flag_affects_diminutives
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_advanced_features_flag_affects_morphology
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_unknown_diminutive_fallback
PASSED tmp/tests/unit/morphology/test_morph_and_diminutives.py::TestMorphologyAndDiminutives::test_mixed_language_diminutives
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_initialization
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_basic_name
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_feminine_name
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_surname
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_patronymic
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_compound_name
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_empty_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_whitespace_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_non_russian_text
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_numbers
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_mixed_text
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_all_forms_with_exception
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_diminutives_masculine
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_diminutives_feminine
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_diminutives_unknown_name
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_diminutives_empty_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_word_forms_all_cases
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_word_forms_multiple_parses
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_word_forms_inflection_failure
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_get_word_forms_non_noun
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_is_russian_name_valid_names
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_is_russian_name_invalid_names
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_is_russian_name_edge_cases
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_analyze_name_capitalization
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_analyze_name_whitespace_handling
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_analyze_name_empty_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_variants_comprehensive
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_variants_deduplication
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test__generate_variants_max_variants_limit
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_batch_process_names
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_batch_process_names_empty_list
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphology::test_batch_process_names_with_errors
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphologyIntegration::test_real_name_processing_integration
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphologyIntegration::test_performance_with_long_name_lists
PASSED tmp/tests/unit/morphology/test_russian_morphology_service.py::TestRussianMorphologyIntegration::test_memory_usage_with_many_variants
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_word_basic
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_gender_detection_male
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_gender_detection_female
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_declensions_generation
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_diminutives_generation
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_variants_generation
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_transliterations_generation
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_language_detection
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_is_russian_name
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_name_complexity
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_phonetic_variants
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_regional_transliterations
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_basic
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_with_language
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_empty_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_none_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_whitespace_input
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_special_characters
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_numbers
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_mixed_case
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_very_long
PASSED tmp/tests/unit/morphology/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_unicode_characters
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0421\u0435\u0440\u0433\u0456\u0439-masc-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041e\u043b\u0435\u043d\u0430-femn-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-masc-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0414\u0430\u0440\u0456\u044f-femn-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041f\u0435\u0442\u0440\u043e-masc-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0410\u043d\u043d\u0430-femn-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041c\u0438\u0445\u0430\u0439\u043b\u043e-masc-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041a\u0430\u0442\u0435\u0440\u0438\u043d\u0430-femn-uk]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_diminutives_generation
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_transliteration_generation
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e-expected_endings0]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u0406\u0432\u0430\u043d\u0435\u043d\u043a\u043e-expected_endings1]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u041c\u0435\u043b\u044c\u043d\u0438\u043a-expected_endings2]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u0428\u0435\u0432\u0447\u0435\u043d\u043a\u043e-expected_endings3]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[-expected_result0]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[\u0410-expected_result1]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[\u0421\u0435\u0440\u0433\u0456\u0439-expected_result2]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0421\u0435\u0440\u0433\u0456\u0439-expected_ukrainian_chars0]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u041e\u043b\u0435\u043a\u0441\u0456\u0439-expected_ukrainian_chars1]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-expected_ukrainian_chars2]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0414\u0430\u0440\u0456\u044f-expected_ukrainian_chars3]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u041f\u0435\u0442\u0440\u043e-expected_ukrainian_chars4]
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_name_complexity_analysis
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_correction_logic
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_basic_functionality
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_empty_name_handling
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_short_name_handling
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_auto_language_detection
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_pymorphy3_initialization_success
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_exceptions_dictionary
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_phonetic_variants_generation
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_regional_transliterations
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_get_all_forms_method
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_is_ukrainian_name_detection
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_complexity_level_calculation
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_basic_transliteration
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_language_detection_internal
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_pymorphy_analysis_failure_handling
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_generate_pymorphy_declensions
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_extract_gender_with_name_tags
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_extract_gender_by_endings
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_apply_regional_transliteration
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_whitespace_name_handling
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_none_name_handling
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_gender_detection_petro
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_gender_detection_daria
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_unknown_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_short_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_lemma_special_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_lemma_unknown_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_special_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_gender_special_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_gender_unknown_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_special_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_unknown_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_special_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_unknown_name
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_basic_functionality
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_with_language_detection
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_empty_string
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_whitespace_only
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_none_input
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_special_characters
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_numbers
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_mixed_case
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_very_long
PASSED tmp/tests/unit/morphology/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_unicode_characters
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_unified_pattern_creation
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_basic
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_empty_text
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_document_pattern_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_contextual_pattern_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_structured_name_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_company_pattern_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_dob_pattern_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_dictionary_pattern_extraction
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_language_detection
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_pattern_optimization
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_stop_words_filtering
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_multilingual_support
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_export_for_aho_corasick
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_pattern_statistics
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_high_quality_name_validation
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_structured_name_validation
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_company_name_validation
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_performance_with_complex_text
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_legacy_compatibility
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_case_sensitivity_handling
PASSED tmp/tests/unit/patterns/test_unified_pattern_service.py::TestUnifiedPatternService::test_special_characters_handling
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_create_empty_result
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_addresses
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_banking_terms
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_business_types
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_capitalized_names
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_company_signals_empty
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_company_signals_with_keywords
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_financial_services
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_keywords
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_legal_entities
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_detect_registration_numbers
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_extract_detected_keywords
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_get_enhanced_company_analysis
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetector::test_initialization
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetectorIntegration::test_financial_institution_detection
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetectorIntegration::test_multilingual_support
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_banking_terms
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_legal_forms
PASSED tmp/tests/unit/screening/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_organization_patterns
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_analyze_regular_signals_high_confidence
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_analyze_regular_signals_low_confidence
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_collect_all_signals
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_determine_risk_level
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_get_decision_statistics
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_get_decision_statistics_empty
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_get_detailed_analysis
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_initialization
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_initialization_with_terrorism_detection
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_is_excluded_text
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_make_decision_empty_text
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_make_decision_excluded_text
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_make_regular_decision_thresholds
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_update_thresholds
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionLogic::test_update_thresholds_invalid_key
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionResult::test_decision_result_creation
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionTypes::test_decision_type_values
PASSED tmp/tests/unit/screening/test_decision_logic.py::TestDecisionTypes::test_risk_level_values
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_create_empty_result
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_addresses
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_bank_details
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_contact_info
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_dates
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_document_numbers
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_document_signals_empty
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_document_signals_with_inn
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_detect_inn
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_extract_detected_documents
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_initialization
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetector::test_is_valid_date
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetectorIntegration::test_comprehensive_document_analysis
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetectorIntegration::test_multilingual_document_support
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_address_detection
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_date_detection
PASSED tmp/tests/unit/screening/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_inn_detection
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_analyze_payment_description
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_date_only_text
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_exclusion_patterns
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_initialization
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_initialization_with_terrorism_detection
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_language_composition_analysis
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_language_detection
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_make_smart_decision
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_service_words_cleaning
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_empty
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_excluded
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_with_signals
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterService::test_text_normalization
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterIntegration::test_company_detection
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterIntegration::test_person_name_detection
PASSED tmp/tests/unit/screening/test_smart_filter_service.py::TestSmartFilterIntegration::test_safe_content_handling
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_create_empty_result
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_activity_patterns
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_financing_patterns
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_organization_patterns
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_terrorism_signals_empty
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_terrorism_signals_excluded_content
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_detect_weapons_patterns
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_determine_risk_level
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_extract_detected_indicators
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_get_risk_assessment
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_initialization
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetector::test_is_excluded_content
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_defensive_purpose_only
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_false_positive_prevention
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_pattern_weights_balance
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_risk_escalation_thresholds
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_comprehensive_threat_assessment
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_defensive_system_requirements
PASSED tmp/tests/unit/screening/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_risk_assessment_workflow
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_proximity_matching_single_person_single_id
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_proximity_matching_multiple_persons_multiple_ids
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_proximity_matching_distance_limits
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_fallback_for_ids_without_position
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_fallback_logic_single_person_single_id
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_no_duplicate_id_assignment
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_assign_id_to_person_method
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_assign_invalid_id_evidence
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_persons_without_names_in_text
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityMatching::test_distance_calculation_accuracy
PASSED tmp/tests/unit/signals/test_id_person_proximity_matching.py::TestIDPersonProximityIntegration::test_full_signals_extraction_with_proximity
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_extract_async_success
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_extract_async_without_normalization
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_extract_async_empty_text
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_extract_async_error_handling
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_async_method_uses_thread_pool
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_concurrent_async_calls
PASSED tmp/tests/unit/signals/test_signals_service_async.py::TestSignalsServiceAsync::test_extract_async_with_different_languages
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_initialization
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_signals_basic
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_signals_with_organization
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_signals_with_birthdate
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_signals_with_ids
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_persons_from_normalization_result
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_organizations_from_normalization_result
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_person_ids
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_organization_ids
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_birthdates
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_enrich_persons_with_ids
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_enrich_organizations_with_ids
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_enrich_with_birthdates_proximity_matching
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_calculate_person_confidence
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_calculate_organization_confidence
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_extract_legal_forms
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_person_to_dict_serialization
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_organization_to_dict_serialization
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceCore::test_calculate_overall_confidence
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceEdgeCases::test_extract_signals_empty_text
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceEdgeCases::test_extract_signals_none_normalization
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceEdgeCases::test_extract_persons_malformed_core
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceEdgeCases::test_confidence_calculation_edge_cases
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceIntegration::test_complex_payment_scenario
PASSED tmp/tests/unit/signals/test_signals_service_comprehensive.py::TestSignalsServiceIntegration::test_multilingual_entity_extraction
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_ac_integration_enabled
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_ac_integration_disabled
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_ac_search_enabled
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_ac_search_disabled
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_ac_search_with_matches
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_pattern_analysis
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_pattern_confidence_scoring
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_tier_priority_scoring
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_pattern_type_inference
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_processing_recommendations
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_analysis_with_ukrainian_text
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_enhanced_analysis_with_english_text
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_max_matches_limit
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_error_handling_invalid_text
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_integration_with_existing_smart_filter
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_performance_with_long_text
PASSED tmp/tests/unit/smart_filter/test_enhanced_smart_filter.py::TestEnhancedSmartFilter::test_async_compatibility
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_should_process_text_async_success
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_should_process_text_async_excluded
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_should_process_text_async_empty_text
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_should_process_text_async_whitespace_only
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_async_method_uses_thread_pool
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_concurrent_async_calls
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_async_error_handling
PASSED tmp/tests/unit/smart_filter/test_smart_filter_service_async.py::TestSmartFilterServiceAsync::test_async_with_different_text_types
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_aggregates_all_variants
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_without_morphology
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_error_handling
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_empty_text
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_language_detection
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_token_variants_structure
PASSED tmp/tests/unit/test_advanced_normalization_unit.py::TestNormalizationService::test_normalize_async_morphology_integration
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_template_builder_initialization
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_create_entity_template
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_create_batch_templates
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_generate_search_patterns
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_calculate_complexity_score
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_template_builder_logging_setup
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_build_templates_with_different_entity_types
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_template_builder_error_handling
PASSED tmp/tests/unit/test_build_templates_script.py::TestBuildTemplatesScript::test_template_generation_performance
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_basic_set_get
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_get_nonexistent_key
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_lru_eviction
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_ttl_expiration
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_statistics
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_get_or_set_cache_hit
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_get_or_set_cache_miss
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_clear_cache
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_exists_method
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_exists_with_expired_key
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_touch_method
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_touch_nonexistent_key
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_cleanup_expired
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_set_max_size
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_get_keys
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_memory_usage_estimation
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_generate_key_method
PASSED tmp/tests/unit/test_cache_service.py::TestCacheService::test_lru_logic_with_access
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_create_empty_result
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_addresses
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_banking_terms
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_business_types
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_capitalized_names
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_company_signals_empty
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_company_signals_with_keywords
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_financial_services
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_keywords
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_legal_entities
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_detect_registration_numbers
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_extract_detected_keywords
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_get_enhanced_company_analysis
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetector::test_initialization
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetectorIntegration::test_financial_institution_detection
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetectorIntegration::test_multilingual_support
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_banking_terms
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_legal_forms
PASSED tmp/tests/unit/test_company_detector.py::TestCompanyDetectorIntegration::test_requirement_organization_patterns
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_low_risk_canary_scenarios
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_medium_risk_canary_scenarios
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_high_risk_canary_scenarios
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_skip_risk_canary_scenarios
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_edge_case_canary_scenarios
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_score_calculation_stability
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_reasons_stability
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_metrics_recording_stability
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_configuration_stability
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_batch_consistency
PASSED tmp/tests/unit/test_decision_canary.py::TestDecisionCanary::test_canary_regression_detection
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_default_config_values
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_thr_high
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_thr_medium
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_weights
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_all_values
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_invalid_values
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_partial_values
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_unified_config_uses_env_overrides
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_decision_engine_uses_unified_config
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_decision_engine_custom_config_overrides_env
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_decision_engine_functionality_with_env_overrides
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_edge_cases
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_config_model_dump_with_env_overrides
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_case_sensitivity
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_env_override_priority
PASSED tmp/tests/unit/test_decision_config_overrides.py::TestDecisionConfigOverrides::test_multiple_instances_consistency
PASSED tmp/tests/unit/test_decision_contracts.py::TestRiskLevel::test_risk_level_values
PASSED tmp/tests/unit/test_decision_contracts.py::TestRiskLevel::test_risk_level_enumeration
PASSED tmp/tests/unit/test_decision_contracts.py::TestSmartFilterInfo::test_smart_filter_info_creation
PASSED tmp/tests/unit/test_decision_contracts.py::TestSmartFilterInfo::test_smart_filter_info_with_optional
PASSED tmp/tests/unit/test_decision_contracts.py::TestSmartFilterInfo::test_smart_filter_info_serialization
PASSED tmp/tests/unit/test_decision_contracts.py::TestSignalsInfo::test_signals_info_creation
PASSED tmp/tests/unit/test_decision_contracts.py::TestSignalsInfo::test_signals_info_with_optional
PASSED tmp/tests/unit/test_decision_contracts.py::TestSignalsInfo::test_signals_info_serialization
PASSED tmp/tests/unit/test_decision_contracts.py::TestSimilarityInfo::test_similarity_info_creation
PASSED tmp/tests/unit/test_decision_contracts.py::TestSimilarityInfo::test_similarity_info_with_values
PASSED tmp/tests/unit/test_decision_contracts.py::TestSimilarityInfo::test_similarity_info_serialization
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionInput::test_decision_input_creation
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionInput::test_decision_input_with_all_fields
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionInput::test_decision_input_serialization
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionOutput::test_decision_output_creation
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionOutput::test_decision_output_with_all_fields
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionOutput::test_decision_output_to_dict
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionConfig::test_decision_config_defaults
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionConfig::test_decision_config_custom_values
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionEngine::test_decision_engine_initialization
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionEngine::test_decision_engine_with_custom_config
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionEngine::test_decision_engine_decide_stub
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionEngine::test_decision_engine_high_risk_scenario
PASSED tmp/tests/unit/test_decision_contracts.py::TestDecisionEngine::test_decision_engine_low_risk_scenario
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_smartfilter_defaults_to_process_true
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_signals_defaults_to_zero_confidence
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_similarity_defaults_to_zero_contribution
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_all_none_evidence_results_in_low_risk
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_confidence_values_default_to_zero
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_boolean_flags_default_to_false
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_none_evidence_dict_defaults_to_empty
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_smartfilter_should_process_none_defaults_to_true
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_mixed_none_values_handled_gracefully
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_empty_text_handled_gracefully
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_very_high_confidence_with_none_other_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_skip_decision_with_none_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_details_contain_safe_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_evidence_strength_indicators_with_none_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_score_breakdown_with_none_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_reasons_generation_with_none_values
PASSED tmp/tests/unit/test_decision_edges.py::TestDecisionEngineEdgeCases::test_decision_engine_never_raises_exceptions
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_skip_scenario_smartfilter_false
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_high_risk_scenario
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_medium_risk_scenario
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_low_risk_scenario
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_score_calculation_deterministic
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_custom_config_weights
PASSED tmp/tests/unit/test_decision_engine_core.py::TestDecisionEngineCore::test_similarity_none_handling
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_strong_smartfilter_signal_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_person_evidence_strong_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_org_evidence_strong_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_high_vector_similarity_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_id_exact_match_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_dob_match_reason
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_multiple_strong_evidence_reasons
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_moderate_evidence_fallback_reasons
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_low_evidence_no_strong_reasons
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_score_breakdown_in_details
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_normalized_features_in_details
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_evidence_strength_indicators
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_weights_and_thresholds_in_details
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_skip_scenario_reasons
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_reasons_consistency_with_evidence_strength
PASSED tmp/tests/unit/test_decision_explain.py::TestDecisionExplanation::test_contribution_calculation_accuracy
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_analyze_regular_signals_high_confidence
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_analyze_regular_signals_low_confidence
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_collect_all_signals
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_determine_risk_level
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_get_decision_statistics
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_get_decision_statistics_empty
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_get_detailed_analysis
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_initialization
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_initialization_with_terrorism_detection
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_is_excluded_text
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_make_decision_empty_text
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_make_decision_excluded_text
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_make_regular_decision_thresholds
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_update_thresholds
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionLogic::test_update_thresholds_invalid_key
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionResult::test_decision_result_creation
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionTypes::test_decision_type_values
PASSED tmp/tests/unit/test_decision_logic.py::TestDecisionTypes::test_risk_level_values
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_create_empty_result
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_addresses
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_bank_details
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_contact_info
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_dates
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_document_numbers
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_document_signals_empty
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_document_signals_with_inn
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_detect_inn
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_extract_detected_documents
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_initialization
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetector::test_is_valid_date
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetectorIntegration::test_comprehensive_document_analysis
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetectorIntegration::test_multilingual_document_support
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_address_detection
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_date_detection
PASSED tmp/tests/unit/test_document_detector.py::TestDocumentDetectorIntegration::test_requirement_inn_detection
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingConfig::test_default_model_name
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingConfig::test_default_device
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingConfig::test_default_batch_size
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingConfig::test_default_enable_index
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingConfig::test_custom_config
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_single_text_encoding
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_multiple_texts_encoding
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_empty_input
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_device_from_config
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_embedding_dimension
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_model_info
PASSED tmp/tests/unit/test_embedding_config.py::TestEmbeddingService::test_lazy_initialization
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_encode_one_returns_384_floats
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_encode_batch_returns_2x384
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_encode_one_empty_text
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_encode_batch_empty_list
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_encode_batch_mixed_valid_empty
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_legacy_encode_method_still_works
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_no_similarity_methods_exist
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_no_indexing_imports
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_enable_index_ignored
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_pure_vector_generation_contract
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_batch_size_from_config
PASSED tmp/tests/unit/test_embedding_contract.py::TestEmbeddingContract::test_device_from_config
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_default_model_works
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_to_all_minilm_l6_v2
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_invalid_model_raises_error
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_extra_models_allowlist
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_config_validation_error_messages
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_preserves_functionality
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_with_batch_processing
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_model_switch_with_preprocessing
PASSED tmp/tests/unit/test_embedding_model_switch.py::TestEmbeddingModelSwitch::test_embedding_dimensions_consistency
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_remove_dates_and_ids_by_default
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_remove_various_date_formats
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_remove_various_id_formats
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_fold_spaces
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_preserve_spaces_when_fold_spaces_false
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_empty_text_handling
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_only_dates_and_ids
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_extract_name_only_method
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_include_attrs_future_flag
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_complex_text_processing
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_organization_names
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_mixed_language_text
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_whitespace_normalization
PASSED tmp/tests/unit/test_embedding_preprocessor.py::TestEmbeddingPreprocessor::test_case_insensitive_removal
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_multilingual_name_triangle_similarity
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_name_vs_noise_low_similarity
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_organization_vs_personal_names_distinction
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_empty_and_whitespace_handling
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_consistency_across_calls
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_embedding_dimensions_consistency
PASSED tmp/tests/unit/test_embeddings_canary_names.py::TestEmbeddingsCanaryNames::test_preprocessing_removes_dates_ids
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_service_initialization
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_ukrainian_name_analysis
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_russian_name_analysis
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_language_detection_priority
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_mixed_language_handling
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_fallback_behavior
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_advanced_normalization_pipeline
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_language_auto_detection
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_morphology_consistency
PASSED tmp/tests/unit/test_integration_morphology.py::TestMorphologyIntegration::test_error_recovery
PASSED tmp/tests/unit/test_lang_canary_random_noise.py::TestLanguageDetectionCanaryRandomNoise::test_random_noise_low_confidence
PASSED tmp/tests/unit/test_lang_canary_random_noise.py::TestLanguageDetectionCanaryRandomNoise::test_noise_patterns_detection
PASSED tmp/tests/unit/test_lang_canary_random_noise.py::TestLanguageDetectionCanaryRandomNoise::test_edge_case_noise_robustness
PASSED tmp/tests/unit/test_lang_canary_random_noise.py::TestLanguageDetectionCanaryRandomNoise::test_reproducible_randomness
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_russian_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_ukrainian_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_english_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_mixed_language_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_unknown_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_empty_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_whitespace_text_detection
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_ukrainian_specific_characters
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_russian_specific_characters
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_mixed_language_close_ratios
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_config_thresholds_behavior
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_confidence_calculation
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_result_methods
PASSED tmp/tests/unit/test_lang_config_contract.py::TestLanguageConfigContract::test_detailed_analysis_structure
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_short_text_edge_cases
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_acronym_detection_with_confidence_penalty
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_uppercase_text_confidence_penalty
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_numeric_punctuation_dominance
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_normal_text_not_affected
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_mixed_case_acronyms
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_long_words_not_affected
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_edge_case_confidence_ranges
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_empty_and_whitespace_text
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_special_characters_and_unicode
PASSED tmp/tests/unit/test_lang_edge_cases.py::TestLanguageDetectionEdgeCases::test_threshold_boundary_cases
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_ukrainian_priority_detection
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_logic_ambiguous_text
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_empty_text_handling
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_whitespace_only_text
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_english
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_russian
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_ukrainian
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_langdetect_fallback
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_langdetect_exception_handling
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_ukrainian_specific
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_russian_specific
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_patterns
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_latin_only
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_batch_detection
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_detection_statistics
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_reset_statistics
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_supported_languages
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_is_language_supported
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_add_language_mapping
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_add_invalid_language_mapping
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_confidence_scores_limit
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_language_mapping_coverage
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_no_fallback_option
PASSED tmp/tests/unit/test_language_detection_service.py::TestLanguageDetectionService::test_original_detected_language_preservation
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_create_empty_result
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_name_signals_empty
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_name_signals_full_name
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_name_signals_structure
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_names_basic
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_names_empty
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_detect_names_none
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetector::test_initialization
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetectorIntegration::test_requirement_full_names
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetectorIntegration::test_requirement_names_and_surnames
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetectorIntegration::test_requirement_patronymic_patterns
PASSED tmp/tests/unit/test_name_detector.py::TestNameDetectorIntegration::test_requirement_surname_patterns
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_russian_names_no_internal_duplicates
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_ukrainian_names_no_internal_duplicates
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_english_names_no_internal_duplicates
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_no_cross_dictionary_duplicates
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_additional_english_names_consistency
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_dictionaries_statistics
PASSED tmp/tests/unit/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_name_data_structure
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_process_basic_functionality
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_process_with_smart_filter_skip
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_process_with_validation_error
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_process_with_language_detection_failure
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_process_with_normalization_failure
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_orchestrator_initialization
PASSED tmp/tests/unit/test_orchestrator_service.py::TestUnifiedOrchestrator::test_orchestrator_without_optional_services
PASSED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_language_detection_failure
PASSED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_normalization_failure
PASSED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_orchestrator_initialization
PASSED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_orchestrator_without_optional_services
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_name_pattern_creation
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_generate_patterns_basic
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_generate_patterns_empty_text
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_generate_patterns_ukrainian
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_generate_patterns_compound_name
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_pattern_confidence_scoring
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_pattern_types_variety
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_pattern_metadata_inclusion
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_special_characters_handling
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_multilingual_pattern_generation
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_performance_with_long_names
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_error_handling_invalid_language
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_pattern_uniqueness
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_confidence_ordering
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_empty_and_whitespace_handling
PASSED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_numeric_and_special_content
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_format_processing_result_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_format_processing_result_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_format_error_response
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_token_variants
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_token_variants_empty_trace
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_risk_level_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_risk_level_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_risk_score_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_risk_score_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_decision_reasons_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_decision_reasons_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_decision_details_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_get_decision_details_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_smart_filter_info_with_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_smart_filter_info_without_decision
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_signals_summary_with_data
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_extract_signals_summary_without_data
PASSED tmp/tests/unit/test_response_formatter.py::TestResponseFormatter::test_response_structure_completeness
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_python_version_valid
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_python_version_invalid
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_poetry_available
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_poetry_not_available
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_dependencies_success
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_dependencies_failure
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_dependencies_exception
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_spacy_models_all_available
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_spacy_models_some_missing_auto_install_success
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_check_spacy_models_all_missing_no_auto_install
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_run_service_success
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_run_service_no_service_file
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_run_service_exception
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_main_all_checks_pass
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_main_python_check_fails
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_main_poetry_check_fails
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_main_dependencies_check_fails
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScript::test_main_models_check_fails
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScriptIntegration::test_script_imports_successfully
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScriptIntegration::test_script_has_main_guard
PASSED tmp/tests/unit/test_run_service_script.py::TestRunServiceScriptIntegration::test_checks_list_structure
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_gender_detection_male
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_gender_detection_female
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_declensions_generation
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_diminutives_generation
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_variants_generation
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_transliterations_generation
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_language_detection
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_name_complexity
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_phonetic_variants
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_regional_transliterations
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_empty_input
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_none_input
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_whitespace_input
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_special_characters
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_numbers
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_mixed_case
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_very_long
PASSED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_unicode_characters
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_analyze_payment_description
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_date_only_text
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_exclusion_patterns
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_initialization
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_language_composition_analysis
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_language_detection
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_empty
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_with_signals
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_text_normalization
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterIntegration::test_company_detection
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterIntegration::test_person_name_detection
PASSED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterIntegration::test_safe_content_handling
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_1_ac_disabled_petrov_no_context
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_2_ac_enabled_with_document_pattern
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_3_ac_enabled_nasa_no_trigger
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_4_ac_enabled_petrov_with_context
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_5_ac_verification_in_name_detector
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_6_confidence_comparison_with_without_ac
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_7_adapter_integration_ac_disabled
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_8_adapter_integration_ac_enabled
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_9_config_flag_behavior
PASSED tmp/tests/unit/test_smartfilter_aho.py::TestSmartFilterAhoCorasickIntegration::test_scenario_10_edge_cases
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_template_creation
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_entity_template_initialization
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_entity_template_to_dict
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_entity_template_to_dict_with_numpy_embeddings
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_get_search_keywords
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_get_high_confidence_patterns
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_build_templates_batch
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_build_templates_batch_with_embeddings
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_build_templates_batch_error_handling
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_calculate_complexity_score
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_get_templates_statistics
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_get_templates_statistics_empty
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_export_templates_for_aho_corasick
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_template_builder_error_handling
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_complexity_score_edge_cases
PASSED tmp/tests/unit/test_template_builder.py::TestTemplateBuilder::test_template_post_init
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_create_empty_result
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_activity_patterns
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_financing_patterns
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_organization_patterns
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_terrorism_signals_empty
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_terrorism_signals_excluded_content
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_detect_weapons_patterns
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_determine_risk_level
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_extract_detected_indicators
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_get_risk_assessment
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_initialization
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetector::test_is_excluded_content
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_defensive_purpose_only
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_false_positive_prevention
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_pattern_weights_balance
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorSafety::test_risk_escalation_thresholds
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_comprehensive_threat_assessment
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_defensive_system_requirements
PASSED tmp/tests/unit/test_terrorism_detector.py::TestTerrorismDetectorIntegration::test_risk_assessment_workflow
PASSED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[-expected_result0]
PASSED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_empty_name_handling
PASSED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_pymorphy3_initialization_success
PASSED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_none_name_handling
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_lemma_special_name
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_lemma_unknown_name
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_is_known_word_unknown_name
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_empty_string
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_whitespace_only
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_none_input
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_special_characters
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_numbers
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_mixed_case
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_very_long
PASSED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_unicode_characters
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_aggressive_normalization_sao_paulo
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_cyrillic_processing
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_empty_text_handling
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_none_text_handling
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_complex_mappings_applied
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_confidence_calculation
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_batch_normalization
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_similarity_score
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_encoding_issues_detection
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_preserve_chars_functionality
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_unicode_normalization_nfd_nfkc
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_ascii_folding_failure_handling
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_length_metadata
PASSED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_german_umlauts_handling
PASSED tmp/tests/unit/test_unified_contracts.py::TestTokenTrace::test_token_trace_creation
PASSED tmp/tests/unit/test_unified_contracts.py::TestTokenTrace::test_token_trace_with_morphology
PASSED tmp/tests/unit/test_unified_contracts.py::TestTokenTrace::test_token_trace_serialization
PASSED tmp/tests/unit/test_unified_contracts.py::TestNormalizationResult::test_normalization_result_basic
PASSED tmp/tests/unit/test_unified_contracts.py::TestNormalizationResult::test_normalization_result_with_metadata
PASSED tmp/tests/unit/test_unified_contracts.py::TestNormalizationResult::test_normalization_result_serialization
PASSED tmp/tests/unit/test_unified_contracts.py::TestSignalsContracts::test_signals_person
PASSED tmp/tests/unit/test_unified_contracts.py::TestSignalsContracts::test_signals_organization
PASSED tmp/tests/unit/test_unified_contracts.py::TestSignalsContracts::test_signals_result
PASSED tmp/tests/unit/test_unified_contracts.py::TestSmartFilterResult::test_smart_filter_result_basic
PASSED tmp/tests/unit/test_unified_contracts.py::TestSmartFilterResult::test_smart_filter_classifications
PASSED tmp/tests/unit/test_unified_contracts.py::TestUnifiedProcessingResult::test_unified_result_complete
PASSED tmp/tests/unit/test_unified_contracts.py::TestUnifiedProcessingResult::test_unified_result_serialization
PASSED tmp/tests/unit/test_unified_contracts.py::TestUnifiedProcessingResult::test_unified_result_backward_compatibility
PASSED tmp/tests/unit/test_unified_contracts.py::TestProcessingContext::test_processing_context_basic
PASSED tmp/tests/unit/test_unified_contracts.py::TestContractCompatibility::test_contract_chain_compatibility
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_smart_filter_skip_behavior
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_backward_compatibility_methods
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_valid_services
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_validation_service
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_language_service
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_unicode_service
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_normalization_service
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_signals_service
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_optional_services_none
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorEdgeCases::test_empty_input
PASSED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorEdgeCases::test_service_initialization_failure
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_transliteration_variants_grigoriy
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_compound_surname_processing
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_basic_transliteration_functionality
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_multiple_transliteration_standards
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_phonetic_variants_generation
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_visual_similarities_generation
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_typo_variants_generation
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_comprehensive_variants_generation
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_empty_text_handling
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_none_text_handling
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_max_variants_limit
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_language_specific_processing
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_find_best_matches_functionality
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_similarity_calculation
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_keyboard_layout_variants
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_morphological_variants_integration
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_morphological_variants_mocked
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_processing_statistics
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_duplicate_removal
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_case_preservation_and_normalization
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_special_characters_handling
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_performance_with_long_names
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_error_handling_in_transliteration
PASSED tmp/tests/unit/test_variant_generation_service.py::TestVariantGenerationService::test_variant_scores_match_config
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_remove_stop_words_false
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_remove_stop_words_true
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_preserve_names_false
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_preserve_names_true
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_enable_advanced_features_false_slavic
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_enable_advanced_features_true_slavic
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_enable_advanced_features_false_english
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_enable_advanced_features_true_english
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_initial_cleanup_still_works_with_flags
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_all_flags_false
PASSED tmp/tests/unit/text_processing/test_flags_behavior.py::TestFlagsBehavior::test_all_flags_true
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_ukrainian_priority_detection
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_logic_ambiguous_text
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_empty_text_handling
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_whitespace_only_text
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_english
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_russian
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_quick_patterns_ukrainian
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_langdetect_fallback
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_langdetect_exception_handling
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_ukrainian_specific
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_russian_specific
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_cyrillic_patterns
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_fallback_latin_only
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_batch_detection
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_detection_statistics
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_reset_statistics
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_supported_languages
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_is_language_supported
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_add_language_mapping
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_add_invalid_language_mapping
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_confidence_scores_limit
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_language_mapping_coverage
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_no_fallback_option
PASSED tmp/tests/unit/text_processing/test_language_detection_service.py::TestLanguageDetectionService::test_original_detected_language_preservation
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0437\u0430 \u043f\u043e\u0441\u043b\u0443\u0433\u0438, \u043f\u043b\u0430\u0442\u043d\u0438\u043a \u041f\u0435\u0442\u0440\u0438\u043a \u041f.-\u041f\u0435\u0442\u0440\u043e \u041f.]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u041f\u0435\u0442\u0440\u0443\u0441\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430, \u0437\u0430 \u0440\u0435\u043c\u043e\u043d\u0442-\u041f\u0435\u0442\u0440\u043e \u0406\u0432\u0430\u043d\u043e\u0432]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041f\u0435\u0440\u0435\u043a\u0430\u0437 \u0432\u0456\u0434 \u0412\u043e\u0432\u0447\u0438\u043a\u0430 \u0417\u0435\u043b\u0435\u043d\u0441\u044c\u043a\u043e\u0433\u043e \u0412. \u041e.-\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440 \u0417\u0435\u043b\u0435\u043d\u0441\u044c\u043a\u0438\u0439 \u0412. \u041e.]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041f\u043e\u0434\u0430\u0440\u0443\u043d\u043e\u043a \u0434\u043b\u044f \u0414\u0430\u0448\u0435\u043d\u044c\u043a\u0438 \u041a\u0432\u0456\u0442\u043a\u043e\u0432\u043e\u0457-\u0414\u0430\u0440\u0456\u044f \u041a\u0432\u0456\u0442\u043a\u043e\u0432\u0430]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0412\u0456\u0434 \u0421\u0430\u0448\u043a\u0430 \u041f\u043e\u043b\u043e\u0436\u0438\u043d\u0441\u044c\u043a\u043e\u0433\u043e \u0437\u0430 \u043a\u0432\u0438\u0442\u043a\u0438-\u041e\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440 \u041f\u043e\u043b\u043e\u0436\u0438\u043d\u0441\u044c\u043a\u0438\u0439]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u044f\u043a\u0443\u0454\u043c\u043e \u0421\u0435\u0440\u0433\u0456\u0454\u0432\u0456 \u0416\u0430\u0434\u0430\u043d\u0443 \u0437\u0430 \u0442\u0432\u043e\u0440\u0447\u0456\u0441\u0442\u044c-\u0421\u0435\u0440\u0433\u0456\u0439 \u0416\u0430\u0434\u0430\u043d]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041f\u043e\u0434\u0430\u0440\u0443\u043d\u043e\u043a \u0434\u043b\u044f \u041e\u043a\u0441\u0430\u043d\u0438 \u0417\u0430\u0431\u0443\u0436\u043a\u043e-\u041e\u043a\u0441\u0430\u043d\u0430 \u0417\u0430\u0431\u0443\u0436\u043a\u043e]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041f\u043b\u0442\u0456\u0436 \u0432\u0456\u0434 \u0412'\u044f\u0447\u0435\u0441\u043b\u0430\u0432\u0430 \u0432\u0430\u043a\u0430\u0440\u0447\u0443\u043a\u0430 (\u043e\u043a\u0435\u0430\u043d \u0435\u043b\u044c\u0437\u0438)-\u0412'\u044f\u0447\u0435\u0441\u043b\u0430\u0432 \u0412\u0430\u043a\u0430\u0440\u0447\u0443\u043a]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u041f\u0435\u0440\u0435\u043a\u0430\u0437 \u041e\u041b\u0415\u0413\u0423 \u0421\u041a\u0420\u0418\u041f\u0426\u0406-\u041e\u043b\u0435\u0433 \u0421\u043a\u0440\u0438\u043f\u043a\u0430]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u041f\u0435\u0440\u0435\u0432\u043e\u0434 \u043e\u0442 \u0421\u0430\u0448\u0438 \u041f\u0443\u0448\u043a\u0438\u043d\u0430 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447\u0430-\u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440 \u041f\u0443\u0448\u043a\u0438\u043d \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u041e\u043f\u043b\u0430\u0442\u0430 \u0434\u043b\u044f \u0412\u043e\u043b\u043e\u0434\u0438 \u0412\u044b\u0441\u043e\u0446\u043a\u043e\u0433\u043e-\u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440 \u0412\u044b\u0441\u043e\u0446\u043a\u0438\u0439]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u041f\u043b\u0430\u0442\u0451\u0436 \u043e\u0442 \u0414\u0438\u043c\u044b \u041c\u0435\u0434\u0432\u0435\u0434\u0435\u0432\u0430-\u0414\u043c\u0438\u0442\u0440\u0438\u0439 \u041c\u0435\u0434\u0432\u0435\u0434\u0435\u0432]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u041f\u0435\u0440\u0435\u0432\u043e\u0434 \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u0418\u0432\u0430\u043d\u0443 \u0411\u0443\u043d\u0438\u043d\u0443-\u0418\u0432\u0430\u043d \u0411\u0443\u043d\u0438\u043d]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0434\u043b\u044f \u0415\u0441\u0435\u043d\u0438\u043d\u0430 \u0421. \u0410.-\u0415\u0441\u0435\u043d\u0438\u043d \u0421. \u0410.]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Payment from John Fitzgerald Kennedy-John Fitzgerald Kennedy]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Transfer to Stephen E. King for services-Stephen E. King]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[For Mr. Sherlock Holmes, Baker st. 221b-Sherlock Holmes]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Refund to Ms. Joanna Rowling-Joanna Rowling]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[From Bill Gates for charity-William Gates]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[For Liz Truss, former PM-Elizabeth Truss]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Payment from Mike Johnson-Michael Johnson]
PASSED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[For BARACK H. OBAMA, invoice 123-Barack H. Obama]
PASSED tmp/tests/unit/text_processing/test_normalization_result_fields.py::TestNormalizationResultFields::test_normalization_result_metadata_fields
PASSED tmp/tests/unit/text_processing/test_normalization_result_fields.py::TestNormalizationResultFields::test_normalization_result_tokens
PASSED tmp/tests/unit/text_processing/test_normalization_result_fields.py::TestNormalizationResultFields::test_normalization_result_extra_fields_allowed
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_english_text
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_russian_text
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_ukrainian_text
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_fallback
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_auto_language_detection
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_person_names
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_russian_names
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_ukrainian_names
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_initials
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_empty_text
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_whitespace_only
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_special_characters
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_numbers
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_sync_method
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_async_method
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_flags
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_error_handling
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_result_structure
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_with_complex_text
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationServiceConfiguration::test_service_has_required_attributes
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationServiceConfiguration::test_service_has_required_methods
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationServiceConfiguration::test_morph_analyzers_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationServiceConfiguration::test_name_dictionaries_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationServiceConfiguration::test_diminutive_maps_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationResult::test_normalization_result_creation
PASSED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationResult::test_normalization_result_error_case
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_ukrainian_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_person_names
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_russian_names
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_ukrainian_names
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_initials
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_empty_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_whitespace_only
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_numbers
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_error_handling
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_result_structure
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_complex_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_service_has_required_attributes
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_service_has_required_methods
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_morph_analyzers_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_name_dictionaries_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_initialization
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_ukrainian_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_success
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_without_optional_processing
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_ukrainian_with_forms
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_empty_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_whitespace_only
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_unicode_error
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_language_detection_error
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_processing_error
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_very_long_text
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_special_characters
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_mixed_languages
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_unsupported_language
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_ukrainian_normalization_basic
PASSED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationResult::test_normalization_result_creation
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_org_acronyms_are_tagged_as_unknown
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_org_acronyms_not_in_normalized_output
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_person_tokens_survive
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_various_org_acronyms_are_filtered
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_org_acronyms_case_insensitive
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_org_acronyms_excluded_from_positional_fallbacks
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_mixed_content_with_org_acronyms
PASSED tmp/tests/unit/text_processing/test_org_acronyms_filter.py::TestOrgAcronymsFilter::test_org_acronyms_constant_contains_expected_values
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_multi_initial_splitting
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_triple_initial_splitting
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_enhanced_patronymic_patterns_male
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_enhanced_patronymic_patterns_female
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_enhanced_surname_patterns_enko
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_enhanced_surname_patterns_ov_ova
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_enhanced_surname_patterns_sky_ska
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_new_surname_patterns_yan
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_new_surname_patterns_dze
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_conservative_unknown_tagging
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_positional_heuristics_still_work
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_integration_with_organization_roles
PASSED tmp/tests/unit/text_processing/test_role_tagging_extended.py::TestExtendedRoleTagging::test_sentence_with_org_and_people
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_aggressive_normalization_sao_paulo
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_cyrillic_processing
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_empty_text_handling
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_none_text_handling
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_complex_mappings_applied
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_confidence_calculation
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_batch_normalization
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_similarity_score
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_encoding_issues_detection
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_preserve_chars_functionality
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_unicode_normalization_nfd_nfkc
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_ascii_folding_failure_handling
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_unicode_normalization_failure_handling
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_length_metadata
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_case_normalization
PASSED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_german_umlauts_handling
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_transliteration_variants_grigoriy
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_compound_surname_processing
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_basic_transliteration_functionality
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_multiple_transliteration_standards
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_phonetic_variants_generation
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_visual_similarities_generation
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_typo_variants_generation
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_comprehensive_variants_generation
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_empty_text_handling
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_none_text_handling
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_max_variants_limit
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_language_specific_processing
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_find_best_matches_functionality
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_similarity_calculation
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_keyboard_layout_variants
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_morphological_variants_integration
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_morphological_variants_mocked
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_processing_statistics
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_duplicate_removal
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_case_preservation_and_normalization
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_special_characters_handling
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_performance_with_long_names
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_error_handling_in_transliteration
PASSED tmp/tests/unit/text_processing/test_variant_generation_service.py::TestVariantGenerationService::test_variant_scores_match_config
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_ukrainian_apostrophes_unification
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_compound_names_normalization
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_irish_names_apostrophes
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_company_quotes_unification
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_mixed_apostrophes_in_text
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_preserve_meaningful_punctuation
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_confidence_calculation_with_replacements
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_batch_normalization_consistency
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_similarity_after_normalization
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_encoding_recovery_with_apostrophes
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_performance_with_many_replacements
PASSED tmp/tests/unit/unicode/test_apostrophe_normalization.py::TestApostropheNormalization::test_edge_cases_empty_and_none
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_initialization
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalize_text_basic
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalize_text_cyrillic_mapping
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalize_text_latin_diacritics
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalize_text_aggressive_mode
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalize_text_mixed_scripts
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_unicode_nfc_normalization
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_encoding_recovery
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_whitespace_normalization
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_invisible_characters_removal
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_homoglyph_handling
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_preserve_cyrillic_characters
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_edge_cases
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_long_text_handling
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_character_mapping_completeness
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalization_consistency
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_normalization_with_numbers_and_punctuation
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_different_normalization_forms
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeService::test_rtl_and_bidi_text
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeServiceIntegration::test_real_world_name_normalization
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeServiceIntegration::test_payment_text_normalization
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeServiceIntegration::test_normalization_preserves_structure
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeServiceIntegration::test_aggressive_vs_conservative_mode[True]
PASSED tmp/tests/unit/unicode/test_unicode_service_comprehensive.py::TestUnicodeServiceIntegration::test_aggressive_vs_conservative_mode[False]
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_basic_set_get
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_get_nonexistent_key
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_lru_eviction
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_ttl_expiration
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_statistics
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_get_or_set_cache_hit
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_get_or_set_cache_miss
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_clear_cache
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_exists_method
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_exists_with_expired_key
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_touch_method
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_touch_nonexistent_key
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_cleanup_expired
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_set_max_size
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_get_keys
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_memory_usage_estimation
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_generate_key_method
PASSED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_lru_logic_with_access
PASSED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_english_context_words
PASSED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_positional_heuristics_blocked_for_context_words
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_homoglyphs
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_zero_width_characters
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_surrogate_pairs
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_combining_characters
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_malformed_utf8
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestUnicodeServiceEdgeCases::test_normalize_text_with_rtl_text
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_very_short_text
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_numbers_only
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_symbols_only
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_mixed_scripts
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_code_snippets
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestLanguageDetectionEdgeCases::test_detect_language_with_html_tags
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCacheServiceEdgeCases::test_cache_with_complex_objects
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCacheServiceEdgeCases::test_cache_key_collision_with_similar_keys
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCacheServiceEdgeCases::test_cache_overflow_handling
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCacheServiceEdgeCases::test_cache_with_zero_ttl
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCacheServiceEdgeCases::test_cache_with_negative_ttl
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCustomExceptionHandling::test_validation_api_error_creation
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCustomExceptionHandling::test_validation_api_error_with_details
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCustomExceptionHandling::test_internal_server_error_creation
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCustomExceptionHandling::test_service_unavailable_error_creation
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestCustomExceptionHandling::test_exception_chaining
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestResourceCleanupAndMemoryManagement::test_service_cleanup_on_deletion
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestResourceCleanupAndMemoryManagement::test_large_object_caching_memory_usage
PASSED tmp/tests/unit/utilities/test_edge_cases_comprehensive.py::TestResourceCleanupAndMemoryManagement::test_concurrent_access_resource_safety
PASSED tmp/tests/unit/utilities/test_flags_ab_strict.py::test_enable_advanced_features_false_no_morph
PASSED tmp/tests/unit/utilities/test_flags_ab_strict.py::test_preserve_names_false_splits_apostrophe
PASSED tmp/tests/unit/utilities/test_flags_ab_strict.py::test_remove_stop_words_false_keeps_stopwords
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_valid_text_processing
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_zero_width_character_removal
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_control_character_removal
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_suspicious_pattern_detection
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_strict_mode_blocking
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_text_length_limiting
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_empty_text_handling
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_unicode_normalization
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_sanctions_input_validation
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_sanctions_input_missing_required_field
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_sanctions_input_with_malicious_content
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_suspicion_analysis_high_zero_width
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_non_string_input_raises_error
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_whitespace_normalization
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_url_encoding_detection
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_html_entity_detection
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_unicode_normalization_failure
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_input_validator_global_instance
PASSED tmp/tests/unit/utilities/test_input_validation.py::TestValidationResult::test_validation_result_creation
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_russian_names_no_internal_duplicates
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_ukrainian_names_no_internal_duplicates
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_english_names_no_internal_duplicates
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_no_cross_dictionary_duplicates
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_additional_english_names_consistency
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_dictionaries_statistics
PASSED tmp/tests/unit/utilities/test_name_dictionaries_validation.py::TestNameDictionariesValidation::test_name_data_structure
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_unified_pattern_creation
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_basic
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_empty_text
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_ukrainian
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_generate_patterns_compound_name
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_pattern_confidence_scoring
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_pattern_types_variety
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_pattern_metadata_inclusion
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_special_characters_handling
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_case_sensitivity_handling
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_multilingual_pattern_generation
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_performance_with_long_names
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_error_handling_invalid_language
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_pattern_uniqueness
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_confidence_ordering
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_empty_and_whitespace_handling
PASSED tmp/tests/unit/utilities/test_pattern_service.py::TestUnifiedPatternService::test_numeric_and_special_content
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_initialization
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_initialize_success
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_initialize_failure
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_not_initialized
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_success
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_invalid_input
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_exception_handling
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_empty_text
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_long_text
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_and_sanitize_none_input
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_with_risk_levels
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_with_blocked_patterns
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_validate_with_warnings
PASSED tmp/tests/unit/validation/test_validation_service.py::TestValidationService::test_interface_compliance
SKIPPED [1] tests/performance/test_embeddings_perf.py:170: psutil not available for memory monitoring
SKIPPED [1] tests/unit/core/test_decision_engine.py:204: Feature not implemented
SKIPPED [1] tests/unit/core/test_decision_engine.py:222: Feature not implemented
SKIPPED [1] tests/unit/core/test_decision_engine.py:238: Feature not implemented
SKIPPED [1] tests/unit/core/test_decision_engine.py:260: Feature not implemented
SKIPPED [1] tests/unit/core/test_decision_engine.py:281: Feature not implemented
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:19: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:36: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:54: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:93: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:119: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:136: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:151: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:166: Test expects AdvancedNormalizationService which no longer exists
SKIPPED [1] tests/unit/morphology/test_integration_morphology.py:182: Test expects AdvancedNormalizationService which no longer exists
FAILED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_corrupted_encoding_nightmare
FAILED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_performance_nightmare
FAILED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_edge_cases_nightmare
FAILED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_cache_effectiveness_nightmare
FAILED tmp/tests/e2e/test_nightmare_scenario.py::TestNightmareScenario::test_batch_nightmare
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_ukrainian_surname_pattern_detection
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_malicious_input_sanitization
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_early_stopping_high_confidence
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_performance_under_load
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_audit_trail_completeness
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_screening_metrics_collection
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningPipelineE2E::test_sanctions_data_format_compatibility
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningRobustness::test_extremely_long_input_handling
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningRobustness::test_unicode_edge_cases
FAILED tmp/tests/e2e/test_sanctions_screening_pipeline.py::TestSanctionsScreeningRobustness::test_concurrent_screening_stress
FAILED tmp/tests/integration/test_e2e_sanctions_screening.py::TestE2ESanctionsScreening::test_golden_dataset_stability
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0416\u0435\u043d\u0456 \u0413\u0430\u043b\u0438\u0447\u0430 \u0437 \u0433\u0440\u0443\u043f\u0438 O.Torvald-\u0404\u0432\u0433\u0435\u043d \u0413\u0430\u043b\u0438\u0447]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0417\u0443\u0441\u0442\u0440\u0456\u0447 \u0437 \u041b\u0456\u043d\u043e\u044e \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e-\u041b\u0456\u043d\u0430 \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_ukrainian_full_normalization[\u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0432 \u0437 \u0412\u0430\u043b\u0435\u0440\u0456\u0454\u043c \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u043c-\u0412\u0430\u043b\u0435\u0440\u0456\u0439 \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u0439]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u0414\u043b\u044f \u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c \u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_russian_full_normalization[\u0412\u0441\u0442\u0440\u0435\u0447\u0430 \u0441 \u0410\u043d\u043d\u043e\u0439 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u043e\u0439-\u0410\u043d\u043d\u0430 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u0430]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_english_full_normalization[Sent to ELON MUSK for X corp-Elon Musk]
FAILED tmp/tests/integration/test_full_normalization_suite.py::test_critical_russian_normalization
FAILED tmp/tests/integration/test_gender_adjustment.py::TestGenderAdjustmentIntegration::test_ukrainian_female_name_with_patronymic
FAILED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_unicode_normalization_before_language_detection
FAILED tmp/tests/integration/test_lang_order_unicode_first.py::TestUnicodeFirstLanguageDetectionOrder::test_orchestrator_call_order_verification
FAILED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_with_cyrillic_surnames
FAILED tmp/tests/integration/test_mixed_script_names.py::TestMixedScriptNames::test_ascii_names_no_morphology
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_ukrainian_name_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_russian_name_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_mixed_language_text_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_compound_name_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_error_resilience_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_empty_text_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_performance_pipeline
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_morphology_integration
FAILED tmp/tests/integration/test_normalization_pipeline.py::TestNormalizationPipeline::test_transliteration_integration
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[ukrainian_company_with_legal_form]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[mixed_person_and_company]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[person_with_inn]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[mixed_script_names]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[quoted_company_with_person]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[hyphenated_surname]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[overfit_canary]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_pipeline_integration[full_pipeline_stress_test]
FAILED tmp/tests/integration/test_pipeline_end2end.py::TestPipelineEnd2End::test_normalization_flags_behavior
FAILED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430-ru]
FAILED tmp/tests/integration/test_role_based_normalization.py::test_role_based_slavic_normalization[\u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439-ru]
FAILED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_multiple_persons_same_surname
FAILED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_surname_variations
FAILED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_organization_legal_forms_filtering
FAILED tmp/tests/integration/test_ru_uk_sentences.py::TestRussianUkrainianSentences::test_performance_with_long_text
FAILED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_basic_functionality
FAILED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_smart_filter_skip
FAILED tmp/tests/unit/test_orchestrator_service_fixed.py::TestUnifiedOrchestrator::test_process_with_validation_error
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_basic_functionality
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_with_cache_hit
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_with_cache_miss
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_with_embeddings
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_error_handling
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_batch
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_batch_with_exceptions
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_search_similar_names_with_embeddings
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_search_similar_names_fallback
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_analyze_text_complexity
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_get_processing_stats
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_clear_cache
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_reset_stats
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_generate_cache_key
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_update_stats
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_calculate_complexity_score
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_generate_complexity_recommendations
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_force_reprocess_ignores_cache
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_orchestrator_initialization
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_language_service_failure
FAILED tmp/tests/unit/test_orchestrator_service_old.py::TestOrchestratorService::test_process_normalization_service_exception
FAILED tmp/tests/unit/test_pattern_service.py::TestPatternService::test_case_sensitivity_handling
FAILED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_word_basic
FAILED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_is_russian_name
FAILED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_basic
FAILED tmp/tests/unit/test_russian_morphology_unit.py::TestRussianMorphologyAnalyzer::test_analyze_name_with_language
FAILED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_initialization_with_terrorism_detection
FAILED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_make_smart_decision
FAILED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_service_words_cleaning
FAILED tmp/tests/unit/test_smart_filter_service.py::TestSmartFilterService::test_should_process_text_excluded
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0421\u0435\u0440\u0433\u0456\u0439-masc-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041e\u043b\u0435\u043d\u0430-femn-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-masc-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0414\u0430\u0440\u0456\u044f-femn-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041f\u0435\u0442\u0440\u043e-masc-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u0410\u043d\u043d\u0430-femn-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041c\u0438\u0445\u0430\u0439\u043b\u043e-masc-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_detection_for_ukrainian_names[\u041a\u0430\u0442\u0435\u0440\u0438\u043d\u0430-femn-uk]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_diminutives_generation
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_transliteration_generation
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e-expected_endings0]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u0406\u0432\u0430\u043d\u0435\u043d\u043a\u043e-expected_endings1]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u041c\u0435\u043b\u044c\u043d\u0438\u043a-expected_endings2]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_surname_endings[\u0428\u0435\u0432\u0447\u0435\u043d\u043a\u043e-expected_endings3]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[\u0410-expected_result1]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_edge_cases_handling[\u0421\u0435\u0440\u0433\u0456\u0439-expected_result2]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0421\u0435\u0440\u0433\u0456\u0439-expected_ukrainian_chars0]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u041e\u043b\u0435\u043a\u0441\u0456\u0439-expected_ukrainian_chars1]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0412\u043e\u043b\u043e\u0434\u0438\u043c\u0438\u0440-expected_ukrainian_chars2]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u0414\u0430\u0440\u0456\u044f-expected_ukrainian_chars3]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_ukrainian_character_detection[\u041f\u0435\u0442\u0440\u043e-expected_ukrainian_chars4]
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_name_complexity_analysis
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_correction_logic
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_basic_functionality
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_short_name_handling
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_auto_language_detection
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_gender_exceptions_dictionary
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_phonetic_variants_generation
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_regional_transliterations
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_get_all_forms_method
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_is_ukrainian_name_detection
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_complexity_level_calculation
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_basic_transliteration
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_language_detection_internal
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_pymorphy_analysis_failure_handling
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_generate_pymorphy_declensions
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_extract_gender_with_name_tags
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_extract_gender_by_endings
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_apply_regional_transliteration
FAILED tmp/tests/unit/test_ukrainian_morphology.py::TestUkrainianMorphologyAnalyzer::test_whitespace_name_handling
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_gender_detection_petro
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_gender_detection_daria
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_word_short_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_is_known_word_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_gender_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_gender_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_basic_functionality
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_with_language_detection
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_final_cleanup
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_unicode_normalization_failure_handling
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_case_normalization
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_complete_pipeline
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_normalization_flags_passed_correctly
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_optional_services_disabled
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_error_handling
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_performance_warning
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_signals_integration
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_trace_preservation
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_language_hint
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_result_serialization
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0416\u0435\u043d\u0456 \u0413\u0430\u043b\u0438\u0447\u0430 \u0437 \u0433\u0440\u0443\u043f\u0438 O.Torvald-\u0404\u0432\u0433\u0435\u043d \u0413\u0430\u043b\u0438\u0447]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0417\u0443\u0441\u0442\u0440\u0456\u0447 \u0437 \u041b\u0456\u043d\u043e\u044e \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e-\u041b\u0456\u043d\u0430 \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0432 \u0437 \u0412\u0430\u043b\u0435\u0440\u0456\u0454\u043c \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u043c-\u0412\u0430\u043b\u0435\u0440\u0456\u0439 \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u0439]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u0430 \u0421.\u0412.-\u0406\u0432\u0430\u043d\u043e\u0432-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e \u0421.\u0412.]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0414\u043b\u044f \u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c \u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0412\u0441\u0442\u0440\u0435\u0447\u0430 \u0441 \u0410\u043d\u043d\u043e\u0439 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u043e\u0439-\u0410\u043d\u043d\u0430 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u0430]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0417\u0430\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0442 \u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432\u0430 \u041c.\u042e.-\u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432 \u041c.\u042e.]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Sent to ELON MUSK for X corp-Elon Musk]
FAILED tmp/tests/unit/text_processing/test_normalization_result_fields.py::TestNormalizationResultFields::test_normalization_result_basic_serialization
FAILED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_russian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_ukrainian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_english_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_russian_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_auto_language_detection
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_special_characters
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_sync_method
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_async_method
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_flags
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_russian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_ukrainian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_diminutive_maps_initialization
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationResult::test_normalization_result_creation
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationResult::test_normalization_result_error_case
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_english_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_russian_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_tokenize_text_fallback_to_nltk
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_tokenize_text_basic_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_ukrainian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_without_spacy
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_without_nltk
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_minimal_dependencies
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_cache_functionality
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationResult::test_normalization_result_error_case
FAILED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_final_cleanup
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_context_words_never_become_names
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_ukrainian_context_words
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_russian_context_words
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_mixed_language_context_words
FAILED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_homoglyph_replacement
FAILED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_suspicion_analysis_high_homoglyph_ratio
202 failed, 1616 passed, 15 skipped, 5 warnings in 426.43s (0:07:06)
s/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_gender_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_variants_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_special_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_get_diminutives_unknown_name
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_basic_functionality
FAILED tmp/tests/unit/test_ukrainian_morphology_unit.py::TestUkrainianMorphologyAnalyzer::test_analyze_name_with_language_detection
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_final_cleanup
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_unicode_normalization_failure_handling
FAILED tmp/tests/unit/test_unicode_service.py::TestUnicodeService::test_case_normalization
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_complete_pipeline
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_normalization_flags_passed_correctly
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_smart_filter_skip_behavior
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_optional_services_disabled
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_error_handling
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_performance_warning
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_backward_compatibility_methods
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_signals_integration
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_trace_preservation
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_language_hint
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestrator::test_result_serialization
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_valid_services
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_validation_service
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_language_service
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_unicode_service
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_normalization_service
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_none_signals_service
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorConstructor::test_constructor_with_optional_services_none
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorEdgeCases::test_empty_input
FAILED tmp/tests/unit/test_unified_orchestrator.py::TestUnifiedOrchestratorEdgeCases::test_service_initialization_failure
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0416\u0435\u043d\u0456 \u0413\u0430\u043b\u0438\u0447\u0430 \u0437 \u0433\u0440\u0443\u043f\u0438 O.Torvald-\u0404\u0432\u0433\u0435\u043d \u0413\u0430\u043b\u0438\u0447]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0417\u0443\u0441\u0442\u0440\u0456\u0447 \u0437 \u041b\u0456\u043d\u043e\u044e \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e-\u041b\u0456\u043d\u0430 \u041a\u043e\u0441\u0442\u0435\u043d\u043a\u043e]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0420\u043e\u0437\u043c\u043e\u0432\u043b\u044f\u0432 \u0437 \u0412\u0430\u043b\u0435\u0440\u0456\u0454\u043c \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u043c-\u0412\u0430\u043b\u0435\u0440\u0456\u0439 \u0417\u0430\u043b\u0443\u0436\u043d\u0438\u0439]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_ukrainian_full_normalization[\u0414\u043b\u044f \u0406\u0432\u0430\u043d\u043e\u0432\u0430-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u0430 \u0421.\u0412.-\u0406\u0432\u0430\u043d\u043e\u0432-\u041f\u0435\u0442\u0440\u0435\u043d\u043a\u043e \u0421.\u0412.]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0414\u043b\u044f \u0410\u043b\u043b\u044b \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u044b \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u043e\u0439-\u0410\u043b\u043b\u0430 \u0411\u043e\u0440\u0438\u0441\u043e\u0432\u043d\u0430 \u041f\u0443\u0433\u0430\u0447\u0435\u0432\u0430]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c \u041f\u0435\u0442\u0440\u0443 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u043e\u043c\u0443-\u041f\u0435\u0442\u0440 \u0427\u0430\u0439\u043a\u043e\u0432\u0441\u043a\u0438\u0439]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0412\u0441\u0442\u0440\u0435\u0447\u0430 \u0441 \u0410\u043d\u043d\u043e\u0439 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u043e\u0439-\u0410\u043d\u043d\u0430 \u0410\u0445\u043c\u0430\u0442\u043e\u0432\u0430]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_russian_full_normalization[\u0417\u0430\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0442 \u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432\u0430 \u041c.\u042e.-\u041b\u0435\u0440\u043c\u043e\u043d\u0442\u043e\u0432 \u041c.\u042e.]
FAILED tmp/tests/unit/text_processing/test_normalization_logic.py::test_english_full_normalization[Sent to ELON MUSK for X corp-Elon Musk]
FAILED tmp/tests/unit/text_processing/test_normalization_result_fields.py::TestNormalizationResultFields::test_normalization_result_basic_serialization
FAILED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_russian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service.py::TestNormalizationService::test_normalize_ukrainian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_english_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_russian_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_auto_language_detection
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_special_characters
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_sync_method
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_async_method
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_with_flags
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_russian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationService::test_normalize_ukrainian_complex_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationServiceConfiguration::test_diminutive_maps_initialization
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationResult::test_normalization_result_creation
FAILED tmp/tests/unit/text_processing/test_normalization_service_fixed.py::TestNormalizationResult::test_normalization_result_error_case
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_english_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_russian_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_tokenize_text_fallback_to_nltk
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_tokenize_text_basic_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_remove_stop_words_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_ukrainian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_stemming_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_english
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_russian
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_apply_lemmatization_fallback
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_success
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_without_optional_processing
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_ukrainian_with_forms
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_empty_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_whitespace_only
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_unicode_error
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_language_detection_error
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationService::test_normalize_processing_error
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_very_long_text
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_special_characters
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_mixed_languages
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_normalize_unsupported_language
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceEdgeCases::test_ukrainian_normalization_basic
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_without_spacy
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_without_nltk
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_initialization_minimal_dependencies
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationServiceConfiguration::test_cache_functionality
FAILED tmp/tests/unit/text_processing/test_normalization_service_old.py::TestNormalizationResult::test_normalization_result_error_case
FAILED tmp/tests/unit/text_processing/test_unicode_service.py::TestUnicodeService::test_final_cleanup
FAILED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_ttl_expiration
FAILED tmp/tests/unit/utilities/test_cache_service.py::TestCacheService::test_exists_with_expired_key
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_context_words_never_become_names
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_ukrainian_context_words
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_russian_context_words
FAILED tmp/tests/unit/utilities/test_canary_overfit.py::TestCanaryOverfit::test_mixed_language_context_words
FAILED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_homoglyph_replacement
FAILED tmp/tests/unit/utilities/test_input_validation.py::TestInputValidator::test_suspicion_analysis_high_homoglyph_ratio
285 failed, 1533 passed, 15 skipped, 128 warnings in 292.56s (0:04:52)
