#!/usr/bin/env python3

"""
–¢–µ—Å—Ç —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ fuzzy search –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è false positives.
"""

import json
import asyncio
import aiohttp
import sys
from typing import List, Dict, Any

async def test_improved_fuzzy_thresholds():
    """Test improved fuzzy search with better thresholds."""
    print("üîß –¢–ï–°–¢ –£–õ–£–ß–®–ï–ù–ù–´–• FUZZY SEARCH –ü–û–†–û–ì–û–í")
    print("=" * 70)

    es_url = "http://95.217.84.234:9200"
    index_name = "ai_service_ac_patterns"

    test_cases = [
        {
            "query": "–ö–æ–≤—Ä–∏–∫–æ –†–æ–º–∞–Ω",
            "expected": "–ö–æ–≤—Ä–∏–∫–æ–≤ –†–æ–º–∞–Ω",
            "should_match": True,
            "description": "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–ø–µ—á–∞—Ç–∫–∞ - –¥–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏"
        },
        {
            "query": "–†–æ–º–∞–Ω –ö–æ–≤—Ä–∏–∫–æ–≤ –ê–Ω–∞—Ç–æ–ª—å–µ–≤–∏—á",
            "expected": "–ö–æ–≤—Ä–∏–∫–æ–≤ –†–æ–º–∞–Ω –í–∞–ª–µ—Ä—ñ–π–æ–≤–∏—á",
            "should_match": False,
            "description": "–†–∞–∑–Ω—ã–µ –æ—Ç—á–µ—Å—Ç–≤–∞ - –ù–ï –¥–æ–ª–∂–µ–Ω —Å—á–∏—Ç–∞—Ç—å—Å—è –≤—ã—Å–æ–∫–∏–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º"
        },
        {
            "query": "–î–∞—Ä—å—è –ü–∞–≤–ª–æ–≤–∞ –Æ—Ä—å–µ–≤–Ω–∞",
            "expected": "–í–æ–ª–æ—á–∫–æ–≤ –ü–∞–≤–ª–æ –ü–∞–≤–ª–æ–≤–∏—á",
            "should_match": False,
            "description": "–°–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ –ª—é–¥–∏ - –ù–ï –¥–æ–ª–∂–µ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—å"
        }
    ]

    try:
        async with aiohttp.ClientSession() as session:
            for i, test_case in enumerate(test_cases, 1):
                print(f"\nüß™ –¢–µ—Å—Ç {i}: {test_case['description']}")
                print(f"   –ó–∞–ø—Ä–æ—Å: '{test_case['query']}'")

                # Updated ES query with conservative settings
                es_query = {
                    "query": {
                        "bool": {
                            "should": [
                                {
                                    "fuzzy": {
                                        "pattern": {
                                            "value": test_case['query'],
                                            "fuzziness": 1,
                                            "prefix_length": 2,
                                            "max_expansions": 20,
                                            "boost": 2.0
                                        }
                                    }
                                },
                                {
                                    "fuzzy": {
                                        "canonical": {
                                            "value": test_case['query'],
                                            "fuzziness": 1,
                                            "prefix_length": 2,
                                            "max_expansions": 20,
                                            "boost": 1.5
                                        }
                                    }
                                },
                                {
                                    "match": {
                                        "canonical": {
                                            "query": test_case['query'],
                                            "fuzziness": 1,
                                            "boost": 1.2
                                        }
                                    }
                                }
                            ],
                            "minimum_should_match": 1
                        }
                    },
                    "size": 10,
                    "_source": ["pattern", "canonical", "entity_id", "entity_type", "confidence", "tier"]
                }

                url = f"{es_url}/{index_name}/_search"
                async with session.post(url, json=es_query) as response:
                    if response.status == 200:
                        data = await response.json()
                        hits = data.get("hits", {}).get("hits", [])

                        print(f"   –ù–∞–π–¥–µ–Ω–æ ES —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(hits)}")

                        # Simulate our improved scoring logic
                        scored_results = []
                        for hit in hits:
                            source = hit.get('_source', {})
                            es_score = hit.get('_score', 0.0)

                            # Calculate word similarity (same logic as in code)
                            query_parts = set(test_case['query'].lower().split())
                            result_text = source.get('canonical', source.get('pattern', ''))
                            result_parts = set(result_text.lower().split())

                            if query_parts and result_parts:
                                overlap = len(query_parts.intersection(result_parts))
                                total_unique = len(query_parts.union(result_parts))
                                word_similarity = overlap / total_unique if total_unique > 0 else 0
                            else:
                                word_similarity = 0

                            # Apply same scoring as in code
                            es_normalized = min(es_score / 50.0, 1.0)
                            normalized_score = (es_normalized * 0.3) + (word_similarity * 0.7)

                            if word_similarity < 0.3:
                                normalized_score *= 0.5

                            # Apply minimum threshold
                            if normalized_score >= 0.4:
                                scored_results.append({
                                    "text": result_text,
                                    "score": normalized_score,
                                    "es_score": es_score,
                                    "word_similarity": word_similarity,
                                    "pattern": source.get('pattern', '')
                                })

                        # Sort by score
                        scored_results.sort(key=lambda x: x['score'], reverse=True)

                        print(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(scored_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        for j, result in enumerate(scored_results[:3], 1):
                            print(f"     {j}. {result['text']}")
                            print(f"        Score: {result['score']:.3f} (ES: {result['es_score']:.1f}, Word sim: {result['word_similarity']:.3f})")

                        # Check expectations
                        if test_case['should_match']:
                            high_score_found = any(r['score'] > 0.7 for r in scored_results)
                            expected_found = any(test_case['expected'].lower() in r['text'].lower() for r in scored_results)
                            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {'PASS' if (high_score_found and expected_found) else 'FAIL'}")
                        else:
                            high_score_found = any(r['score'] > 0.7 for r in scored_results)
                            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {'PASS' if not high_score_found else 'FAIL'} (–≤—ã—Å–æ–∫–∏—Ö —Å–∫–æ—Ä–æ–≤: {high_score_found})")

                    else:
                        print(f"   ‚ùå ES error: {response.status}")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False

async def main():
    """Main function."""
    print("üéØ IMPROVED FUZZY THRESHOLDS TEST")
    print("=" * 50)

    success = await test_improved_fuzzy_thresholds()

    print("\n" + "=" * 50)
    if success:
        print("üéâ SUCCESS: –¢–µ—Å—Ç –ø–æ—Ä–æ–≥–æ–≤ fuzzy search –∑–∞–≤–µ—Ä—à–µ–Ω!")
    else:
        print("‚ùå FAILURE: –ü—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ—Å—Ç–æ–º –ø–æ—Ä–æ–≥–æ–≤")

    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)