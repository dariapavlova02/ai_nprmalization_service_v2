#!/usr/bin/env python3
"""
Debug why –ê–ù–î–†–Ü–ô is marked as unknown
"""

import sys
sys.path.insert(0, '.')
sys.path.insert(0, 'src')

def debug_andrii_role():
    """Debug why –ê–ù–î–†–Ü–ô is not recognized as given name."""
    print("üîç DEBUGGING –ê–ù–î–†–Ü–ô ROLE CLASSIFICATION")
    print("="*40)

    test_tokens = ["–®–ï–í–ß–ï–ù–ö–û", "–ê–ù–î–†–Ü–ô", "–ê–ù–ê–¢–û–õ–Ü–ô–û–í–ò–ß"]

    try:
        # Use the same classifier instance as normalization service
        from ai_service.layers.normalization.normalization_service import NormalizationService
        service = NormalizationService()
        classifier = service.normalization_factory.role_classifier

        print(f"üîç Classifier given_names for uk: {len(classifier.given_names.get('uk', set()))} names")
        uk_names = classifier.given_names.get('uk', set())
        if '–∞–Ω–¥—Ä—ñ–π' in uk_names:
            print(f"    ‚úÖ '–∞–Ω–¥—Ä—ñ–π' is in classifier.given_names['uk']")
        else:
            print(f"    ‚ùå '–∞–Ω–¥—Ä—ñ–π' is NOT in classifier.given_names['uk']")

        print("üîç Individual token classification:")
        for token in test_tokens:
            try:
                result = classifier._classify_personal_role(token, "uk")
                print(f"  '{token}' -> '{result}'")

                # Also test with lowercase
                result_lower = classifier._classify_personal_role(token.lower(), "uk")
                print(f"  '{token.lower()}' -> '{result_lower}'")

                # Test if it's in Ukrainian names dict
                try:
                    from ai_service.data.dicts.ukrainian_names import UKRAINIAN_NAMES
                    if token in UKRAINIAN_NAMES:
                        print(f"    ‚úÖ Found in UKRAINIAN_NAMES")
                        print(f"    Data: {UKRAINIAN_NAMES[token]}")
                    elif token.lower() in UKRAINIAN_NAMES:
                        print(f"    ‚úÖ Found in UKRAINIAN_NAMES (lowercase)")
                    elif token.capitalize() in UKRAINIAN_NAMES:
                        print(f"    ‚úÖ Found in UKRAINIAN_NAMES (capitalized)")
                        print(f"    Data: {UKRAINIAN_NAMES[token.capitalize()]}")
                    else:
                        print(f"    ‚ùå Not found in UKRAINIAN_NAMES")
                except ImportError:
                    print(f"    ‚ö†Ô∏è Cannot import UKRAINIAN_NAMES")

            except Exception as e:
                print(f"  ‚ùå Error classifying '{token}': {e}")

        print(f"\nüîç Full token sequence classification:")
        try:
            tagged_tokens, traces, organizations = classifier.tag_tokens(test_tokens, "uk")

            print("Tagged tokens:")
            for token, role in tagged_tokens:
                print(f"  '{token}' -> '{role}'")

            print("\nTraces:")
            for trace in traces:
                print(f"  {trace}")

        except Exception as e:
            print(f"‚ùå Error in full classification: {e}")

        print(f"\nüîç Testing recognition patterns:")
        # Test if –ê–ù–î–†–Ü–ô matches Ukrainian given name patterns
        test_cases = ["–ê–Ω–¥—Ä—ñ–π", "–ê–ù–î–†–Ü–ô", "–∞–Ω–¥—Ä—ñ–π"]
        for case in test_cases:
            print(f"\nTesting '{case}':")

            # Check if it looks like given name
            is_given = classifier._is_personal_candidate(case, "uk")
            print(f"  _is_personal_candidate: {is_given}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_andrii_role()