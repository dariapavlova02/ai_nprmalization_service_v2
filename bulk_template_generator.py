#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –º–∞—Å—Å–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
1. sanctioned_persons.json - 13,192 –∑–∞–ø–∏—Å–∏
2. sanctioned_companies.json - 7,603 –∑–∞–ø–∏—Å–∏
3. terrorism_black_list.json - 5,258 –∑–∞–ø–∏—Å–µ–π

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π HighRecallACGenerator —Å –¥–æ—Ä–∞–±–æ—Ç–∫–∞–º–∏:
- –ß–∏—Å—Ç—ã–µ –¥–∏–º–∏–Ω—É—Ç–∏–≤—ã –±–µ–∑ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∞–ª—Ñ–∞–≤–∏—Ç–æ–≤
- Title Case —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
- –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏
- –ú–∏–Ω–∏-—Å–∞–Ω–∏—Ç–∞–π–∑–µ—Ä
"""

import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass, asdict

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

from ai_service.layers.variants.templates.high_recall_ac_generator import (
    HighRecallACGenerator,
    RecallOptimizedPattern
)


@dataclass
class GenerationStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–æ–≤"""
    total_entities: int = 0
    processed_entities: int = 0
    total_patterns: int = 0
    patterns_by_tier: Dict[int, int] = None
    patterns_by_type: Dict[str, int] = None
    processing_time: float = 0.0
    errors: List[str] = None

    def __post_init__(self):
        if self.patterns_by_tier is None:
            self.patterns_by_tier = {}
        if self.patterns_by_type is None:
            self.patterns_by_type = {}
        if self.errors is None:
            self.errors = []


class BulkTemplateGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —à–∞–±–ª–æ–Ω–æ–≤ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""

    def __init__(self):
        self.generator = HighRecallACGenerator()
        self.stats = {
            'persons': GenerationStats(),
            'companies': GenerationStats(),
            'terrorists': GenerationStats()
        }

    def load_data_files(self) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤...")

        # –°–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω—ã
        with open('src/ai_service/data/sanctioned_persons.json', 'r', encoding='utf-8') as f:
            persons = json.load(f)

        # –°–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
        with open('src/ai_service/data/sanctioned_companies.json', 'r', encoding='utf-8') as f:
            companies = json.load(f)

        # –¢–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –±–ª—ç–∫-–ª–∏—Å—Ç
        with open('src/ai_service/data/terrorism_black_list.json', 'r', encoding='utf-8') as f:
            terrorists = json.load(f)

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ:")
        print(f"  - –°–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω—ã: {len(persons):,}")
        print(f"  - –°–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏: {len(companies):,}")
        print(f"  - –¢–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –±–ª—ç–∫-–ª–∏—Å—Ç: {len(terrorists):,}")
        print(f"  - –í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {len(persons) + len(companies) + len(terrorists):,}")

        return persons, companies, terrorists

    def extract_person_names(self, person_data: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∏–º—ë–Ω –ø–µ—Ä—Å–æ–Ω—ã"""
        names = []

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∏–º—ë–Ω
        if person_data.get('name'):
            names.append(person_data['name'])
        if person_data.get('name_ru'):
            names.append(person_data['name_ru'])
        if person_data.get('name_en'):
            names.append(person_data['name_en'])

        return [name for name in names if name and name.strip()]

    def extract_terrorist_names(self, terrorist_data: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º—ë–Ω –∏–∑ —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
        names = []

        if terrorist_data.get('aka_name'):
            names.append(terrorist_data['aka_name'])

        return [name for name in names if name and name.strip()]

    def extract_company_names(self, company_data: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–π"""
        names = []

        if company_data.get('name'):
            names.append(company_data['name'])

        return [name for name in names if name and name.strip()]

    def generate_patterns_for_entity(self, names: List[str], entity_type: str, entity_data: Dict = None) -> List[RecallOptimizedPattern]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏"""
        all_patterns = []

        for name in names:
            try:
                if entity_type in ['persons', 'terrorists']:
                    # –î–ª—è –ø–µ—Ä—Å–æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if entity_data and entity_type == 'persons':
                        patterns = self.generator.generate_high_recall_patterns_from_sanctions_data(entity_data)
                    else:
                        # –ò–Ω–∞—á–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ã—á–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
                        patterns = self.generator.generate_high_recall_patterns(
                            name,
                            language='auto'
                        )
                else:
                    # –î–ª—è –∫–æ–º–ø–∞–Ω–∏–π
                    if entity_data:
                        patterns = self.generator.generate_high_recall_patterns_from_sanctions_data(entity_data)
                    else:
                        patterns = self.generator.generate_high_recall_patterns(
                            name,
                            language='auto'
                        )

                all_patterns.extend(patterns)

            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è '{name}': {str(e)}"
                self.stats[entity_type].errors.append(error_msg)

        return all_patterns

    def update_statistics(self, patterns: List[RecallOptimizedPattern], entity_type: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = self.stats[entity_type]
        stats.total_patterns += len(patterns)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏—Ä–∞–º
        for pattern in patterns:
            tier = getattr(pattern, 'recall_tier', 0)
            stats.patterns_by_tier[tier] = stats.patterns_by_tier.get(tier, 0) + 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        for pattern in patterns:
            pattern_type = getattr(pattern, 'pattern_type', 'unknown')
            stats.patterns_by_type[pattern_type] = stats.patterns_by_type.get(pattern_type, 0) + 1

    def process_persons(self, persons_data: List[Dict]) -> List[RecallOptimizedPattern]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω"""
        print(f"\nüë• –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω ({len(persons_data):,} –∑–∞–ø–∏—Å–µ–π)...")

        start_time = time.time()
        all_patterns = []
        stats = self.stats['persons']
        stats.total_entities = len(persons_data)

        for i, person in enumerate(persons_data, 1):
            if i % 1000 == 0 or i == len(persons_data):
                elapsed = time.time() - start_time
                rate = i / elapsed if elapsed > 0 else 0
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,}/{len(persons_data):,} ({rate:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫)")

            names = self.extract_person_names(person)
            if names:
                patterns = self.generate_patterns_for_entity(names, 'persons', person)
                all_patterns.extend(patterns)
                self.update_statistics(patterns, 'persons')
                stats.processed_entities += 1

        stats.processing_time = time.time() - start_time
        print(f"‚úÖ –ü–µ—Ä—Å–æ–Ω—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {stats.processed_entities:,} –∑–∞–ø–∏—Å–µ–π, {len(all_patterns):,} —à–∞–±–ª–æ–Ω–æ–≤")

        return all_patterns

    def process_terrorists(self, terrorists_data: List[Dict]) -> List[RecallOptimizedPattern]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –±–ª—ç–∫-–ª–∏—Å—Ç–∞"""
        print(f"\nüíÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –±–ª—ç–∫-–ª–∏—Å—Ç–∞ ({len(terrorists_data):,} –∑–∞–ø–∏—Å–µ–π)...")

        start_time = time.time()
        all_patterns = []
        stats = self.stats['terrorists']
        stats.total_entities = len(terrorists_data)

        for i, terrorist in enumerate(terrorists_data, 1):
            if i % 1000 == 0 or i == len(terrorists_data):
                elapsed = time.time() - start_time
                rate = i / elapsed if elapsed > 0 else 0
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,}/{len(terrorists_data):,} ({rate:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫)")

            names = self.extract_terrorist_names(terrorist)
            if names:
                patterns = self.generate_patterns_for_entity(names, 'terrorists', terrorist)
                all_patterns.extend(patterns)
                self.update_statistics(patterns, 'terrorists')
                stats.processed_entities += 1

        stats.processing_time = time.time() - start_time
        print(f"‚úÖ –¢–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {stats.processed_entities:,} –∑–∞–ø–∏—Å–µ–π, {len(all_patterns):,} —à–∞–±–ª–æ–Ω–æ–≤")

        return all_patterns

    def process_companies(self, companies_data: List[Dict]) -> List[RecallOptimizedPattern]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π"""
        print(f"\nüè¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π ({len(companies_data):,} –∑–∞–ø–∏—Å–µ–π)...")

        start_time = time.time()
        all_patterns = []
        stats = self.stats['companies']
        stats.total_entities = len(companies_data)

        for i, company in enumerate(companies_data, 1):
            if i % 500 == 0 or i == len(companies_data):
                elapsed = time.time() - start_time
                rate = i / elapsed if elapsed > 0 else 0
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i:,}/{len(companies_data):,} ({rate:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫)")

            names = self.extract_company_names(company)
            if names:
                patterns = self.generate_patterns_for_entity(names, 'companies', company)
                all_patterns.extend(patterns)
                self.update_statistics(patterns, 'companies')
                stats.processed_entities += 1

        stats.processing_time = time.time() - start_time
        print(f"‚úÖ –ö–æ–º–ø–∞–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {stats.processed_entities:,} –∑–∞–ø–∏—Å–µ–π, {len(all_patterns):,} —à–∞–±–ª–æ–Ω–æ–≤")

        return all_patterns

    def generate_statistics_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ"""
        report = []
        report.append("=" * 80)
        report.append("üìä –û–¢–ß–Å–¢ –ü–û –ú–ê–°–°–û–í–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò –®–ê–ë–õ–û–ù–û–í")
        report.append("=" * 80)

        total_entities = sum(stats.total_entities for stats in self.stats.values())
        total_processed = sum(stats.processed_entities for stats in self.stats.values())
        total_patterns = sum(stats.total_patterns for stats in self.stats.values())
        total_time = sum(stats.processing_time for stats in self.stats.values())

        report.append(f"\nüéØ –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        report.append(f"  –í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ —Å–ø–∏—Å–∫–∞—Ö: {total_entities:,}")
        report.append(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed:,}")
        report.append(f"  –í—Å–µ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤: {total_patterns:,}")
        report.append(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time:.1f} —Å–µ–∫")
        report.append(f"  –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_processed/total_time:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")

        for category, stats in self.stats.items():
            report.append(f"\nüìã {category.upper()}:")
            report.append(f"  –ó–∞–ø–∏—Å–µ–π –≤ —Å–ø–∏—Å–∫–µ: {stats.total_entities:,}")
            report.append(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {stats.processed_entities:,}")
            report.append(f"  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤: {stats.total_patterns:,}")
            report.append(f"  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats.processing_time:.1f} —Å–µ–∫")

            if stats.patterns_by_tier:
                report.append(f"  –®–∞–±–ª–æ–Ω—ã –ø–æ —Ç–∏—Ä–∞–º: {dict(sorted(stats.patterns_by_tier.items()))}")

            if stats.errors:
                report.append(f"  ‚ö†Ô∏è –û—à–∏–±–æ–∫: {len(stats.errors)}")
                for error in stats.errors[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                    report.append(f"    - {error}")
                if len(stats.errors) > 5:
                    report.append(f"    ... –∏ –µ—â—ë {len(stats.errors) - 5} –æ—à–∏–±–æ–∫")

        return "\n".join(report)

    def export_patterns(self, all_patterns: List[RecallOptimizedPattern], output_file: str):
        """–≠–∫—Å–ø–æ—Ä—Ç —à–∞–±–ª–æ–Ω–æ–≤ –≤ —Ñ–∞–π–ª"""
        print(f"\nüíæ –≠–∫—Å–ø–æ—Ä—Ç —à–∞–±–ª–æ–Ω–æ–≤ –≤ {output_file}...")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        patterns_data = []
        for pattern in all_patterns:
            pattern_dict = {
                'pattern': pattern.pattern,
                'pattern_type': pattern.pattern_type,
                'recall_tier': getattr(pattern, 'recall_tier', 0),
                'precision_hint': getattr(pattern, 'precision_hint', 0.0),
                'variants': getattr(pattern, 'variants', []),
                'language': pattern.language,
                'source_confidence': getattr(pattern, 'source_confidence', 1.0)
            }
            patterns_data.append(pattern_dict)

        # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(patterns_data, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {len(patterns_data):,} —à–∞–±–ª–æ–Ω–æ–≤")

    def run_bulk_generation(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –º–∞—Å—Å–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        print("üöÄ –ó–ê–ü–£–°–ö –ú–ê–°–°–û–í–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò –®–ê–ë–õ–û–ù–û–í")
        print("=" * 60)

        start_time = time.time()

        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            persons, companies, terrorists = self.load_data_files()

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤
            all_patterns = []

            # –°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä—Å–æ–Ω—ã (—Å–∞–Ω–∫—Ü–∏–∏ + —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç—ã)
            person_patterns = self.process_persons(persons)
            all_patterns.extend(person_patterns)

            terrorist_patterns = self.process_terrorists(terrorists)
            all_patterns.extend(terrorist_patterns)

            # –ó–∞—Ç–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
            company_patterns = self.process_companies(companies)
            all_patterns.extend(company_patterns)

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
            report = self.generate_statistics_report()
            print(report)

            # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"generated_patterns_{timestamp}.json"
            self.export_patterns(all_patterns, output_file)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
            report_file = f"generation_report_{timestamp}.txt"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"üìÑ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_file}")

            total_time = time.time() - start_time
            print(f"\nüéâ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
            print(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.1f} —Å–µ–∫")
            print(f"   –í—Å–µ–≥–æ —à–∞–±–ª–æ–Ω–æ–≤: {len(all_patterns):,}")

        except Exception as e:
            print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}")
            import traceback
            traceback.print_exc()


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    generator = BulkTemplateGenerator()
    generator.run_bulk_generation()


if __name__ == "__main__":
    main()